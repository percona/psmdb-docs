{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"index.html","text":"Percona Server for MongoDB 6.0 Documentation \u00b6 Percona Server for MongoDB is a free, enhanced, fully compatible, source available, drop-in replacement for MongoDB 6.0 Community Edition with enterprise-grade features. It requires no changes to MongoDB applications or code. To see which version of Percona Server for MongoDB you are using check the value of the psmdbVersion key in the output of the buildInfo database command. If this key does not exist, Percona Server for MongoDB is not installed on the server. This is the documentation for the latest release, Percona Server for MongoDB 6.0.4-3 ( Release Notes ). Features \u00b6 Percona Server for MongoDB provides the following features: MongoDB\u2019s default WiredTiger engine Percona Memory Engine storage engine Data at Rest Encryption External authentication using OpenLDAP or Active Directory Audit logging to track and query database interactions of users or applications Hot Backup for the default WiredTiger Profiling Rate Limit to decrease the impact of the profiler on performance To learn more about the features, available in Percona Server for MongoDB, see Percona Server for MongoDB Feature Comparison Get started \u00b6 Install Percona Server for MongoDB","title":"Home"},{"location":"index.html#percona-server-for-mongodb-60-documentation","text":"Percona Server for MongoDB is a free, enhanced, fully compatible, source available, drop-in replacement for MongoDB 6.0 Community Edition with enterprise-grade features. It requires no changes to MongoDB applications or code. To see which version of Percona Server for MongoDB you are using check the value of the psmdbVersion key in the output of the buildInfo database command. If this key does not exist, Percona Server for MongoDB is not installed on the server. This is the documentation for the latest release, Percona Server for MongoDB 6.0.4-3 ( Release Notes ).","title":"Percona Server for MongoDB 6.0 Documentation"},{"location":"index.html#features","text":"Percona Server for MongoDB provides the following features: MongoDB\u2019s default WiredTiger engine Percona Memory Engine storage engine Data at Rest Encryption External authentication using OpenLDAP or Active Directory Audit logging to track and query database interactions of users or applications Hot Backup for the default WiredTiger Profiling Rate Limit to decrease the impact of the profiler on performance To learn more about the features, available in Percona Server for MongoDB, see Percona Server for MongoDB Feature Comparison","title":"Features"},{"location":"index.html#get-started","text":"Install Percona Server for MongoDB","title":"Get started"},{"location":"404.html","text":"404 - Not Found \u00b6 We can\u2019t find the page you are looking for. Try using the Search or return to the homepage .","title":"404 - Not Found"},{"location":"404.html#404-not-found","text":"We can\u2019t find the page you are looking for. Try using the Search or return to the homepage .","title":"404 - Not Found"},{"location":"audit-logging.html","text":"Auditing \u00b6 Auditing allows administrators to track and log user activity on a MongoDB server. With auditing enabled, the server will generate an audit log file. This file contains information about different user events including authentication, authorization failures, and so on. To enable audit logging, specify where to send audit events using the --auditDestination option on the command line or the auditLog.destination variable in the configuration file. If you want to output events to a file, also specify the format of the file using the --auditFormat option or the auditLog.format variable, and the path to the file using the --auditPath option or the auditLog.path variable. To filter recorded events, use the --auditFilter option or the auditLog.filter variable. For example, to log only events from a user named tim and write them to a JSON file /var/log/psmdb/audit.json , start the server with the following parameters: $ mongod \\ --dbpath data/db --auditDestination file \\ --auditFormat JSON \\ --auditPath /var/log/psmdb/audit.json \\ --auditFilter '{ \"users.user\" : \"tim\" }' The options in the previous example can be used as variables in the MongoDB configuration file: storage : dbPath : data/db auditLog : destination : file format : JSON path : /var/log/psmdb/audit.json filter : '{ \"users.user\" : \"tim\" }' This example shows how to send audit events to the syslog . Specify the following parameters: mongod \\ --dbpath data/db --auditDestination syslog \\ Alternatively, you can edit the MongoDB configuration file: storage : dbPath : data/db auditLog : destination : syslog Note If you start the server with auditing enabled, you cannot disable auditing dynamically during runtime. Audit options \u00b6 The following options control audit logging: Command line Configuration file Type Description --auditDestination() auditLog.destination string Enables auditing and specifies where to send audit events: - console : Output audit events to stdout . - file : Output audit events to a file specified by the --auditPath option in a format specified by the --auditFormat option. - syslog : Output audit events to syslog --auditFilter() auditLog.filter string Specifies a filter to apply to incoming audit events, enabling the administrator to only capture a subset of them. The value must be interpreted as a query object with the following syntax: { <field1>: <expression1>, ... } Audit log events that match this query will be logged. Events that do not match this query will be ignored. For more information, see Audit filter examples --auditFormat() auditLog.format string Specifies the format of the audit log file, if you set the --auditDestination option to file . The default value is JSON . Alternatively, you can set it to BSON --auditPath() auditLog.path string Specifies the fully qualified path to the file where audit log events are written, if you set the --auditDestination option to file . If this option is not specified, then the auditLog.json file is created in the server\u2019s configured log path. If log path is not configured on the server, then the auditLog.json file is created in the current directory (from which mongod was started). NOTE : This file will rotate in the same manner as the system log path, either on server reboot or using the logRotate command. The time of rotation will be added to the old file\u2019s name. Audit message syntax \u00b6 Audit logging writes messages in JSON format with the following syntax: { atype : < String > , ts : { \"$date\" : < timestamp > }, local : { ip : < String > , port : < int > }, remote : { ip : < String > , port : < int > }, users : [ { user : < String > , db : < String > }, ... ], roles : [ { role : < String > , db : < String > }, ... ], param : < document > , result : < int > } Parameter Description atype Event type ts Date and UTC time of the event local Local IP address and port number of the instance remote Remote IP address and port number of the incoming connection associated with the event users Users associated with the event roles Roles granted to the user param Details of the event associated with the specific type result Exit code ( 0 for success) Audit filter examples \u00b6 The following examples demonstrate the flexibility of audit log filters. auditLog : destination : file filter : '{atype: {$in: [ \"authenticate\", \"authCheck\", \"renameCollection\", \"dropCollection\", \"dropDatabase\", \"createUser\", \"dropUser\", \"dropAllUsersFromDatabase\", \"updateuser\", \"grantRolesToUser\", \"revokeRolesFromUser\", \"createRole\", \"updateRole\", \"dropRole\", \"dropAllRolesFromDatabase\", \"grantRolesToRole\", \"revokeRolesFromRole\", \"grantPrivilegesToRole\", \"revokePrivilegesFromRole\", \"replSetReconfig\", \"enableSharding\", \"shardCollection\", \"addShard\", \"removeShard\", \"shutdown\", \"applicationMessage\" ]}}' Standard query selectors \u00b6 You can use query selectors, such as $eq , $in , $gt , $lt , $ne , and others to log multiple event types. For example, to log only the dropCollection and dropDatabase events: Command line Config file --auditDestination file --auditFilter '{ atype: { $in: [ \"dropCollection\", \"dropDatabase\" ] } }' auditLog : destination : file filter : '{ atype: { $in: [ \"dropCollection\", \"dropDatabase\" ] } }' Regular expressions \u00b6 Another way to specify multiple event types is using regular expressions. For example, to filter all drop operations: Command line Config file --auditDestination file --auditFilter '{ \"atype\" : /^drop.*/ }' auditLog : destination : file filter : '{ \"atype\" : /^drop.*/ }' Read and write operations \u00b6 By default, operations with successful authorization are not logged, so for this filter to work, enable auditAuthorizationSuccess parameter, as described in Enabling auditing of authorization success . For example, to filter read and write operations on all the collections in the test database: Note The dot ( . ) after the database name in the regular expression must be escaped with two backslashes ( \\\\\\\\ ). Command line Config file --setParameter auditAuthorizationSuccess = true --auditDestination file --auditFilter '{ atype: \"authCheck\", \"param.command\": { $in: [ \"find\", \"insert\", \"delete\", \"update\", \"findandmodify\" ] }, \"param.ns\": /^test\\\\./ } }' auditLog : destination : file filter : '{ atype: \"authCheck\", \"param.command\": { $in: [ \"find\", \"insert\", \"delete\", \"update\", \"findandmodify\" ] }, \"param.ns\": /^test\\\\./ } }' setParameter : { auditAuthorizationSuccess : true } Enabling auditing of authorization success \u00b6 By default, only authorization failures for the authCheck action are logged by the audit system. authCheck is for authorization by role-based access control, it does not concern authentication at logins. To enable logging of authorization successes, set the auditAuthorizationSuccess parameter to true . Audit events will then be triggered by every command, including CRUD ones. Warning Enabling the auditAuthorizationSuccess parameter heavily impacts the performance compared to logging only authorization failures. You can enable it on a running server using the following command: db . adminCommand ( { setParameter : 1 , auditAuthorizationSuccess : true } ) To enable it on the command line, use the following option when running mongod or mongos process: -- setParameter auditAuthorizationSuccess = true You can also add it to the configuration file as follows: setParameter : auditAuthorizationSuccess : true","title":"Auditing"},{"location":"audit-logging.html#auditing","text":"Auditing allows administrators to track and log user activity on a MongoDB server. With auditing enabled, the server will generate an audit log file. This file contains information about different user events including authentication, authorization failures, and so on. To enable audit logging, specify where to send audit events using the --auditDestination option on the command line or the auditLog.destination variable in the configuration file. If you want to output events to a file, also specify the format of the file using the --auditFormat option or the auditLog.format variable, and the path to the file using the --auditPath option or the auditLog.path variable. To filter recorded events, use the --auditFilter option or the auditLog.filter variable. For example, to log only events from a user named tim and write them to a JSON file /var/log/psmdb/audit.json , start the server with the following parameters: $ mongod \\ --dbpath data/db --auditDestination file \\ --auditFormat JSON \\ --auditPath /var/log/psmdb/audit.json \\ --auditFilter '{ \"users.user\" : \"tim\" }' The options in the previous example can be used as variables in the MongoDB configuration file: storage : dbPath : data/db auditLog : destination : file format : JSON path : /var/log/psmdb/audit.json filter : '{ \"users.user\" : \"tim\" }' This example shows how to send audit events to the syslog . Specify the following parameters: mongod \\ --dbpath data/db --auditDestination syslog \\ Alternatively, you can edit the MongoDB configuration file: storage : dbPath : data/db auditLog : destination : syslog Note If you start the server with auditing enabled, you cannot disable auditing dynamically during runtime.","title":"Auditing"},{"location":"audit-logging.html#audit-options","text":"The following options control audit logging: Command line Configuration file Type Description --auditDestination() auditLog.destination string Enables auditing and specifies where to send audit events: - console : Output audit events to stdout . - file : Output audit events to a file specified by the --auditPath option in a format specified by the --auditFormat option. - syslog : Output audit events to syslog --auditFilter() auditLog.filter string Specifies a filter to apply to incoming audit events, enabling the administrator to only capture a subset of them. The value must be interpreted as a query object with the following syntax: { <field1>: <expression1>, ... } Audit log events that match this query will be logged. Events that do not match this query will be ignored. For more information, see Audit filter examples --auditFormat() auditLog.format string Specifies the format of the audit log file, if you set the --auditDestination option to file . The default value is JSON . Alternatively, you can set it to BSON --auditPath() auditLog.path string Specifies the fully qualified path to the file where audit log events are written, if you set the --auditDestination option to file . If this option is not specified, then the auditLog.json file is created in the server\u2019s configured log path. If log path is not configured on the server, then the auditLog.json file is created in the current directory (from which mongod was started). NOTE : This file will rotate in the same manner as the system log path, either on server reboot or using the logRotate command. The time of rotation will be added to the old file\u2019s name.","title":"Audit options"},{"location":"audit-logging.html#audit-message-syntax","text":"Audit logging writes messages in JSON format with the following syntax: { atype : < String > , ts : { \"$date\" : < timestamp > }, local : { ip : < String > , port : < int > }, remote : { ip : < String > , port : < int > }, users : [ { user : < String > , db : < String > }, ... ], roles : [ { role : < String > , db : < String > }, ... ], param : < document > , result : < int > } Parameter Description atype Event type ts Date and UTC time of the event local Local IP address and port number of the instance remote Remote IP address and port number of the incoming connection associated with the event users Users associated with the event roles Roles granted to the user param Details of the event associated with the specific type result Exit code ( 0 for success)","title":"Audit message syntax"},{"location":"audit-logging.html#audit-filter-examples","text":"The following examples demonstrate the flexibility of audit log filters. auditLog : destination : file filter : '{atype: {$in: [ \"authenticate\", \"authCheck\", \"renameCollection\", \"dropCollection\", \"dropDatabase\", \"createUser\", \"dropUser\", \"dropAllUsersFromDatabase\", \"updateuser\", \"grantRolesToUser\", \"revokeRolesFromUser\", \"createRole\", \"updateRole\", \"dropRole\", \"dropAllRolesFromDatabase\", \"grantRolesToRole\", \"revokeRolesFromRole\", \"grantPrivilegesToRole\", \"revokePrivilegesFromRole\", \"replSetReconfig\", \"enableSharding\", \"shardCollection\", \"addShard\", \"removeShard\", \"shutdown\", \"applicationMessage\" ]}}'","title":"Audit filter examples"},{"location":"audit-logging.html#standard-query-selectors","text":"You can use query selectors, such as $eq , $in , $gt , $lt , $ne , and others to log multiple event types. For example, to log only the dropCollection and dropDatabase events: Command line Config file --auditDestination file --auditFilter '{ atype: { $in: [ \"dropCollection\", \"dropDatabase\" ] } }' auditLog : destination : file filter : '{ atype: { $in: [ \"dropCollection\", \"dropDatabase\" ] } }'","title":"Standard query selectors"},{"location":"audit-logging.html#regular-expressions","text":"Another way to specify multiple event types is using regular expressions. For example, to filter all drop operations: Command line Config file --auditDestination file --auditFilter '{ \"atype\" : /^drop.*/ }' auditLog : destination : file filter : '{ \"atype\" : /^drop.*/ }'","title":"Regular expressions"},{"location":"audit-logging.html#read-and-write-operations","text":"By default, operations with successful authorization are not logged, so for this filter to work, enable auditAuthorizationSuccess parameter, as described in Enabling auditing of authorization success . For example, to filter read and write operations on all the collections in the test database: Note The dot ( . ) after the database name in the regular expression must be escaped with two backslashes ( \\\\\\\\ ). Command line Config file --setParameter auditAuthorizationSuccess = true --auditDestination file --auditFilter '{ atype: \"authCheck\", \"param.command\": { $in: [ \"find\", \"insert\", \"delete\", \"update\", \"findandmodify\" ] }, \"param.ns\": /^test\\\\./ } }' auditLog : destination : file filter : '{ atype: \"authCheck\", \"param.command\": { $in: [ \"find\", \"insert\", \"delete\", \"update\", \"findandmodify\" ] }, \"param.ns\": /^test\\\\./ } }' setParameter : { auditAuthorizationSuccess : true }","title":"Read and write operations"},{"location":"audit-logging.html#enabling-auditing-of-authorization-success","text":"By default, only authorization failures for the authCheck action are logged by the audit system. authCheck is for authorization by role-based access control, it does not concern authentication at logins. To enable logging of authorization successes, set the auditAuthorizationSuccess parameter to true . Audit events will then be triggered by every command, including CRUD ones. Warning Enabling the auditAuthorizationSuccess parameter heavily impacts the performance compared to logging only authorization failures. You can enable it on a running server using the following command: db . adminCommand ( { setParameter : 1 , auditAuthorizationSuccess : true } ) To enable it on the command line, use the following option when running mongod or mongos process: -- setParameter auditAuthorizationSuccess = true You can also add it to the configuration file as follows: setParameter : auditAuthorizationSuccess : true","title":"Enabling auditing of authorization success"},{"location":"authentication.html","text":"Authentication \u00b6 Authentication is the process of verifying a client\u2019s identity. Normally, a client needs to authenticate themselves against the MongoDB server user database before doing any work or reading any data from a mongod or mongos instance. By default, Percona Server for MongoDB provides a SCRAM authentication mechanism where clients authenticate themselves by providing their user credentials. In addition, you can integrate Percona Server for MongoDB with a separate service, such as OpenLDAP or Active Directory. This enables users to access the database with the same credentials they use for their emails or workstations. You can use any of these authentication mechanisms supported in Percona Server for MongoDB: SCRAM (default) x.509 certificate authentication LDAP authentication with SASL Kerberos Authentication Authentication and authorization with direct binding to LDAP SCRAM \u00b6 SCRAM is the default authentication mechanism. Percona Server for MongoDB verifies the credentials against the user\u2019s name, password and the database where the user record is created for a client (authentication database). For how to enable this mechanism, see Enabling Authentication . x.509 certificate authentication \u00b6 This authentication mechanism enables a client to authenticate in Percona Server for MongoDB by providing an x.509 certificate instead of user credentials. Each certificate contains the subject field defined in the format. In Percona Server for MongoDB, each certificate has a corresponding user record in the $external database. When a user connects to the database, Percona Server for MongoDB matches the subject value against the usernames defined in the $external database. For production use, we recommend using valid certificates. For testing purposes, you can generate and use self-signed certificates. x.509 authentication is compatible with with LDAP authorization to enable you to control user access and operations in Percona Server for MongoDB. For configuration guidelines, refer to Set up x.509 authentication and LDAP authorization . See also MongoDB Documentation: x.509 Percona Blog: Setting up MongoDB with Member x509 auth and SSL + easy-rsa LDAP authentication with SASL \u00b6 Overview \u00b6 LDAP authentication with means that both the client and the server establish a SASL session using the SASL library. Then authentication (bind) requests are sent to the LDAP server through the SASL authentication daemon ( saslauthd ) that acts as a remote proxy for the mongod server. The following components are necessary for external authentication to work: LDAP Server : Remotely stores all user credentials (i.e. user name and associated password). SASL Daemon : Used as a MongoDB server-local proxy for the remote LDAP service. SASL Library : Used by the MongoDB client and server to create data necessary for the authentication mechanism. The following image illustrates this architecture: An authentication session uses the following sequence: A mongosh client connects to a running mongod instance. The client creates a PLAIN authentication request using the SASL library. The client then sends this SASL request to the server as a special mongo command. The mongod server receives this SASL message, with its authentication request payload. The server then creates a SASL session scoped to this client, using its own reference to the SASL library. Then the server passes the authentication payload to the SASL library, which in turn passes it on to the saslauthd daemon. The saslauthd daemon passes the payload on to the LDAP service to get a YES or NO authentication response (in other words, does this user exist and is the password correct). The YES/NO response moves back from saslauthd , through the SASL library, to mongod . The mongod server uses this YES/NO response to authenticate the client or reject the request. If successful, the client has authenticated and can proceed. For configuration instructions, refer to Setting up LDAP authentication with SASL . Kerberos Authentication \u00b6 Percona Server for MongoDB supports Kerberos authentication starting from release 6.0.2-1. This authentication mechanism involves the use of a Key Distribution Center (KDC) - a symmetric encryption component which operates with tickets. A ticket is a small amount of encrypted data which is used for authentication. It is issued for a user session and has a limited lifetime. When using Kerberos authentication, you also operate with principals and realms. A realm is the logical network, similar to a domain, for all Kerberos nodes under the same master KDC. A principal is a user or a service which is known to Kerberos. A principal name is used for authentication in Kerberos. A service principal represents the service, e.g. mongodb . A user principal represents the user. The user principal name corresponds to the username in the $external database in Percona Server for MongoDB. The following diagram shows the authentication workflow: The sequence is the following: A mongo client sends the Ticket-Grantng Ticket (TGT) request to the Key Distribution Center (KDC) The KDC issues the ticket and sends it to the mongo client. The mongo client sends the authentication request to the mongod server presenting the ticket. The mongod server validates the ticket in the KDC. Upon successful ticket validation, the authentication request is approved and the user is authenticated. Kerberos authentication in Percona Server for MongoDB is implemented the same way as in MongoDB Enterprise. See also MongoDB Documentation: Kerberos Authentication","title":"Authentication"},{"location":"authentication.html#authentication","text":"Authentication is the process of verifying a client\u2019s identity. Normally, a client needs to authenticate themselves against the MongoDB server user database before doing any work or reading any data from a mongod or mongos instance. By default, Percona Server for MongoDB provides a SCRAM authentication mechanism where clients authenticate themselves by providing their user credentials. In addition, you can integrate Percona Server for MongoDB with a separate service, such as OpenLDAP or Active Directory. This enables users to access the database with the same credentials they use for their emails or workstations. You can use any of these authentication mechanisms supported in Percona Server for MongoDB: SCRAM (default) x.509 certificate authentication LDAP authentication with SASL Kerberos Authentication Authentication and authorization with direct binding to LDAP","title":"Authentication"},{"location":"authentication.html#scram","text":"SCRAM is the default authentication mechanism. Percona Server for MongoDB verifies the credentials against the user\u2019s name, password and the database where the user record is created for a client (authentication database). For how to enable this mechanism, see Enabling Authentication .","title":"SCRAM"},{"location":"authentication.html#x509-certificate-authentication","text":"This authentication mechanism enables a client to authenticate in Percona Server for MongoDB by providing an x.509 certificate instead of user credentials. Each certificate contains the subject field defined in the format. In Percona Server for MongoDB, each certificate has a corresponding user record in the $external database. When a user connects to the database, Percona Server for MongoDB matches the subject value against the usernames defined in the $external database. For production use, we recommend using valid certificates. For testing purposes, you can generate and use self-signed certificates. x.509 authentication is compatible with with LDAP authorization to enable you to control user access and operations in Percona Server for MongoDB. For configuration guidelines, refer to Set up x.509 authentication and LDAP authorization . See also MongoDB Documentation: x.509 Percona Blog: Setting up MongoDB with Member x509 auth and SSL + easy-rsa","title":"x.509 certificate authentication"},{"location":"authentication.html#ldap-authentication-with-sasl","text":"","title":"LDAP authentication with SASL"},{"location":"authentication.html#overview","text":"LDAP authentication with means that both the client and the server establish a SASL session using the SASL library. Then authentication (bind) requests are sent to the LDAP server through the SASL authentication daemon ( saslauthd ) that acts as a remote proxy for the mongod server. The following components are necessary for external authentication to work: LDAP Server : Remotely stores all user credentials (i.e. user name and associated password). SASL Daemon : Used as a MongoDB server-local proxy for the remote LDAP service. SASL Library : Used by the MongoDB client and server to create data necessary for the authentication mechanism. The following image illustrates this architecture: An authentication session uses the following sequence: A mongosh client connects to a running mongod instance. The client creates a PLAIN authentication request using the SASL library. The client then sends this SASL request to the server as a special mongo command. The mongod server receives this SASL message, with its authentication request payload. The server then creates a SASL session scoped to this client, using its own reference to the SASL library. Then the server passes the authentication payload to the SASL library, which in turn passes it on to the saslauthd daemon. The saslauthd daemon passes the payload on to the LDAP service to get a YES or NO authentication response (in other words, does this user exist and is the password correct). The YES/NO response moves back from saslauthd , through the SASL library, to mongod . The mongod server uses this YES/NO response to authenticate the client or reject the request. If successful, the client has authenticated and can proceed. For configuration instructions, refer to Setting up LDAP authentication with SASL .","title":"Overview"},{"location":"authentication.html#kerberos-authentication","text":"Percona Server for MongoDB supports Kerberos authentication starting from release 6.0.2-1. This authentication mechanism involves the use of a Key Distribution Center (KDC) - a symmetric encryption component which operates with tickets. A ticket is a small amount of encrypted data which is used for authentication. It is issued for a user session and has a limited lifetime. When using Kerberos authentication, you also operate with principals and realms. A realm is the logical network, similar to a domain, for all Kerberos nodes under the same master KDC. A principal is a user or a service which is known to Kerberos. A principal name is used for authentication in Kerberos. A service principal represents the service, e.g. mongodb . A user principal represents the user. The user principal name corresponds to the username in the $external database in Percona Server for MongoDB. The following diagram shows the authentication workflow: The sequence is the following: A mongo client sends the Ticket-Grantng Ticket (TGT) request to the Key Distribution Center (KDC) The KDC issues the ticket and sends it to the mongo client. The mongo client sends the authentication request to the mongod server presenting the ticket. The mongod server validates the ticket in the KDC. Upon successful ticket validation, the authentication request is approved and the user is authenticated. Kerberos authentication in Percona Server for MongoDB is implemented the same way as in MongoDB Enterprise. See also MongoDB Documentation: Kerberos Authentication","title":"Kerberos Authentication"},{"location":"authorization.html","text":"LDAP authorization \u00b6 LDAP authorization allows you to control user access and operations in your database environment using the centralized user management storage \u2013 an LDAP server. You create and manage user credentials and permission information in the LDAP server. In addition, you create roles in the admin database with the names that exactly match the LDAP group Distinguished Name. These roles define what privileges the users who belong to the corresponding LDAP group. Supported authentication mechanisms \u00b6 LDAP authorization is compatible with the following authentication mechanisms: x.509 certificate authentication Kerberos Authentication Authentication and authorization with direct binding to LDAP Authentication and authorization with direct binding to LDAP \u00b6 Starting with release 6.0.2-1, you can configure Percona Server for MongoDB to communicate with the LDAP server directly to authenticate and also authorize users. The advantage of using this mechanism is that it is easy to setup and does not require pre-creating users in the dummy $external database. Nevertheless, the --authenticationDatabase connection argument will still need to be specified as $external . The following example illustrates the connection to Percona Server for MongoDB from the mongosh shell: $ mongosh -u \"CN=alice,CN=Users,DC=engineering,DC=example,DC=com\" -p --authenticationDatabase '$external' --authenticationMechanism PLAIN The following diagram illustrates the authentication and authorization flow: A user connects to the database providing their credentials If required, Percona Server for MongoDB transforms the username to match the user in the LDAP server according to the mapping rules specified for the --ldapUserToDNMapping parameter. Percona Server for MongoDB queries the LDAP server for the user identity and/or the LDAP groups this user belongs to. The LDAP server evaluates the query and if a user exists, returns their LDAP groups. Percona Server for MongoDB authorizes the user by mapping the DN of the returned groups against the roles assigned to the user in the admin database. If a user belongs to several groups they receive permissions associated with every group. Username transformation \u00b6 If clients connect to Percona Server for MongoDB with usernames that are not LDAP DN , these usernames must be converted to the format acceptable by LDAP. To achieve this, the --ldapUserToDNMapping parameter is available in Percona Server for MongoDB configuration. The --ldapUserToDNMapping parameter is a JSON string representing an ordered array of rules expressed as JSON documents. Each document provides a regex pattern ( match field) to match against a provided username. If that pattern matches, there are two ways to continue: If there is the substitution value, then the matched pattern becomes the username of the user for further processing. If there is the ldapQuery value, the matched pattern is sent to the LDAP server and the result of that LDAP query becomes the DN of the user for further processing. Both substitution and ldapQuery should contain placeholders to insert parts of the original username \u2013 those placeholders are replaced with regular expression submatches found on the match stage. So having an array of documents, Percona Server for MongoDB tries to match each document against the provided name and if it matches, the name is replaced either with the substitution string or with the result of the LDAP query. LDAP referrals \u00b6 As of version 6.0.2-1, Percona Server for MongoDB supports LDAP referrals as defined in RFC 4511 4.1.10 . For security reasons, referrals are disabled by default. Double-check that using referrals is safe before enabling them. To enable LDAP referrals, set the ldapFollowReferrals server parameter to true using the setParameter command or by editing the configuration file. setParameter : ldapFollowReferrals : true Connection pool \u00b6 As of version 6.0.2-1, Percona Server for MongoDB always uses a connection pool to LDAP server to process bind requests. The connection pool is enabled by default. The default connection pool size is 2 connections. You can change the connection pool size either at the server startup or dynamically by specifying the value for the ldapConnectionPoolSizePerHost server parameter. For example, to set the number of connections in the pool to 5, use the setParameter command: Command line Configuration file > db . adminCommand ( { setParameter : 1 , ldapConnectionPoolSizePerHost : 5 } ) setParameter : ldapConnectionPoolSizePerHost : 5 Support for multiple LDAP servers \u00b6 As of version 6.0.2-1, you can specify multiple LDAP servers for failover. Percona Server for MongoDB sends bind requests to the first server defined in the list. When this server is down or unavailable, it sends requests to the next server and so on. Note that Percona Server for MongoDB keeps sending requests to this server even after the unavailable server recovers. Specify the LDAP servers as a comma-separated list in the format <host>:<port> for the \u2013ldapServers option. You can define the option value at the server startup by editing the configuration file. security : authorization : \"enabled\" ldap : servers : \"ldap1.example.net,ldap2.example.net\" You can change ldapServers dynamically at runtime using the setParameter . > db . adminCommand ( { setParameter : 1 , ldapServers : \"localhost,ldap1.example.net,ldap2.example.net\" } ) { \"was\" : \"ldap1.example.net,ldap2.example.net\" , \"ok\" : 1 } See also MongoDB Documentation: Authenticate and Authorize Users Using Active Directory via Native LDAP LDAP referrals Configuration \u00b6 For how to configure LDAP authorization with the native LDAP authentication, see Setting up LDAP authentication and authorization using NativeLDAP .","title":"LDAP authorization"},{"location":"authorization.html#ldap-authorization","text":"LDAP authorization allows you to control user access and operations in your database environment using the centralized user management storage \u2013 an LDAP server. You create and manage user credentials and permission information in the LDAP server. In addition, you create roles in the admin database with the names that exactly match the LDAP group Distinguished Name. These roles define what privileges the users who belong to the corresponding LDAP group.","title":"LDAP authorization"},{"location":"authorization.html#supported-authentication-mechanisms","text":"LDAP authorization is compatible with the following authentication mechanisms: x.509 certificate authentication Kerberos Authentication Authentication and authorization with direct binding to LDAP","title":"Supported authentication mechanisms"},{"location":"authorization.html#authentication-and-authorization-with-direct-binding-to-ldap","text":"Starting with release 6.0.2-1, you can configure Percona Server for MongoDB to communicate with the LDAP server directly to authenticate and also authorize users. The advantage of using this mechanism is that it is easy to setup and does not require pre-creating users in the dummy $external database. Nevertheless, the --authenticationDatabase connection argument will still need to be specified as $external . The following example illustrates the connection to Percona Server for MongoDB from the mongosh shell: $ mongosh -u \"CN=alice,CN=Users,DC=engineering,DC=example,DC=com\" -p --authenticationDatabase '$external' --authenticationMechanism PLAIN The following diagram illustrates the authentication and authorization flow: A user connects to the database providing their credentials If required, Percona Server for MongoDB transforms the username to match the user in the LDAP server according to the mapping rules specified for the --ldapUserToDNMapping parameter. Percona Server for MongoDB queries the LDAP server for the user identity and/or the LDAP groups this user belongs to. The LDAP server evaluates the query and if a user exists, returns their LDAP groups. Percona Server for MongoDB authorizes the user by mapping the DN of the returned groups against the roles assigned to the user in the admin database. If a user belongs to several groups they receive permissions associated with every group.","title":"Authentication and authorization with direct binding to LDAP"},{"location":"authorization.html#username-transformation","text":"If clients connect to Percona Server for MongoDB with usernames that are not LDAP DN , these usernames must be converted to the format acceptable by LDAP. To achieve this, the --ldapUserToDNMapping parameter is available in Percona Server for MongoDB configuration. The --ldapUserToDNMapping parameter is a JSON string representing an ordered array of rules expressed as JSON documents. Each document provides a regex pattern ( match field) to match against a provided username. If that pattern matches, there are two ways to continue: If there is the substitution value, then the matched pattern becomes the username of the user for further processing. If there is the ldapQuery value, the matched pattern is sent to the LDAP server and the result of that LDAP query becomes the DN of the user for further processing. Both substitution and ldapQuery should contain placeholders to insert parts of the original username \u2013 those placeholders are replaced with regular expression submatches found on the match stage. So having an array of documents, Percona Server for MongoDB tries to match each document against the provided name and if it matches, the name is replaced either with the substitution string or with the result of the LDAP query.","title":"Username transformation"},{"location":"authorization.html#ldap-referrals","text":"As of version 6.0.2-1, Percona Server for MongoDB supports LDAP referrals as defined in RFC 4511 4.1.10 . For security reasons, referrals are disabled by default. Double-check that using referrals is safe before enabling them. To enable LDAP referrals, set the ldapFollowReferrals server parameter to true using the setParameter command or by editing the configuration file. setParameter : ldapFollowReferrals : true","title":"LDAP referrals"},{"location":"authorization.html#connection-pool","text":"As of version 6.0.2-1, Percona Server for MongoDB always uses a connection pool to LDAP server to process bind requests. The connection pool is enabled by default. The default connection pool size is 2 connections. You can change the connection pool size either at the server startup or dynamically by specifying the value for the ldapConnectionPoolSizePerHost server parameter. For example, to set the number of connections in the pool to 5, use the setParameter command: Command line Configuration file > db . adminCommand ( { setParameter : 1 , ldapConnectionPoolSizePerHost : 5 } ) setParameter : ldapConnectionPoolSizePerHost : 5","title":"Connection pool"},{"location":"authorization.html#support-for-multiple-ldap-servers","text":"As of version 6.0.2-1, you can specify multiple LDAP servers for failover. Percona Server for MongoDB sends bind requests to the first server defined in the list. When this server is down or unavailable, it sends requests to the next server and so on. Note that Percona Server for MongoDB keeps sending requests to this server even after the unavailable server recovers. Specify the LDAP servers as a comma-separated list in the format <host>:<port> for the \u2013ldapServers option. You can define the option value at the server startup by editing the configuration file. security : authorization : \"enabled\" ldap : servers : \"ldap1.example.net,ldap2.example.net\" You can change ldapServers dynamically at runtime using the setParameter . > db . adminCommand ( { setParameter : 1 , ldapServers : \"localhost,ldap1.example.net,ldap2.example.net\" } ) { \"was\" : \"ldap1.example.net,ldap2.example.net\" , \"ok\" : 1 } See also MongoDB Documentation: Authenticate and Authorize Users Using Active Directory via Native LDAP LDAP referrals","title":"Support for multiple LDAP servers"},{"location":"authorization.html#configuration","text":"For how to configure LDAP authorization with the native LDAP authentication, see Setting up LDAP authentication and authorization using NativeLDAP .","title":"Configuration"},{"location":"backup-cursor.html","text":"$backupCursor and $backupCursorExtend aggregation stages \u00b6 $backupCursor and $backupCursorExtend aggregation stages expose the WiredTiger API which allows making consistent backups. Running these stages allows listing and freezing the files so you can copy them without the files being deleted or necessary parts within them being overwritten. $backupCursor outputs the list of files and their size to copy. $backupCursorExtend outputs the list of WiredTiger transaction log files that have been updated or newly added since the $backupCursor was first run. Saving these files enables restoring the database to any arbitrary time between the $backupCursor and $backupCursorExtend execution times. They are available in Percona Server for MongoDB starting with version 6.0.2-1. Percona provides Percona Backup for MongoDB (PBM) \u2013 a light-weight open source solution for consistent backups and restores across sharded clusters. PBM relies on these aggregation stages for physical backups and restores. However, if you wish to develop your own backup application, this document describes the $backupCursor and $backupCursorExtend aggregation stages. Usage \u00b6 You can run these stages in any type of MongoDB deployment. If you need to back up a single node in a replica set, first run the $backupCursor , then the $backupCursorExtend and save the output files to the backup storage. To make a consistent backup of a sharded cluster, run both aggregation stages on one node from each shard and the config server replica set. It can be either the primary or the secondary node. Note that since the secondary node may lag in syncing the data from the primary one, you will have to wait for the exact same time before running the $backupCursorExtend . Note that for standalone MongoDB node with disabled oplogs, you can only run the $backupCursor aggregation stage. Get a list of all files to copy with $backupCursor \u00b6 var bkCsr = db . getSiblingDB ( \"admin\" ). aggregate ([{ $backupCursor : {}}]) bkCsrMetadata = bkCsr . next (). metadata Sample output: [ { metadata: { backupId: UUID(\"35c34101-0107-44cf-bdec-fad285e07534\"), dbpath: '/var/lib/mongodb', oplogStart: { ts: Timestamp({ t: 1666631297, i: 1 }), t: Long(\"-1\") }, oplogEnd: { ts: Timestamp({ t: 1666631408, i: 1 }), t: Long(\"1\") }, checkpointTimestamp: Timestamp({ t: 1666631348, i: 1 }) } }, Store the metadata document somewhere, because you need to pass the backupId parameter from this document as the input parameter for the $backupCursorExtend stage. Also you need the oplogEnd timestamp. Make sure that the $backupCursor is complete on all shards in your cluster. Note Note that when running $backupCursor in a standalone node deployment, oplogStart , oplogEnd , checkpointTimesatmp values may be absent. This is because standalone node deployments don\u2019t have oplogs. Run $backupCursorExtend to retrieve the WiredTiger transaction logs \u00b6 Pass the backupId from the metadata document as the first parameter. For the timestamp parameter, use the maximum (latest) value among the oplogEnd timestamps from all shards and config server replica set. This will be the target time to restore. var bkExtCsr = db . aggregate ([{ $backupCursorExtend : { backupId : bkCsrMetadata . backupId , timestamp : new Timestamp ( 1666631418 , 1 )}}]) Sample output: { \"filename\" : \"/data/plain_rs/n1/data/journal/WiredTigerLog.0000000042\" } { \"filename\" : \"/data/plain_rs/n1/data/journal/WiredTigerLog.0000000043\" } { \"filename\" : \"/data/plain_rs/n1/data/journal/WiredTigerLog.0000000044\" } Loop the $backupCursor \u00b6 Prevent the backup cursor from closing on timeout (default \u2013 10 minutes). This is crucial since it prevents overwriting backup snapshot file blocks with new ones if the files take longer than 10 minutes to copy. Use the getMore command for this purpose. Copy the files to the storage \u00b6 Now you can copy the output of both aggregation stages to your backup storage. After the backup is copied to the storage, terminate the getMore command and close the cursor. Note Save the timestamp that you passed for the $backupCursorExtend stage somewhere since you will need it for the restore. This document is based on the blog post Experimental Feature: $backupCursorExtend in Percona Server for MongoDB by Akira Kurogane","title":"$backupCursor and $backupCursorExtend aggregation stages"},{"location":"backup-cursor.html#backupcursor-and-backupcursorextend-aggregation-stages","text":"$backupCursor and $backupCursorExtend aggregation stages expose the WiredTiger API which allows making consistent backups. Running these stages allows listing and freezing the files so you can copy them without the files being deleted or necessary parts within them being overwritten. $backupCursor outputs the list of files and their size to copy. $backupCursorExtend outputs the list of WiredTiger transaction log files that have been updated or newly added since the $backupCursor was first run. Saving these files enables restoring the database to any arbitrary time between the $backupCursor and $backupCursorExtend execution times. They are available in Percona Server for MongoDB starting with version 6.0.2-1. Percona provides Percona Backup for MongoDB (PBM) \u2013 a light-weight open source solution for consistent backups and restores across sharded clusters. PBM relies on these aggregation stages for physical backups and restores. However, if you wish to develop your own backup application, this document describes the $backupCursor and $backupCursorExtend aggregation stages.","title":"$backupCursor and $backupCursorExtend aggregation stages"},{"location":"backup-cursor.html#usage","text":"You can run these stages in any type of MongoDB deployment. If you need to back up a single node in a replica set, first run the $backupCursor , then the $backupCursorExtend and save the output files to the backup storage. To make a consistent backup of a sharded cluster, run both aggregation stages on one node from each shard and the config server replica set. It can be either the primary or the secondary node. Note that since the secondary node may lag in syncing the data from the primary one, you will have to wait for the exact same time before running the $backupCursorExtend . Note that for standalone MongoDB node with disabled oplogs, you can only run the $backupCursor aggregation stage.","title":"Usage"},{"location":"backup-cursor.html#get-a-list-of-all-files-to-copy-with-backupcursor","text":"var bkCsr = db . getSiblingDB ( \"admin\" ). aggregate ([{ $backupCursor : {}}]) bkCsrMetadata = bkCsr . next (). metadata Sample output: [ { metadata: { backupId: UUID(\"35c34101-0107-44cf-bdec-fad285e07534\"), dbpath: '/var/lib/mongodb', oplogStart: { ts: Timestamp({ t: 1666631297, i: 1 }), t: Long(\"-1\") }, oplogEnd: { ts: Timestamp({ t: 1666631408, i: 1 }), t: Long(\"1\") }, checkpointTimestamp: Timestamp({ t: 1666631348, i: 1 }) } }, Store the metadata document somewhere, because you need to pass the backupId parameter from this document as the input parameter for the $backupCursorExtend stage. Also you need the oplogEnd timestamp. Make sure that the $backupCursor is complete on all shards in your cluster. Note Note that when running $backupCursor in a standalone node deployment, oplogStart , oplogEnd , checkpointTimesatmp values may be absent. This is because standalone node deployments don\u2019t have oplogs.","title":"Get a list of all files to copy with $backupCursor"},{"location":"backup-cursor.html#run-backupcursorextend-to-retrieve-the-wiredtiger-transaction-logs","text":"Pass the backupId from the metadata document as the first parameter. For the timestamp parameter, use the maximum (latest) value among the oplogEnd timestamps from all shards and config server replica set. This will be the target time to restore. var bkExtCsr = db . aggregate ([{ $backupCursorExtend : { backupId : bkCsrMetadata . backupId , timestamp : new Timestamp ( 1666631418 , 1 )}}]) Sample output: { \"filename\" : \"/data/plain_rs/n1/data/journal/WiredTigerLog.0000000042\" } { \"filename\" : \"/data/plain_rs/n1/data/journal/WiredTigerLog.0000000043\" } { \"filename\" : \"/data/plain_rs/n1/data/journal/WiredTigerLog.0000000044\" }","title":"Run $backupCursorExtend to retrieve the WiredTiger transaction logs"},{"location":"backup-cursor.html#loop-the-backupcursor","text":"Prevent the backup cursor from closing on timeout (default \u2013 10 minutes). This is crucial since it prevents overwriting backup snapshot file blocks with new ones if the files take longer than 10 minutes to copy. Use the getMore command for this purpose.","title":"Loop the $backupCursor"},{"location":"backup-cursor.html#copy-the-files-to-the-storage","text":"Now you can copy the output of both aggregation stages to your backup storage. After the backup is copied to the storage, terminate the getMore command and close the cursor. Note Save the timestamp that you passed for the $backupCursorExtend stage somewhere since you will need it for the restore. This document is based on the blog post Experimental Feature: $backupCursorExtend in Percona Server for MongoDB by Akira Kurogane","title":"Copy the files to the storage"},{"location":"comparison.html","text":"Percona Server for MongoDB feature comparison \u00b6 Percona Server for MongoDB 6.0 is based on MongoDB 6.0 . Percona Server for MongoDB extends MongoDB Community Edition to include the functionality that is otherwise only available in MongoDB Enterprise Edition. PSMDB MongoDB Storage Engines - WiredTiger (default) - Percona Memory Engine - WiredTiger (default) - In-Memory (Enterprise only) Encryption-at-Rest - Key servers = Hashicorp Vault , KMIP - Fully open source - Key server = KMIP - Enterprise only Hot Backup YES (replica set) NO LDAP Authentication (legacy) LDAP authentication with SASL Enterprise only LDAP Authorization YES Enterprise only Kerberos Authentication YES Enterprise only Audit Logging YES Enterprise only Log redaction YES Enterprise only SNMP Monitoring NO Enterprise only Database profiler YES with the --rateLimit argument YES Profiling Rate Limiting \u00b6 Profiling Rate Limiting was added to Percona Server for MongoDB in v3.4 with the --rateLimit argument. Since v3.6, MongoDB Community (and Enterprise) Edition includes a similar option slowOpSampleRate . Please see Profiling Rate Limit for more information.","title":"Percona Server for MongoDB feature comparison"},{"location":"comparison.html#percona-server-for-mongodb-feature-comparison","text":"Percona Server for MongoDB 6.0 is based on MongoDB 6.0 . Percona Server for MongoDB extends MongoDB Community Edition to include the functionality that is otherwise only available in MongoDB Enterprise Edition. PSMDB MongoDB Storage Engines - WiredTiger (default) - Percona Memory Engine - WiredTiger (default) - In-Memory (Enterprise only) Encryption-at-Rest - Key servers = Hashicorp Vault , KMIP - Fully open source - Key server = KMIP - Enterprise only Hot Backup YES (replica set) NO LDAP Authentication (legacy) LDAP authentication with SASL Enterprise only LDAP Authorization YES Enterprise only Kerberos Authentication YES Enterprise only Audit Logging YES Enterprise only Log redaction YES Enterprise only SNMP Monitoring NO Enterprise only Database profiler YES with the --rateLimit argument YES","title":"Percona Server for MongoDB feature comparison"},{"location":"comparison.html#profiling-rate-limiting","text":"Profiling Rate Limiting was added to Percona Server for MongoDB in v3.4 with the --rateLimit argument. Since v3.6, MongoDB Community (and Enterprise) Edition includes a similar option slowOpSampleRate . Please see Profiling Rate Limit for more information.","title":"Profiling Rate Limiting"},{"location":"copyright.html","text":"Copyright and Licensing Information \u00b6 Documentation Licensing \u00b6 This software documentation is (C)2016-2022 Percona LLC and/or its affiliates and is distributed under the Creative Commons Attribution 4.0 International License . Software License \u00b6 Percona Server for MongoDB is source-available software .","title":"Copyright and Licensing"},{"location":"copyright.html#copyright-and-licensing-information","text":"","title":"Copyright and Licensing Information"},{"location":"copyright.html#documentation-licensing","text":"This software documentation is (C)2016-2022 Percona LLC and/or its affiliates and is distributed under the Creative Commons Attribution 4.0 International License .","title":"Documentation Licensing"},{"location":"copyright.html#software-license","text":"Percona Server for MongoDB is source-available software .","title":"Software License"},{"location":"data-at-rest-encryption.html","text":"Data at rest encryption \u00b6 Data at rest encryption for the WiredTiger storage engine in MongoDB was introduced in MongoDB Enterprise version 3.2 to ensure that encrypted data files can be decrypted and read by parties with the decryption key. Differences from upstream \u00b6 The data encryption at rest in Percona Server for MongoDB is introduced in version 3.6 to be compatible with data encryption at rest interface in MongoDB. In the current release of Percona Server for MongoDB, the data encryption at rest does not include support for Amazon AWS key management service. Instead, Percona Server for MongoDB is integrated with HashiCorp Vault . Starting with release 6.0.2-1, Percona Server for MongoDB supports the secure transfer of keys using Key Management Interoperability Protocol (KMIP) . This allows users to store encryption keys in their favorite KMIP-compatible key manager when they set up encryption at rest. Two types of keys are used for data at rest encryption: Database keys to encrypt data. They are stored internally, near the data that they encrypt. The master key to encrypt database keys. It is kept separately from the data and database keys and requires external management. To manage the master key, use one of the supported key management options: Integration with an external key server (recommended). Percona Server for MongoDB is integrated with HashiCorp Vault for this purpose and supports the secure transfer of keys using Key Management Interoperability Protocol (KMIP) . Local key management using a keyfile . Note that you can use only one of the key management options at a time. However, you can switch from one management option to another (e.g. from a keyfile to HashiCorp Vault). Refer to Migrating from Key File Encryption to HashiCorp Vault Encryption section for details. Important You can only enable data at rest encryption and provide all encryption settings on an empty database, when you start the mongod instance for the first time. You cannot enable or disable encryption while the Percona Server for MongoDB server is already running and / or has some data. Nor can you change the effective encryption mode by simply restarting the server. Every time you restart the server, the encryption settings must be the same. Important configuration options \u00b6 Percona Server for MongoDB supports the encryptionCipherMode option where you choose one of the following cipher modes: AES256-CBC AES256-GCM By default, the AES256-CBC cipher mode is applied. The following example demonstrates how to apply the AES256-GCM cipher mode when starting the mongod service: $ mongod ... --encryptionCipherMode AES256-GCM See also MongoDB Documentation: encryptionCipherMode Option Encrypting Rollback Files \u00b6 Starting from version 3.6, Percona Server for MongoDB also encrypts rollback files when data at rest encryption is enabled. To inspect the contents of these files, use perconadecrypt . This is a tool that you run from the command line as follows: $ perconadecrypt --encryptionKeyFile FILE --inputPath FILE --outputPath FILE [ --encryptionCipherMode MODE ] When decrypting, the cipher mode must match the cipher mode which was used for the encryption. By default, the --encryptionCipherMode option uses the AES256-CBC mode. Parameters of perconadecrypt \u00b6 Option Purpose \u2013-encryptionKeyFile The path to the encryption key file --encryptionCipherMode The cipher mode for decryption. The supported values are AES256-CBC or AES256-GCM --inputPath The path to the encrypted rollback file --outputPath The path to save the decrypted rollback file","title":"Data at rest encryption"},{"location":"data-at-rest-encryption.html#data-at-rest-encryption","text":"Data at rest encryption for the WiredTiger storage engine in MongoDB was introduced in MongoDB Enterprise version 3.2 to ensure that encrypted data files can be decrypted and read by parties with the decryption key.","title":"Data at rest encryption"},{"location":"data-at-rest-encryption.html#differences-from-upstream","text":"The data encryption at rest in Percona Server for MongoDB is introduced in version 3.6 to be compatible with data encryption at rest interface in MongoDB. In the current release of Percona Server for MongoDB, the data encryption at rest does not include support for Amazon AWS key management service. Instead, Percona Server for MongoDB is integrated with HashiCorp Vault . Starting with release 6.0.2-1, Percona Server for MongoDB supports the secure transfer of keys using Key Management Interoperability Protocol (KMIP) . This allows users to store encryption keys in their favorite KMIP-compatible key manager when they set up encryption at rest. Two types of keys are used for data at rest encryption: Database keys to encrypt data. They are stored internally, near the data that they encrypt. The master key to encrypt database keys. It is kept separately from the data and database keys and requires external management. To manage the master key, use one of the supported key management options: Integration with an external key server (recommended). Percona Server for MongoDB is integrated with HashiCorp Vault for this purpose and supports the secure transfer of keys using Key Management Interoperability Protocol (KMIP) . Local key management using a keyfile . Note that you can use only one of the key management options at a time. However, you can switch from one management option to another (e.g. from a keyfile to HashiCorp Vault). Refer to Migrating from Key File Encryption to HashiCorp Vault Encryption section for details. Important You can only enable data at rest encryption and provide all encryption settings on an empty database, when you start the mongod instance for the first time. You cannot enable or disable encryption while the Percona Server for MongoDB server is already running and / or has some data. Nor can you change the effective encryption mode by simply restarting the server. Every time you restart the server, the encryption settings must be the same.","title":"Differences from upstream"},{"location":"data-at-rest-encryption.html#important-configuration-options","text":"Percona Server for MongoDB supports the encryptionCipherMode option where you choose one of the following cipher modes: AES256-CBC AES256-GCM By default, the AES256-CBC cipher mode is applied. The following example demonstrates how to apply the AES256-GCM cipher mode when starting the mongod service: $ mongod ... --encryptionCipherMode AES256-GCM See also MongoDB Documentation: encryptionCipherMode Option","title":"Important configuration options"},{"location":"data-at-rest-encryption.html#encrypting-rollback-files","text":"Starting from version 3.6, Percona Server for MongoDB also encrypts rollback files when data at rest encryption is enabled. To inspect the contents of these files, use perconadecrypt . This is a tool that you run from the command line as follows: $ perconadecrypt --encryptionKeyFile FILE --inputPath FILE --outputPath FILE [ --encryptionCipherMode MODE ] When decrypting, the cipher mode must match the cipher mode which was used for the encryption. By default, the --encryptionCipherMode option uses the AES256-CBC mode.","title":"Encrypting Rollback Files"},{"location":"data-at-rest-encryption.html#parameters-of-perconadecrypt","text":"Option Purpose \u2013-encryptionKeyFile The path to the encryption key file --encryptionCipherMode The cipher mode for decryption. The supported values are AES256-CBC or AES256-GCM --inputPath The path to the encrypted rollback file --outputPath The path to save the decrypted rollback file","title":"Parameters of perconadecrypt"},{"location":"enable-auth.html","text":"Enabling authentication \u00b6 By default, Percona Server for MongoDB does not restrict access to data and configuration. Enabling authentication enforces users to identify themselves when accessing the database. This documents describes how to enable built-in authentication mechanism. Percona Server for MongoDB also supports the number of external authentication mechanisms. To learn more, refer to Authentication . You can enable authentication either automatically or manually. Automatic setup \u00b6 To enable authentication and automatically set it up, run the /usr/bin/percona-server-mongodb-enable-auth.sh script as root or using sudo . This script creates the dba user with the root role. The password is randomly generated and printed out in the output. Then the script restarts Percona Server for MongoDB with access control enabled. The dba user has full superuser privileges on the server. You can add other users with various roles depending on your needs. For usage information, run the script with the -h option. Manual setup \u00b6 To enable access control manually: Add the following lines to the configuration file: security : authorization : enabled Run the following command on the admin database: > db . createUser ({ user : 'USER' , pwd : 'PASSWORD' , roles : [ 'root' ] }); Restart the mongod service: $ service mongod restart Connect to the database as the newly created user: $ mongosh --port 27017 -u 'USER' -p 'PASSWORD' --authenticationDatabase \"admin\" See also MongoDB Documentation: Enable Access Control","title":"Enabling authentication"},{"location":"enable-auth.html#enabling-authentication","text":"By default, Percona Server for MongoDB does not restrict access to data and configuration. Enabling authentication enforces users to identify themselves when accessing the database. This documents describes how to enable built-in authentication mechanism. Percona Server for MongoDB also supports the number of external authentication mechanisms. To learn more, refer to Authentication . You can enable authentication either automatically or manually.","title":"Enabling authentication"},{"location":"enable-auth.html#automatic-setup","text":"To enable authentication and automatically set it up, run the /usr/bin/percona-server-mongodb-enable-auth.sh script as root or using sudo . This script creates the dba user with the root role. The password is randomly generated and printed out in the output. Then the script restarts Percona Server for MongoDB with access control enabled. The dba user has full superuser privileges on the server. You can add other users with various roles depending on your needs. For usage information, run the script with the -h option.","title":"Automatic setup"},{"location":"enable-auth.html#manual-setup","text":"To enable access control manually: Add the following lines to the configuration file: security : authorization : enabled Run the following command on the admin database: > db . createUser ({ user : 'USER' , pwd : 'PASSWORD' , roles : [ 'root' ] }); Restart the mongod service: $ service mongod restart Connect to the database as the newly created user: $ mongosh --port 27017 -u 'USER' -p 'PASSWORD' --authenticationDatabase \"admin\" See also MongoDB Documentation: Enable Access Control","title":"Manual setup"},{"location":"encryption-mode-switch.html","text":"Migrate from key file encryption to HashiCorp Vault encryption \u00b6 The steps below describe how to migrate from the key file encryption to using HashiCorp Vault. Note This is a simple guideline and it should be used for testing purposes only. We recommend to contact Percona Consulting Services to assist you with migration in production environment. Assumptions \u00b6 We assume that you have installed and configured the vault server and enabled the KV Secrets Engine as the secrets storage for it. Stop mongod . $ sudo systemctl stop mongod Insert the key from keyfile into the HashiCorp Vault server to the desired secret path. Retrieve the key value from the keyfile $ sudo cat /data/key/mongodb.key d0JTFcePmvROyLXwCbAH8fmiP/ZRm0nYbeJDMGaI7Zw = Insert the key into vault $ vault kv put secret/dc/psmongodb1 value = d0JTFcePmvROyLXwCbAH8fmiP/ZRm0nYbeJDMGaI7Zw = !!! note Vault KV Secrets Engine uses different read and write secrets paths. To insert data to Vault, specify the secret path without the `data/` prefix. Edit the configuration file to provision the HashiCorp Vault configuration options instead of the key file encryption options. security : enableEncryption : true vault : serverName : 10.0.2.15 port : 8200 secret : secret/data/dc/psmongodb1 tokenFile : /etc/mongodb/token serverCAFile : /etc/mongodb/vault.crt Start the mongod service $ sudo systemctl start mongod","title":"Migrate from key file encryption to HashiCorp Vault encryption"},{"location":"encryption-mode-switch.html#migrate-from-key-file-encryption-to-hashicorp-vault-encryption","text":"The steps below describe how to migrate from the key file encryption to using HashiCorp Vault. Note This is a simple guideline and it should be used for testing purposes only. We recommend to contact Percona Consulting Services to assist you with migration in production environment.","title":"Migrate from key file encryption to HashiCorp Vault encryption"},{"location":"encryption-mode-switch.html#assumptions","text":"We assume that you have installed and configured the vault server and enabled the KV Secrets Engine as the secrets storage for it. Stop mongod . $ sudo systemctl stop mongod Insert the key from keyfile into the HashiCorp Vault server to the desired secret path. Retrieve the key value from the keyfile $ sudo cat /data/key/mongodb.key d0JTFcePmvROyLXwCbAH8fmiP/ZRm0nYbeJDMGaI7Zw = Insert the key into vault $ vault kv put secret/dc/psmongodb1 value = d0JTFcePmvROyLXwCbAH8fmiP/ZRm0nYbeJDMGaI7Zw = !!! note Vault KV Secrets Engine uses different read and write secrets paths. To insert data to Vault, specify the secret path without the `data/` prefix. Edit the configuration file to provision the HashiCorp Vault configuration options instead of the key file encryption options. security : enableEncryption : true vault : serverName : 10.0.2.15 port : 8200 secret : secret/data/dc/psmongodb1 tokenFile : /etc/mongodb/token serverCAFile : /etc/mongodb/vault.crt Start the mongod service $ sudo systemctl start mongod","title":"Assumptions"},{"location":"glossary.html","text":"Glossary \u00b6 ACID \u00b6 Set of properties that guarantee database transactions are processed reliably. Stands for Atomicity , Consistency , Isolation , Durability . Atomicity \u00b6 Atomicity means that database operations are applied following a \u201call or nothing\u201d rule. A transaction is either fully applied or not at all. Consistency \u00b6 Consistency means that each transaction that modifies the database takes it from one consistent state to another. Durability \u00b6 Once a transaction is committed, it will remain so. Foreign Key \u00b6 A referential constraint between two tables. Example: A purchase order in the purchase_orders table must have been made by a customer that exists in the customers table. Isolation \u00b6 The Isolation requirement means that no transaction can interfere with another. Jenkins \u00b6 Jenkins is a continuous integration system that we use to help ensure the continued quality of the software we produce. It helps us achieve the aims of: no failed tests in trunk on any platform, aid developers in ensuring merge requests build and test on all platforms, no known performance regressions (without a damn good explanation). Kerberos \u00b6 Kerberos is an authentication protocol for client/server authentication without sending the passwords over an insecure network. Kerberos uses symmetric encryption in the form of tickets - small pieces of encrypted data used for authentication. A ticket is issued for the client and validated by the server. Rolling restart \u00b6 A rolling restart (rolling upgrade) is shutting down and upgrading nodes one by one. The whole cluster remains operational. There is no interruption to clients assuming the elections are short and all writes directed to the old primary use the retryWrite mechanism.# Glossary","title":"Glossary"},{"location":"glossary.html#glossary","text":"","title":"Glossary"},{"location":"glossary.html#acid","text":"Set of properties that guarantee database transactions are processed reliably. Stands for Atomicity , Consistency , Isolation , Durability .","title":"ACID"},{"location":"glossary.html#atomicity","text":"Atomicity means that database operations are applied following a \u201call or nothing\u201d rule. A transaction is either fully applied or not at all.","title":"Atomicity"},{"location":"glossary.html#consistency","text":"Consistency means that each transaction that modifies the database takes it from one consistent state to another.","title":"Consistency"},{"location":"glossary.html#durability","text":"Once a transaction is committed, it will remain so.","title":"Durability"},{"location":"glossary.html#foreign-key","text":"A referential constraint between two tables. Example: A purchase order in the purchase_orders table must have been made by a customer that exists in the customers table.","title":"Foreign Key"},{"location":"glossary.html#isolation","text":"The Isolation requirement means that no transaction can interfere with another.","title":"Isolation"},{"location":"glossary.html#jenkins","text":"Jenkins is a continuous integration system that we use to help ensure the continued quality of the software we produce. It helps us achieve the aims of: no failed tests in trunk on any platform, aid developers in ensuring merge requests build and test on all platforms, no known performance regressions (without a damn good explanation).","title":"Jenkins"},{"location":"glossary.html#kerberos","text":"Kerberos is an authentication protocol for client/server authentication without sending the passwords over an insecure network. Kerberos uses symmetric encryption in the form of tickets - small pieces of encrypted data used for authentication. A ticket is issued for the client and validated by the server.","title":"Kerberos"},{"location":"glossary.html#rolling-restart","text":"A rolling restart (rolling upgrade) is shutting down and upgrading nodes one by one. The whole cluster remains operational. There is no interruption to clients assuming the elections are short and all writes directed to the old primary use the retryWrite mechanism.# Glossary","title":"Rolling restart"},{"location":"hot-backup.html","text":"Hot Backup \u00b6 Percona Server for MongoDB includes an integrated open source hot backup system for the default WiredTiger storage engine. It creates a physical data backup on a running server without notable performance and operating degradation. Note Hot backups are done on mongod servers independently, without synchronizing them across replica set members and shards in a cluster. To ensure data consistency during backups and restores, we recommend using Percona Backup for MongoDB . Make a backup \u00b6 To take a hot backup of the database in your current dbpath , do the following: Provide access to the backup directory for the mongod user: $ sudo chown mongod:mongod <backupDir> Run the createBackup command as administrator on the admin database and specify the backup directory. > use admin switched to db admin > db . runCommand ({ createBackup : 1 , backupDir : \"<backup_data_path>\" }) { \"ok\" : 1 } The backup taken is the snapshot of the mongod server\u2019s dataDir at the moment of the createBackup command start. If the backup was successful, you should receive an { \"ok\" : 1 } object. If there was an error, you will receive a failing ok status with the error message, for example: > db . runCommand ({ createBackup : 1 , backupDir : \"\" }) { \"ok\" : 0 , \"errmsg\" : \"Destination path must be absolute\" } Save a backup to a TAR archive \u00b6 To save a backup as a tar archive, use the archive field to specify the destination path: > use admin ... > db . runCommand ({ createBackup : 1 , archive : < path_to_archive > . tar }) Streaming hot backups to a remote destination \u00b6 Percona Server for MongoDB enables uploading hot backups to an Amazon S3 or a compatible storage service, such as MinIO . This method requires that you provide the bucket field in the s3 object: > use admin ... > db . runCommand ({ createBackup : 1 , s3 : { bucket : \"backup20190510\" , path : < some_optional_path > } }) In addition to the mandatory bucket field, the s3 object may contain the following fields: Field Type Description bucket string The only mandatory field. Names are subject to restrictions described in the Bucket Restrictions and Limitations section of Amazon S3 documentation path string The virtual path inside the specified bucket where the backup will be created. If the path is not specified, then the backup is created in the root of the bucket. If there are any objects under the specified path, the backup will not be created and an error will be reported. endpoint string The endpoint address and port - mainly for AWS S3 compatible servers such as the MinIO server. For a local MinIO server, this can be \u201c127.0.0.1:9000\u201d. For AWS S3 this field can be omitted. scheme string \u201cHTTP\u201d or \u201cHTTPS\u201d (default). For a local MinIO server started with the minio server command this should field should contain HTTP . useVirtualAddressing bool The style of addressing buckets in the URL. By default \u2018true\u2019. For MinIO servers, set this field to false . For more information, see Virtual Hosting of Buckets in the Amazon S3 documentation. region string The name of an AWS region. The default region is US_EAST_1 . For more information see AWS Service Endpoints in the Amazon S3 documentation. profile string The name of a credentials profile in the credentials configuration file. If not specified, the profile named default is used. accessKeyId string The access key id secretAccessKey string The secret access key Credentials \u00b6 If the user provides the access key id and the secret access key parameters, these are used as credentials. If the access key id parameter is not specified then the credentials are loaded from the credentials configuration file. By default, it is ~/.aws/credentials . Example credentials file \u00b6 [default] aws_access_key_id = ABC123XYZ456QQQAAAFFF aws_secret_access_key = zuf+secretkey0secretkey1secretkey2 [localminio] aws_access_key_id = ABCABCABCABC55566678 aws_secret_access_key = secretaccesskey1secretaccesskey2secretaccesskey3 Examples \u00b6 Backup in root of bucket on local instance of MinIO server > db . runCommand ({ createBackup : 1 , s3 : { bucket : \"backup20190901500\" , scheme : \"HTTP\" , endpoint : \"127.0.0.1:9000\" , useVirtualAddressing : false , profile : \"localminio\" }}) Backup on MinIO testing server with the default credentials profile The following command creates a backup under the virtual path \u201cyear2019/day42\u201d in the backup bucket: > db . runCommand ({ createBackup : 1 , s3 : { bucket : \"backup\" , path : \"year2019/day42\" , endpoint : \"sandbox.min.io:9000\" , useVirtualAddressing : false }}) Backup on AWS S3 service using default settings > db . runCommand ({ createBackup : 1 , s3 : { bucket : \"backup\" , path : \"year2019/day42\" }}) See also AWS Documentation: Providing AWS Credentials Restoring data from backup \u00b6 Restoring from backup on a standalone server \u00b6 To restore your database on a standalone server, stop the mongod service, clean out the data directory and copy files from the backup directory to the data directory. The mongod user requires access to those files to start the service. Therefore, make the mongod user the owner of the data directory and all files and subdirectories under it, and restart the mongod service. Note If you try to restore the node into the existing replica set and there is more recent data, the restored node detects that it is out of date with the other replica set members, deletes the data and makes an initial sync. Run the following commands as root or by using the sudo command Stop the mongod service $ systemctl stop mongod Clean out the data directory $ rm -rf /var/lib/mongodb/* Copy backup files $ cp -RT <backup_data_path> /var/lib/mongodb/ Grant permissions to data files for the mongod user $ chown -R mongod:mongod /var/lib/mongodb/ Start the mongod service $ systemctl start mongod Restoring from backup in a replica set \u00b6 The recommended way to restore the replica set from a backup is to restore it into a standalone node and then initiate it as the first member of a new replica set. Note If you try to restore the node into the existing replica set and there is more recent data, the restored node detects that it is out of date with the other replica set members, deletes the data and makes an initial sync. Run the following commands as root or by using the sudo command Stop the mongod service: $ systemctl stop mongod Clean the data directory and then copy the files from the backup directory to your data directory. Assuming that the data directory is /var/lib/mongodb/ , use the following commands: $ rm -rf /var/lib/mongodb/* $ cp -RT <backup_data_path> /var/lib/mongodb/ Grant permissions to the data files for the mongod user $ chown -R mongod:mongod /var/lib/mongodb/ Make sure the replication is disabled in the config file and start the mongod service. $ systemctl start mongod Connect to your standalone node via the mongo shell and drop the local database > mongo > use local > db . dropDatabase () Restart the node with the replication enabled Shut down the node. $ systemctl stop mongod Edit the configuration file and specify the replication.replSetname option Start the mongod node: $ systemctl start mongod Initiate a new replica set # Start the mongosh shell > mongosh # Initiate a new replica set > rs . initiate ()","title":"Hot Backup"},{"location":"hot-backup.html#hot-backup","text":"Percona Server for MongoDB includes an integrated open source hot backup system for the default WiredTiger storage engine. It creates a physical data backup on a running server without notable performance and operating degradation. Note Hot backups are done on mongod servers independently, without synchronizing them across replica set members and shards in a cluster. To ensure data consistency during backups and restores, we recommend using Percona Backup for MongoDB .","title":"Hot Backup"},{"location":"hot-backup.html#make-a-backup","text":"To take a hot backup of the database in your current dbpath , do the following: Provide access to the backup directory for the mongod user: $ sudo chown mongod:mongod <backupDir> Run the createBackup command as administrator on the admin database and specify the backup directory. > use admin switched to db admin > db . runCommand ({ createBackup : 1 , backupDir : \"<backup_data_path>\" }) { \"ok\" : 1 } The backup taken is the snapshot of the mongod server\u2019s dataDir at the moment of the createBackup command start. If the backup was successful, you should receive an { \"ok\" : 1 } object. If there was an error, you will receive a failing ok status with the error message, for example: > db . runCommand ({ createBackup : 1 , backupDir : \"\" }) { \"ok\" : 0 , \"errmsg\" : \"Destination path must be absolute\" }","title":"Make a backup"},{"location":"hot-backup.html#save-a-backup-to-a-tar-archive","text":"To save a backup as a tar archive, use the archive field to specify the destination path: > use admin ... > db . runCommand ({ createBackup : 1 , archive : < path_to_archive > . tar })","title":"Save a backup to a TAR archive"},{"location":"hot-backup.html#streaming-hot-backups-to-a-remote-destination","text":"Percona Server for MongoDB enables uploading hot backups to an Amazon S3 or a compatible storage service, such as MinIO . This method requires that you provide the bucket field in the s3 object: > use admin ... > db . runCommand ({ createBackup : 1 , s3 : { bucket : \"backup20190510\" , path : < some_optional_path > } }) In addition to the mandatory bucket field, the s3 object may contain the following fields: Field Type Description bucket string The only mandatory field. Names are subject to restrictions described in the Bucket Restrictions and Limitations section of Amazon S3 documentation path string The virtual path inside the specified bucket where the backup will be created. If the path is not specified, then the backup is created in the root of the bucket. If there are any objects under the specified path, the backup will not be created and an error will be reported. endpoint string The endpoint address and port - mainly for AWS S3 compatible servers such as the MinIO server. For a local MinIO server, this can be \u201c127.0.0.1:9000\u201d. For AWS S3 this field can be omitted. scheme string \u201cHTTP\u201d or \u201cHTTPS\u201d (default). For a local MinIO server started with the minio server command this should field should contain HTTP . useVirtualAddressing bool The style of addressing buckets in the URL. By default \u2018true\u2019. For MinIO servers, set this field to false . For more information, see Virtual Hosting of Buckets in the Amazon S3 documentation. region string The name of an AWS region. The default region is US_EAST_1 . For more information see AWS Service Endpoints in the Amazon S3 documentation. profile string The name of a credentials profile in the credentials configuration file. If not specified, the profile named default is used. accessKeyId string The access key id secretAccessKey string The secret access key","title":"Streaming hot backups to a remote destination"},{"location":"hot-backup.html#credentials","text":"If the user provides the access key id and the secret access key parameters, these are used as credentials. If the access key id parameter is not specified then the credentials are loaded from the credentials configuration file. By default, it is ~/.aws/credentials .","title":"Credentials"},{"location":"hot-backup.html#examples","text":"Backup in root of bucket on local instance of MinIO server > db . runCommand ({ createBackup : 1 , s3 : { bucket : \"backup20190901500\" , scheme : \"HTTP\" , endpoint : \"127.0.0.1:9000\" , useVirtualAddressing : false , profile : \"localminio\" }}) Backup on MinIO testing server with the default credentials profile The following command creates a backup under the virtual path \u201cyear2019/day42\u201d in the backup bucket: > db . runCommand ({ createBackup : 1 , s3 : { bucket : \"backup\" , path : \"year2019/day42\" , endpoint : \"sandbox.min.io:9000\" , useVirtualAddressing : false }}) Backup on AWS S3 service using default settings > db . runCommand ({ createBackup : 1 , s3 : { bucket : \"backup\" , path : \"year2019/day42\" }}) See also AWS Documentation: Providing AWS Credentials","title":"Examples"},{"location":"hot-backup.html#restoring-data-from-backup","text":"","title":"Restoring data from backup"},{"location":"hot-backup.html#restoring-from-backup-on-a-standalone-server","text":"To restore your database on a standalone server, stop the mongod service, clean out the data directory and copy files from the backup directory to the data directory. The mongod user requires access to those files to start the service. Therefore, make the mongod user the owner of the data directory and all files and subdirectories under it, and restart the mongod service. Note If you try to restore the node into the existing replica set and there is more recent data, the restored node detects that it is out of date with the other replica set members, deletes the data and makes an initial sync. Run the following commands as root or by using the sudo command Stop the mongod service $ systemctl stop mongod Clean out the data directory $ rm -rf /var/lib/mongodb/* Copy backup files $ cp -RT <backup_data_path> /var/lib/mongodb/ Grant permissions to data files for the mongod user $ chown -R mongod:mongod /var/lib/mongodb/ Start the mongod service $ systemctl start mongod","title":"Restoring from backup on a standalone server"},{"location":"hot-backup.html#restoring-from-backup-in-a-replica-set","text":"The recommended way to restore the replica set from a backup is to restore it into a standalone node and then initiate it as the first member of a new replica set. Note If you try to restore the node into the existing replica set and there is more recent data, the restored node detects that it is out of date with the other replica set members, deletes the data and makes an initial sync. Run the following commands as root or by using the sudo command Stop the mongod service: $ systemctl stop mongod Clean the data directory and then copy the files from the backup directory to your data directory. Assuming that the data directory is /var/lib/mongodb/ , use the following commands: $ rm -rf /var/lib/mongodb/* $ cp -RT <backup_data_path> /var/lib/mongodb/ Grant permissions to the data files for the mongod user $ chown -R mongod:mongod /var/lib/mongodb/ Make sure the replication is disabled in the config file and start the mongod service. $ systemctl start mongod Connect to your standalone node via the mongo shell and drop the local database > mongo > use local > db . dropDatabase () Restart the node with the replication enabled Shut down the node. $ systemctl stop mongod Edit the configuration file and specify the replication.replSetname option Start the mongod node: $ systemctl start mongod Initiate a new replica set # Start the mongosh shell > mongosh # Initiate a new replica set > rs . initiate ()","title":"Restoring from backup in a replica set"},{"location":"inmemory.html","text":"Percona Memory Engine \u00b6 Percona Memory Engine is a special configuration of WiredTiger that does not store user data on disk. Data fully resides in the main memory, making processing much faster and smoother. Keep in mind that you need to have enough memory to hold the data set, and ensure that the server does not shut down. The Percona Memory Engine is available in Percona Server for MongoDB along with the default MongoDB engine WiredTiger . Usage \u00b6 As of version 3.2, Percona Server for MongoDB runs with WiredTiger by default. You can select a storage engine using the --storageEngine command-line option when you start mongod . Alternatively, you can set the storage.engine variable in the configuration file (by default, /etc/mongod.conf ): storage : dbPath : <dataDir> engine : inMemory Configuration \u00b6 You can configure Percona Memory Engine using either command-line options or corresponding parameters in the /etc/mongod.conf file. The following are the configuration examples: Configuration file Command line The configuration file is formatted in YAML storage : engine : inMemory inMemory : engineConfig : inMemorySizeGB : 140 statisticsLogDelaySecs : 0 Setting parameters in the configuration file is the same as starting the mongod daemon with the following options: mongod --storageEngine = inMemory \\ --inMemorySizeGB = 140 \\ --inMemoryStatisticsLogDelaySecs = 0 Options \u00b6 The following options are available (with corresponding YAML configuration file parameters): Command line Configuration file Default Description --inMemorySizeGB() storage.inMemory.engineConfig.inMemorySizeGB 50% of total memory minus 1024 MB, but not less than 256 MB Specifies the maximum memory in gigabytes to use for data --inMemoryStatisticsLogDelaySecs() storage.inMemory.engineConfig.statisticsLogDelaySecs 0 Specifies the number of seconds between writes to statistics log. If 0 is specified then statistics are not logged Switching storage engines \u00b6 Considerations \u00b6 If you have data files in your database and want to change to Percona Memory Engine, consider the following: Data files created by one storage engine are not compatible with other engines, because each one has its own data model. When changing the storage engine, the mongod node requires an empty dbPath data directory when it is restarted. Though Percona Memory Engine stores all data in memory, some metadata files, diagnostics logs and statistics metrics are still written to disk. This is controlled with the --inMemoryStatisticsLogDelaySecs option. Creating a new dbPath data directory for a different storage engine is the simplest solution. Yet when you switch between disk-using storage engines (e.g. from WiredTiger to Percona Memory Engine), you may have to delete the old data if there is not enough disk space for both. Double-check that your backups are solid and/or the replica set nodes are healthy before you switch to the new storage engine. Procedure \u00b6 To change a storage engine, you have the following options: Temporarily test Percona Memory Engine \u00b6 Set a different data directory for the dbPath variable in the configuration file. Make sure that the user running mongod has read and write permissions for the new data directory. Stop mongod $ service mongod stop Edit the configuration file storage : dbPath : <newDataDir> engine : inmemory Start mongod $ service mongod start Permanent switch to Percona Memory Engine without any valuable data in your database \u00b6 Clean out the dbPath data directory (by default, /var/lib/mongodb ) and edit the configuration file: Stop mongod $ service mongod stop Clean out the dbPath data directory $ sudo rm -rf <dbpathDataDir> Edit the configuration file storage : dbPath : <newDataDir> engine : inmemory Start mongod $ service mongod start Switch to Percona Memory Engine with data migration and compatibility \u00b6 Standalone instance Replica set For a standalone instance or a single-node replica set, use the mongodump and mongorestore utilities: Export the dataDir contents $ mongodump --out <dumpDir> Stop mongod $ service mongod stop Clean out the dbPath data directory $ sudo rm -rf <dbpathDataDir> Update the configuration file by setting the new value for the storage.engine variable. Set the engine-specific settings such as storage.inMemory.engineConfig.inMemorySizeGB Start mongod $ service mongod start Restore the database $ mongorestore <dumpDir> Use the \u201crolling restart\u201d process. Switch to the Percona Memory Engine on the secondary node. Clean out the dbPath data directory and edit the configuration file: Stop mongod $ service mongod stop Clean out the dbPath data directory $ sudo rm -rf <dbpathDataDir> Edit the configuration file storage : dbPath : <newDataDir> engine : inmemory Start mongod $ service mongod start Wait for the node to rejoin with the other nodes and report the SECONDARY status. Repeat the procedure to switch the remaining nodes to Percona Memory Engine. Data at rest encryption \u00b6 Using Data at Rest Encryption means using the same storage.\\* configuration options as for WiredTiger . To change from normal to Data at Rest Encryption mode or backward, you must clean up the dbPath data directory, just as if you change the storage engine. This is because mongod cannot convert the data files to an encrypted format \u2018in place\u2019. It must get the document data again either via the initial sync from another replica set member, or from imported backup dump. Percona memory engine \u00b6 Percona memory engine is a special configuration of WiredTiger that does not store user data on disk. Data fully resides in the main memory, making processing much faster and smoother. Keep in mind that you need to have enough memory to hold the data set, and ensure that the server does not shut down. The Percona Memory Engine is available in Percona Server for MongoDB along with the default MongoDB engine WiredTiger . Using Percona Memory Engine \u00b6 As of version 3.2, Percona Server for MongoDB runs with WiredTiger by default. You can select a storage engine using the --storageEngine command-line option when you start mongod . Alternatively, you can set the storage.engine variable in the configuration file (by default, /etc/mongod.conf ): storage : dbPath : <dataDir> engine : inMemory Switching storage engines \u00b6 Considerations \u00b6 If you have data files in your database and want to change to Percona Memory Engine, consider the following: Data files created by one storage engine are not compatible with other engines, because each one has its own data model. When changing the storage engine, the mongod node requires an empty dbPath data directory when it is restarted. Though Percona Memory Engine stores all data in memory, some metadata files, diagnostics logs and statistics metrics are still written to disk. This is controlled with the --inMemoryStatisticsLogDelaySecs option. Creating a new dbPath data directory for a different storage engine is the simplest solution. Yet when you switch between disk-using storage engines (e.g. from WiredTiger to Percona Memory Engine), you may have to delete the old data if there is not enough disk space for both. Double-check that your backups are solid and/or the replica set nodes are healthy before you switch to the new storage engine. Procedure \u00b6 To change a storage engine, you have the following options: If you simply want to temporarily test Percona Memory Engine, set a different data directory for the dbPath variable in the configuration file. Make sure that the user running mongod has read and write permissions for the new data directory. $ service mongod stop $ # In the configuration file, set the inmemory $ # value for the storage.engine variable $ # Set the <newDataDir> for the dbPath variable $ service mongod start If you want to permanently switch to Percona Memory Engine and do not have any valuable data in your database, clean out the dbPath data directory (by default, /var/lib/mongodb ) and edit the configuration file: $ service mongod stop $ rm -rf <dbpathDataDir> $ # Update the configuration file by setting the new $ # value for the storage.engine variable $ # set the engine-specific settings such as $ # storage.inMemory.engineConfig.inMemorySizeGB $ service mongod start If there is data that you want to migrate and make compatible with Percona Memory Engine, use the following methods: for replica sets, use the \u201crolling restart\u201d process. Switch to the Percona Memory Engine on the secondary node. Clean out the dbPath data directory and edit the configuration file: $ service mongod stop $ rm -rf <dbpathDataDir> $ # Update the configuration file by setting the new $ # value for the storage.engine variable $ # set the engine-specific settings such as $ # storage.inMemory.engineConfig.inMemorySizeGB $ service mongod start Wait for the node to rejoin with the other nodes and report the SECONDARY status. Repeat the procedure to switch the remaining nodes to Percona Memory Engine. * for a standalone instance or a single-node replica set, use the `mongodump` and `mongorestore` utilities: $ mongodump --out <dumpDir> $ service mongod stop $ rm -rf <dbpathDataDir> $ # Update the configuration file by setting the new $ # value for the storage.engine variable $ # set the engine-specific settings such as $ # storage.inMemory.engineConfig.inMemorySizeGB $ service mongod start $ mongorestore <dumpDir> Switching engines with encrypted data \u00b6 Using Data at Rest Encryption means using the same storage.\\* configuration options as for WiredTiger . To change from normal to Data at Rest Encryption mode or backward, you must clean up the dbPath data directory, just as if you change the storage engine. This is because mongod cannot convert the data files to an encrypted format \u2018in place\u2019. It must get the document data again either via the initial sync from another replica set member, or from imported backup dump. Configuring Percona Memory Engine \u00b6 You can configure the Percona Memory Engine using either command-line options or corresponding parameters in the /etc/mongod.conf file. The configuration file is formatted in YAML. For example: storage : engine : inMemory inMemory : engineConfig : inMemorySizeGB : 140 statisticsLogDelaySecs : 0 Setting parameters in the previous example configuration file is the same as starting the mongod daemon with the following options: $ mongod --storageEngine = inMemory \\ --inMemorySizeGB = 140 \\ --inMemoryStatisticsLogDelaySecs = 0 The following options are available (with corresponding YAML configuration file parameters): \u2013inMemorySizeGB() \u00b6 Config storage.inMemory.engineConfig.inMemorySizeGB Default 50% of total memory minus 1024 MB, but not less than 256 MB Specifies the maximum memory in gigabytes to use for data. \u2013inMemoryStatisticsLogDelaySecs() \u00b6 Config storage.inMemory.engineConfig.statisticsLogDelaySecs Default 0 Specifies the number of seconds between writes to statistics log. If 0 is specified then statistics are not logged.","title":"Percona Memory Engine"},{"location":"inmemory.html#percona-memory-engine","text":"Percona Memory Engine is a special configuration of WiredTiger that does not store user data on disk. Data fully resides in the main memory, making processing much faster and smoother. Keep in mind that you need to have enough memory to hold the data set, and ensure that the server does not shut down. The Percona Memory Engine is available in Percona Server for MongoDB along with the default MongoDB engine WiredTiger .","title":"Percona Memory Engine"},{"location":"inmemory.html#usage","text":"As of version 3.2, Percona Server for MongoDB runs with WiredTiger by default. You can select a storage engine using the --storageEngine command-line option when you start mongod . Alternatively, you can set the storage.engine variable in the configuration file (by default, /etc/mongod.conf ): storage : dbPath : <dataDir> engine : inMemory","title":"Usage"},{"location":"inmemory.html#configuration","text":"You can configure Percona Memory Engine using either command-line options or corresponding parameters in the /etc/mongod.conf file. The following are the configuration examples: Configuration file Command line The configuration file is formatted in YAML storage : engine : inMemory inMemory : engineConfig : inMemorySizeGB : 140 statisticsLogDelaySecs : 0 Setting parameters in the configuration file is the same as starting the mongod daemon with the following options: mongod --storageEngine = inMemory \\ --inMemorySizeGB = 140 \\ --inMemoryStatisticsLogDelaySecs = 0","title":"Configuration"},{"location":"inmemory.html#options","text":"The following options are available (with corresponding YAML configuration file parameters): Command line Configuration file Default Description --inMemorySizeGB() storage.inMemory.engineConfig.inMemorySizeGB 50% of total memory minus 1024 MB, but not less than 256 MB Specifies the maximum memory in gigabytes to use for data --inMemoryStatisticsLogDelaySecs() storage.inMemory.engineConfig.statisticsLogDelaySecs 0 Specifies the number of seconds between writes to statistics log. If 0 is specified then statistics are not logged","title":"Options"},{"location":"inmemory.html#switching-storage-engines","text":"","title":"Switching storage engines"},{"location":"inmemory.html#considerations","text":"If you have data files in your database and want to change to Percona Memory Engine, consider the following: Data files created by one storage engine are not compatible with other engines, because each one has its own data model. When changing the storage engine, the mongod node requires an empty dbPath data directory when it is restarted. Though Percona Memory Engine stores all data in memory, some metadata files, diagnostics logs and statistics metrics are still written to disk. This is controlled with the --inMemoryStatisticsLogDelaySecs option. Creating a new dbPath data directory for a different storage engine is the simplest solution. Yet when you switch between disk-using storage engines (e.g. from WiredTiger to Percona Memory Engine), you may have to delete the old data if there is not enough disk space for both. Double-check that your backups are solid and/or the replica set nodes are healthy before you switch to the new storage engine.","title":"Considerations"},{"location":"inmemory.html#procedure","text":"To change a storage engine, you have the following options:","title":"Procedure"},{"location":"inmemory.html#data-at-rest-encryption","text":"Using Data at Rest Encryption means using the same storage.\\* configuration options as for WiredTiger . To change from normal to Data at Rest Encryption mode or backward, you must clean up the dbPath data directory, just as if you change the storage engine. This is because mongod cannot convert the data files to an encrypted format \u2018in place\u2019. It must get the document data again either via the initial sync from another replica set member, or from imported backup dump.","title":"Data at rest encryption"},{"location":"inmemory.html#percona-memory-engine_1","text":"Percona memory engine is a special configuration of WiredTiger that does not store user data on disk. Data fully resides in the main memory, making processing much faster and smoother. Keep in mind that you need to have enough memory to hold the data set, and ensure that the server does not shut down. The Percona Memory Engine is available in Percona Server for MongoDB along with the default MongoDB engine WiredTiger .","title":"Percona memory engine"},{"location":"inmemory.html#using-percona-memory-engine","text":"As of version 3.2, Percona Server for MongoDB runs with WiredTiger by default. You can select a storage engine using the --storageEngine command-line option when you start mongod . Alternatively, you can set the storage.engine variable in the configuration file (by default, /etc/mongod.conf ): storage : dbPath : <dataDir> engine : inMemory","title":"Using Percona Memory Engine"},{"location":"inmemory.html#switching-storage-engines_1","text":"","title":"Switching storage engines"},{"location":"inmemory.html#considerations_1","text":"If you have data files in your database and want to change to Percona Memory Engine, consider the following: Data files created by one storage engine are not compatible with other engines, because each one has its own data model. When changing the storage engine, the mongod node requires an empty dbPath data directory when it is restarted. Though Percona Memory Engine stores all data in memory, some metadata files, diagnostics logs and statistics metrics are still written to disk. This is controlled with the --inMemoryStatisticsLogDelaySecs option. Creating a new dbPath data directory for a different storage engine is the simplest solution. Yet when you switch between disk-using storage engines (e.g. from WiredTiger to Percona Memory Engine), you may have to delete the old data if there is not enough disk space for both. Double-check that your backups are solid and/or the replica set nodes are healthy before you switch to the new storage engine.","title":"Considerations"},{"location":"inmemory.html#procedure_1","text":"To change a storage engine, you have the following options: If you simply want to temporarily test Percona Memory Engine, set a different data directory for the dbPath variable in the configuration file. Make sure that the user running mongod has read and write permissions for the new data directory. $ service mongod stop $ # In the configuration file, set the inmemory $ # value for the storage.engine variable $ # Set the <newDataDir> for the dbPath variable $ service mongod start If you want to permanently switch to Percona Memory Engine and do not have any valuable data in your database, clean out the dbPath data directory (by default, /var/lib/mongodb ) and edit the configuration file: $ service mongod stop $ rm -rf <dbpathDataDir> $ # Update the configuration file by setting the new $ # value for the storage.engine variable $ # set the engine-specific settings such as $ # storage.inMemory.engineConfig.inMemorySizeGB $ service mongod start If there is data that you want to migrate and make compatible with Percona Memory Engine, use the following methods: for replica sets, use the \u201crolling restart\u201d process. Switch to the Percona Memory Engine on the secondary node. Clean out the dbPath data directory and edit the configuration file: $ service mongod stop $ rm -rf <dbpathDataDir> $ # Update the configuration file by setting the new $ # value for the storage.engine variable $ # set the engine-specific settings such as $ # storage.inMemory.engineConfig.inMemorySizeGB $ service mongod start Wait for the node to rejoin with the other nodes and report the SECONDARY status. Repeat the procedure to switch the remaining nodes to Percona Memory Engine. * for a standalone instance or a single-node replica set, use the `mongodump` and `mongorestore` utilities: $ mongodump --out <dumpDir> $ service mongod stop $ rm -rf <dbpathDataDir> $ # Update the configuration file by setting the new $ # value for the storage.engine variable $ # set the engine-specific settings such as $ # storage.inMemory.engineConfig.inMemorySizeGB $ service mongod start $ mongorestore <dumpDir>","title":"Procedure"},{"location":"inmemory.html#switching-engines-with-encrypted-data","text":"Using Data at Rest Encryption means using the same storage.\\* configuration options as for WiredTiger . To change from normal to Data at Rest Encryption mode or backward, you must clean up the dbPath data directory, just as if you change the storage engine. This is because mongod cannot convert the data files to an encrypted format \u2018in place\u2019. It must get the document data again either via the initial sync from another replica set member, or from imported backup dump.","title":"Switching engines with encrypted data"},{"location":"inmemory.html#configuring-percona-memory-engine","text":"You can configure the Percona Memory Engine using either command-line options or corresponding parameters in the /etc/mongod.conf file. The configuration file is formatted in YAML. For example: storage : engine : inMemory inMemory : engineConfig : inMemorySizeGB : 140 statisticsLogDelaySecs : 0 Setting parameters in the previous example configuration file is the same as starting the mongod daemon with the following options: $ mongod --storageEngine = inMemory \\ --inMemorySizeGB = 140 \\ --inMemoryStatisticsLogDelaySecs = 0 The following options are available (with corresponding YAML configuration file parameters):","title":"Configuring Percona Memory Engine"},{"location":"inmemory.html#-inmemorysizegb","text":"Config storage.inMemory.engineConfig.inMemorySizeGB Default 50% of total memory minus 1024 MB, but not less than 256 MB Specifies the maximum memory in gigabytes to use for data.","title":"--inMemorySizeGB()"},{"location":"inmemory.html#-inmemorystatisticslogdelaysecs","text":"Config storage.inMemory.engineConfig.statisticsLogDelaySecs Default 0 Specifies the number of seconds between writes to statistics log. If 0 is specified then statistics are not logged.","title":"--inMemoryStatisticsLogDelaySecs()"},{"location":"kerberos.html","text":"Setting up Kerberos authentication \u00b6 This document provides configuration steps for setting up Kerberos Authentication in Percona Server for MongoDB. Assumptions \u00b6 The setup of the Kerberos server itself is out of scope of this document. Please refer to the Kerberos documentation for the installation and configuration steps relevant to your operation system. We assume that you have successfully completed the following steps: Installed and configured the Kerberos server Added necessary realms Added service, admin and user principals Configured the A and PTR DNS records for every host running mongod instance to resolve the hostnames onto Kerberos realm. Add user principals to Percona Server for MongoDB \u00b6 To get authenticated, users must exist both in the Kerberos and Percona Server for MongoDB servers with exactly matching names. After you defined the user principals in the Kerberos server, add them to the $external database in Percona Server for MongoDB and assign required roles: > use $external > db . createUser ({ user : \"demo@PERCONATEST.COM\" , roles : [{ role : \"read\" , db : \"admin\" }]}) Replace demo@PERCONATEST.COM with your username and Kerberos realm. Configure Kerberos keytab files \u00b6 A keytab file stores the authentication keys for a service principal representing a mongod instance to access the Kerberos admin server. After you have added the service principal to the Kerberos admin server, the entry for this principal is added to the /etc/krb5.keytab keytab file. The mongod server must have access to the keytab file to authenticate. To keep the keytab file secure, restrict the access to it only for the user running the mongod process. Stop the mongod service $ sudo systemctl stop mongod Generate the keytab file or get a copy of it if you generated the keytab file on another host. Save the keyfile under a separate path (e.g. /etc/mongodb.keytab ) $ cp /etc/krb5.keytab /etc/mongodb.keytab Change the ownership to the keytab file $ sudo chown mongod:mongod /etc/mongodb.keytab Set the KRB5_KTNAME variable in the environment file for the mongod process. Debian and Ubuntu RHEL and derivatives Edit the environment file at the path /etc/default/mongod and specify the KRB5_KTNAME variable: KRB5_KTNAME=/etc/mongodb.keytab If you have a different path to the keytab file, specify it accordingly. Edit the environment file at the path /etc/sysconfig/mongod and specify the KRB5_KTNAME variable: KRB5_KTNAME=/etc/mongodb.keytab If you have a different path to the keytab file, specify it accordingly. Restart the mongod service $ sudo systemctl start mongod","title":"Setting up Kerberos authentication"},{"location":"kerberos.html#setting-up-kerberos-authentication","text":"This document provides configuration steps for setting up Kerberos Authentication in Percona Server for MongoDB.","title":"Setting up Kerberos authentication"},{"location":"kerberos.html#assumptions","text":"The setup of the Kerberos server itself is out of scope of this document. Please refer to the Kerberos documentation for the installation and configuration steps relevant to your operation system. We assume that you have successfully completed the following steps: Installed and configured the Kerberos server Added necessary realms Added service, admin and user principals Configured the A and PTR DNS records for every host running mongod instance to resolve the hostnames onto Kerberos realm.","title":"Assumptions"},{"location":"kerberos.html#add-user-principals-to-percona-server-for-mongodb","text":"To get authenticated, users must exist both in the Kerberos and Percona Server for MongoDB servers with exactly matching names. After you defined the user principals in the Kerberos server, add them to the $external database in Percona Server for MongoDB and assign required roles: > use $external > db . createUser ({ user : \"demo@PERCONATEST.COM\" , roles : [{ role : \"read\" , db : \"admin\" }]}) Replace demo@PERCONATEST.COM with your username and Kerberos realm.","title":"Add user principals to Percona Server for MongoDB"},{"location":"kerberos.html#configure-kerberos-keytab-files","text":"A keytab file stores the authentication keys for a service principal representing a mongod instance to access the Kerberos admin server. After you have added the service principal to the Kerberos admin server, the entry for this principal is added to the /etc/krb5.keytab keytab file. The mongod server must have access to the keytab file to authenticate. To keep the keytab file secure, restrict the access to it only for the user running the mongod process. Stop the mongod service $ sudo systemctl stop mongod Generate the keytab file or get a copy of it if you generated the keytab file on another host. Save the keyfile under a separate path (e.g. /etc/mongodb.keytab ) $ cp /etc/krb5.keytab /etc/mongodb.keytab Change the ownership to the keytab file $ sudo chown mongod:mongod /etc/mongodb.keytab Set the KRB5_KTNAME variable in the environment file for the mongod process. Debian and Ubuntu RHEL and derivatives Edit the environment file at the path /etc/default/mongod and specify the KRB5_KTNAME variable: KRB5_KTNAME=/etc/mongodb.keytab If you have a different path to the keytab file, specify it accordingly. Edit the environment file at the path /etc/sysconfig/mongod and specify the KRB5_KTNAME variable: KRB5_KTNAME=/etc/mongodb.keytab If you have a different path to the keytab file, specify it accordingly. Restart the mongod service $ sudo systemctl start mongod","title":"Configure Kerberos keytab files"},{"location":"keyfile.html","text":"Local key management using a keyfile \u00b6 The key file must contain a 32 character string encoded in base64. You can generate a random key and save it to a file by using the openssl command: $ openssl rand -base64 32 > mongodb-keyfile Then, as the owner of the mongod process, update the file permissions: only the owner should be able to read and modify this file. The effective permissions specified with the chmod command can be: 600 - only the owner may read and modify the file 400 - only the owner may read the file. $ chmod 600 mongodb-keyfile Enable the data encryption at rest in Percona Server for MongoDB by setting these options: --enableEncryption to enable data at rest encryption --encryptionKeyFile to specify the path to a file that contains the encryption key $ mongod ... --enableEncryption --encryptionKeyFile <fileName> By default, Percona Server for MongoDB uses the AES256-CBC cipher mode. If you want to use the AES256-GCM cipher mode, then use the --encryptionCipherMode parameter to change it. If mongod is started with the --relaxPermChecks option and the key file is owned by root , then mongod can read the file based on the group bit set accordingly. The effective key file permissions in this case are: 440 - both the owner and the group can only read the file, or 640 - only the owner can read and the change the file, the group can only read the file. All these options can be specified in the configuration file: security : enableEncryption : <boolean> encryptionCipherMode : <string> encryptionKeyFile : <string> relaxPermChecks : <boolean>","title":"Local key management using a keyfile"},{"location":"keyfile.html#local-key-management-using-a-keyfile","text":"The key file must contain a 32 character string encoded in base64. You can generate a random key and save it to a file by using the openssl command: $ openssl rand -base64 32 > mongodb-keyfile Then, as the owner of the mongod process, update the file permissions: only the owner should be able to read and modify this file. The effective permissions specified with the chmod command can be: 600 - only the owner may read and modify the file 400 - only the owner may read the file. $ chmod 600 mongodb-keyfile Enable the data encryption at rest in Percona Server for MongoDB by setting these options: --enableEncryption to enable data at rest encryption --encryptionKeyFile to specify the path to a file that contains the encryption key $ mongod ... --enableEncryption --encryptionKeyFile <fileName> By default, Percona Server for MongoDB uses the AES256-CBC cipher mode. If you want to use the AES256-GCM cipher mode, then use the --encryptionCipherMode parameter to change it. If mongod is started with the --relaxPermChecks option and the key file is owned by root , then mongod can read the file based on the group bit set accordingly. The effective key file permissions in this case are: 440 - both the owner and the group can only read the file, or 640 - only the owner can read and the change the file, the group can only read the file. All these options can be specified in the configuration file: security : enableEncryption : <boolean> encryptionCipherMode : <string> encryptionKeyFile : <string> relaxPermChecks : <boolean>","title":"Local key management using a keyfile"},{"location":"kmip.html","text":"Using the Key Management Interoperability Protocol (KMIP) \u00b6 Percona Server for MongoDB adds support for secure transfer of keys using the OASIS Key Management Interoperability Protocol (KMIP) . The KMIP implementation was tested with the PyKMIP server and the HashiCorp Vault Enterprise KMIP Secrets Engine . KMIP enables the communication between key management systems and the database server. KMIP provides the following benefits: Streamlines encryption key management Eliminates redundant key management processes You can specify multiple KMIP servers for failover. On startup, Percona Server for MongoDB connects to the servers in the order listed and selects the one with which the connection is successful. Starting with version 6.0.2-1, the kmipKeyIdentifier option is no longer mandatory. When left blank, the database server creates a key on the KMIP server and uses that for encryption. When you specify the identifier, the key with such an ID must exist on the key storage. KMIP parameters \u00b6 Option Type Description --kmipServerName string The hostname or IP address of the KMIP server. Multiple KMIP servers are supported as the comma-separated list, e.g. kmip1.example.com,kmip2.example.com --kmipPort number The port used to communicate with the KMIP server. When undefined, the default port 5696 will be used --kmipServerCAFile string The path to the CA certificate file. CA file is used to validate secure client connection to the KMIP server --kmipClientCertificateFile string The path to the PEM file with the KMIP client private key and the certificate chain. The database server uses this PEM file to authenticate the KMIP server --kmipKeyIdentifier string Optional. The identifier of the KMIP key. If the key does not exist, the database server creates a key on the KMIP server with the specified identifier. When you specify the identifier, the key with such an ID must exist on the key storage. You can only use this setting for the first time you enable encryption --kmipRotateMasterKey boolean Controls master keys rotation. When enabled, generates the new master key version and re-encrypts the keystore. Requires the unique --kmipKeyIdentifier for every mongod node --kmipClientCertificatePassword string The password for the KMIP client private key or certificate. Use this parameter only if the KMIP client private key or certificate is encrypted. Available starting with version 4.2.21-21 Key rotation \u00b6 Percona Server for MongoDB supports the master key rotation . This enables users to comply with data security regulations when using KMIP. Configuration \u00b6 Considerations \u00b6 Make sure you have obtained the root certificate, and the keypair for the KMIP server and the mongod client. For testing purposes you can use the OpenSSL to issue self-signed certificates. For production use we recommend you use the valid certificates issued by the key management appliance. To enable data-at-rest encryption in Percona Server for MongoDB using KMIP, edit the /etc/mongod.conf configuration file as follows: security : enableEncryption : true kmip : serverName : <kmip_server_name> port : <kmip_port> clientCertificateFile : </path/client_certificate.pem> serverCAFile : </path/ca.pem> keyIdentifier : <key_name> Alternatively, you can start Percona Server for MongoDB using the command line as follows: $ mongod --enableEncryption \\ --kmipServerName <kmip_servername> \\ --kmipPort <kmip_port> \\ --kmipServerCAFile <path_to_ca_file> \\ --kmipClientCertificateFile <path_to_client_certificate> \\ --kmipKeyIdentifier <kmip_identifier>","title":"Using the Key Management Interoperability Protocol (KMIP)"},{"location":"kmip.html#using-the-key-management-interoperability-protocol-kmip","text":"Percona Server for MongoDB adds support for secure transfer of keys using the OASIS Key Management Interoperability Protocol (KMIP) . The KMIP implementation was tested with the PyKMIP server and the HashiCorp Vault Enterprise KMIP Secrets Engine . KMIP enables the communication between key management systems and the database server. KMIP provides the following benefits: Streamlines encryption key management Eliminates redundant key management processes You can specify multiple KMIP servers for failover. On startup, Percona Server for MongoDB connects to the servers in the order listed and selects the one with which the connection is successful. Starting with version 6.0.2-1, the kmipKeyIdentifier option is no longer mandatory. When left blank, the database server creates a key on the KMIP server and uses that for encryption. When you specify the identifier, the key with such an ID must exist on the key storage.","title":"Using the Key Management Interoperability Protocol (KMIP)"},{"location":"kmip.html#kmip-parameters","text":"Option Type Description --kmipServerName string The hostname or IP address of the KMIP server. Multiple KMIP servers are supported as the comma-separated list, e.g. kmip1.example.com,kmip2.example.com --kmipPort number The port used to communicate with the KMIP server. When undefined, the default port 5696 will be used --kmipServerCAFile string The path to the CA certificate file. CA file is used to validate secure client connection to the KMIP server --kmipClientCertificateFile string The path to the PEM file with the KMIP client private key and the certificate chain. The database server uses this PEM file to authenticate the KMIP server --kmipKeyIdentifier string Optional. The identifier of the KMIP key. If the key does not exist, the database server creates a key on the KMIP server with the specified identifier. When you specify the identifier, the key with such an ID must exist on the key storage. You can only use this setting for the first time you enable encryption --kmipRotateMasterKey boolean Controls master keys rotation. When enabled, generates the new master key version and re-encrypts the keystore. Requires the unique --kmipKeyIdentifier for every mongod node --kmipClientCertificatePassword string The password for the KMIP client private key or certificate. Use this parameter only if the KMIP client private key or certificate is encrypted. Available starting with version 4.2.21-21","title":"KMIP parameters"},{"location":"kmip.html#key-rotation","text":"Percona Server for MongoDB supports the master key rotation . This enables users to comply with data security regulations when using KMIP.","title":"Key rotation"},{"location":"kmip.html#configuration","text":"","title":"Configuration"},{"location":"kmip.html#considerations","text":"Make sure you have obtained the root certificate, and the keypair for the KMIP server and the mongod client. For testing purposes you can use the OpenSSL to issue self-signed certificates. For production use we recommend you use the valid certificates issued by the key management appliance. To enable data-at-rest encryption in Percona Server for MongoDB using KMIP, edit the /etc/mongod.conf configuration file as follows: security : enableEncryption : true kmip : serverName : <kmip_server_name> port : <kmip_port> clientCertificateFile : </path/client_certificate.pem> serverCAFile : </path/ca.pem> keyIdentifier : <key_name> Alternatively, you can start Percona Server for MongoDB using the command line as follows: $ mongod --enableEncryption \\ --kmipServerName <kmip_servername> \\ --kmipPort <kmip_port> \\ --kmipServerCAFile <path_to_ca_file> \\ --kmipClientCertificateFile <path_to_client_certificate> \\ --kmipKeyIdentifier <kmip_identifier>","title":"Considerations"},{"location":"ldap-setup.html","text":"Set up LDAP authentication and authorization using NativeLDAP \u00b6 This document describes an example configuration of LDAP authentication and authorization using direct binding to an LDAP server (Native LDAP). We recommend testing this setup in a non-production environment first, before applying it in production. Assumptions \u00b6 The setup of an LDAP server is out of scope of this document. We assume that you are familiar with the LDAP server schema. You have the LDAP server up and running and it is accessible to the servers with Percona Server for MongoDB installed. This document primarily focuses on OpenLDAP used as the LDAP server and the examples are given based on the OpenLDAP format. If you are using Active Directory, refer to the Active Directory configuration section. You have the sudo privilege to the server with the Percona Server for MongoDB installed. Prerequisites \u00b6 In this setup we use anonymous binds to the LDAP server. If your LDAP server disallows anonymous binds, create the user that Percona Server for MongoDB will use to connect to and query the LDAP server. Define this user\u2019s credentials for the security.ldap.bind.queryUser and security.ldap.bind.queryPassword parameters in the mongod.conf configuration file. In this setup, we use the following OpenLDAP groups: dn: cn=testusers,dc=percona,dc=com objectClass: groupOfNames cn: testusers member: cn=alice,dc=percona,dc=com dn: cn=otherusers,dc=percona,dc=com objectClass: groupOfNames cn: otherusers member: cn=bob,dc=percona,dc=com Setup procedure \u00b6 Configure TLS/SSL connection for Percona Server for MongoDB \u00b6 By default, Percona Server for MongoDB establishes the TLS connection when binding to the LDAP server and thus, it requires access to the LDAP certificates. To make Percona Server for MongoDB aware of the certificates, do the following: Place the certificate in the certs directory. The path to the certs directory is: On Debian / Ubuntu: /etc/ssl/certs/ On RHEL / CentOS: /etc/openldap/certs/ Specify the path to the certificates in the ldap.conf file: Debian / Ubuntu RHEL and derivatives tee -a /etc/openldap/ldap.conf <<EOF TLS_CACERT /etc/ssl/certs/my_CA.crt EOF tee -a /etc/openldap/ldap.conf <<EOF TLS_CACERT /etc/openldap/certs/my_CA.crt EOF Create roles for LDAP groups in Percona Server for MongoDB \u00b6 Percona Server for MongoDB authorizes users based on LDAP group membership. For every group, you must create the role in the admin database with the name that exactly matches the of the LDAP group. Percona Server for MongoDB maps the user\u2019s LDAP group to the roles and determines what role is assigned to the user. Percona Server for MongoDB then grants privileges defined by this role. To create the roles, use the following command: var admin = db . getSiblingDB ( \"admin\" ) db . createRole ( { role : \"cn=testusers,dc=percona,dc=com\" , privileges : [], roles : [ \"readWrite\" ] } ) db . createRole ( { role : \"cn=otherusers,dc=percona,dc=com\" , privileges : [], roles : [ \"read\" ] } ) Percona Server for MongoDB configuration \u00b6 Access without username transformation \u00b6 This section assumes that users connect to Percona Server for MongoDB by providing their LDAP DN as the username. Edit the Percona Server for MongoDB configuration file (by default, /etc/mongod.conf ) and specify the following configuration: security : authorization : \"enabled\" ldap : servers : \"ldap.example.com\" transportSecurity : tls authz : queryTemplate : \"dc=percona,dc=com??sub?(&(objectClass=groupOfNames)(member={PROVIDED_USER}))\" setParameter : authenticationMechanisms : \"PLAIN\" The {PROVIDED_USER} variable substitutes the provided username before authentication or username transformation takes place. Replace ldap.example.com with the hostname of your LDAP server. In the LDAP query template, replace the domain controllers percona and com with those relevant to your organization. Restart the mongod service: $ sudo systemctl restart mongod Test the access to Percona Server for MongoDB: $ mongosh -u \"cn=alice,dc=percona,dc=com\" -p \"secretpwd\" --authenticationDatabase '$external' --authenticationMechanism 'PLAIN' Access with username transformation \u00b6 If users connect to Percona Server for MongoDB with usernames that are not LDAP , you need to transform these usernames to be accepted by the LDAP server. Using the --ldapUserToDNMapping configuration parameter allows you to do this. You specify the match pattern as a regexp to capture a username. Next, specify how to transform it - either to use a substitution value or to query the LDAP server for a username. If you don\u2019t know what the substitution or LDAP query string should be, please consult with the LDAP administrators to figure this out. Note that you can use only the query or the substitution stage, the combination of two is not allowed. Substitution LDAP query Edit the Percona Server for MongoDB configuration file (by default, /etc/mongod.conf ) and specify the userToDNMapping parameter: security : authorization : \"enabled\" ldap : servers : \"ldap.example.com\" transportSecurity : tls authz : queryTemplate : \"dc=percona,dc=com??sub?(&(objectClass=groupOfNames)(member={USER}))\" userToDNMapping : >- [ { match: \"([^@]+)@percona\\\\.com\", substitution: \"CN={0},DC=percona,DC=com\" } ] setParameter : authenticationMechanisms : \"PLAIN\" The {USER} variable substitutes the username transformed during the userToDNMapping stage. Modify the given example configuration to match your deployment. Restart the mongod service: $ sudo systemctl restart mongod Test the access to Percona Server for MongoDB: $ mongosh -u \"alice@percona.com\" -p \"secretpwd\" --authenticationDatabase '$external' --authenticationMechanism 'PLAIN' Edit the Percona Server for MongoDB configuration file (by default, /etc/mongod.conf ) and specify the userToDNMapping parameter: security : authorization : \"enabled\" ldap : servers : \"ldap.example.com\" transportSecurity : tls authz : queryTemplate : \"dc=percona,dc=com??sub?(&(objectClass=groupOfNames)(member={USER}))\" userToDNMapping : >- [ { match: \"([^@]+)@percona\\\\.com\", ldapQuery: \"dc=percona,dc=com??sub?(&(objectClass=organizationalPerson)(cn={0}))\" } ] setParameter : authenticationMechanisms : \"PLAIN\" The {USER} variable substitutes the username transformed during the userToDNMapping stage. Modify the given example configuration to match your deployment, For example, replace ldap.example.com with the hostname of your LDAP server. Replace the domain controllers (DC) percona and com with those relevant to your organization. Depending on your LDAP schema, further modifications of the LDAP query may be required. Restart the mongod service: $ sudo systemctl restart mongod Test the access to Percona Server for MongoDB: mongosh -u \"alice\" -p \"secretpwd\" --authenticationDatabase '$external' --authenticationMechanism 'PLAIN' Active Directory configuration \u00b6 Microsoft Active Directory uses a different schema for user and group definition. To illustrate Percona Server for MongoDB configuration, we will use the following AD users: dn:CN=alice,CN=Users,DC=testusers,DC=percona,DC=com userPrincipalName: alice@testusers.percona.com memberOf: CN=testusers,CN=Users,DC=percona,DC=com dn:CN=bob,CN=Users,DC=otherusers,DC=percona,DC=com userPrincipalName: bob@otherusers.percona.com memberOf: CN=otherusers,CN=Users,DC=percona,DC=com The following are respective groups: dn:CN=testusers,CN=Users,DC=percona,DC=com member:CN=alice,CN=Users,DC=testusers,DC=example,DC=com dn:CN=otherusers,CN=Users,DC=percona,DC=com member:CN=bob,CN=Users,DC=otherusers,DC=example,DC=com Use one of the given Percona Server for MongoDB configurations for user authentication and authorization in Active Directory: No username transformation Username substitution LDAP query Edit the /etc/mongod.conf configuration file: ldap : servers : \"ldap.example.com\" authz : queryTemplate : \"DC=percona,DC=com??sub?(&(objectClass=group)(member:1.2.840.113556.1.4.1941:={PROVIDED_USER}))\" setParameter : authenticationMechanisms : \"PLAIN\" Restart the mongod service: $ sudo systemctl restart mongod Test the access to Percona Server for MongoDB: $ mongosh -u \"CN=alice,CN=Users,DC=testusers,DC=percona,DC=com\" -p \"secretpwd\" --authenticationDatabase '$external' --authenticationMechanism 'PLAIN' Edit the /etc/mongod.conf configuration file: ldap : servers : \"ldap.example.com\" authz : queryTemplate : \"DC=percona,DC=com??sub?(&(objectClass=group)(member:1.2.840.113556.1.4.1941:={USER}))\" userToDNMapping : >- [ { match: \"([^@]+)@([^\\\\.]+)\\\\.percona\\\\.com\", substitution: \"CN={0},CN=Users,DC={1},DC=percona,DC=com\" } ] setParameter : authenticationMechanisms : \"PLAIN\" Restart the mongod service: $ sudo systemctl restart mongod Test the access to Percona Server for MongoDB: $ mongosh -u \"alice@percona.com\" -p \"secretpwd\" --authenticationDatabase '$external' --authenticationMechanism 'PLAIN' Edit the /etc/mongod.conf configuration file: ldap : servers : \"ldap.example.com\" authz : queryTemplate : \"DC=percona,DC=com??sub?(&(objectClass=group)(member:1.2.840.113556.1.4.1941:={USER}))\" userToDNMapping : >- [ { match: \"(.+)\", ldapQuery: \"dc=example,dc=com??sub?(&(objectClass=organizationalPerson)(userPrincipalName={0}))\" } ] setParameter : authenticationMechanisms : \"PLAIN\" Restart the mongod service: $ sudo systemctl restart mongod Test the access to Percona Server for MongoDB: $ mongosh -u \"alice\" -p \"secretpwd\" --authenticationDatabase '$external' --authenticationMechanism 'PLAIN' Modify one of this example configuration to match your deployment. This document is based on the following posts from Percona Database Performance Blog: Percona Server for MongoDB LDAP Enhancements: User-to- DN Mapping by Igor Solodovnikov Authenticate Percona Server for MongoDB Users via Native LDAP by Ivan Groenewold","title":"Set up LDAP authentication and authorization using NativeLDAP"},{"location":"ldap-setup.html#set-up-ldap-authentication-and-authorization-using-nativeldap","text":"This document describes an example configuration of LDAP authentication and authorization using direct binding to an LDAP server (Native LDAP). We recommend testing this setup in a non-production environment first, before applying it in production.","title":"Set up LDAP authentication and authorization using NativeLDAP"},{"location":"ldap-setup.html#assumptions","text":"The setup of an LDAP server is out of scope of this document. We assume that you are familiar with the LDAP server schema. You have the LDAP server up and running and it is accessible to the servers with Percona Server for MongoDB installed. This document primarily focuses on OpenLDAP used as the LDAP server and the examples are given based on the OpenLDAP format. If you are using Active Directory, refer to the Active Directory configuration section. You have the sudo privilege to the server with the Percona Server for MongoDB installed.","title":"Assumptions"},{"location":"ldap-setup.html#prerequisites","text":"In this setup we use anonymous binds to the LDAP server. If your LDAP server disallows anonymous binds, create the user that Percona Server for MongoDB will use to connect to and query the LDAP server. Define this user\u2019s credentials for the security.ldap.bind.queryUser and security.ldap.bind.queryPassword parameters in the mongod.conf configuration file. In this setup, we use the following OpenLDAP groups: dn: cn=testusers,dc=percona,dc=com objectClass: groupOfNames cn: testusers member: cn=alice,dc=percona,dc=com dn: cn=otherusers,dc=percona,dc=com objectClass: groupOfNames cn: otherusers member: cn=bob,dc=percona,dc=com","title":"Prerequisites"},{"location":"ldap-setup.html#setup-procedure","text":"","title":"Setup procedure"},{"location":"ldap-setup.html#configure-tlsssl-connection-for-percona-server-for-mongodb","text":"By default, Percona Server for MongoDB establishes the TLS connection when binding to the LDAP server and thus, it requires access to the LDAP certificates. To make Percona Server for MongoDB aware of the certificates, do the following: Place the certificate in the certs directory. The path to the certs directory is: On Debian / Ubuntu: /etc/ssl/certs/ On RHEL / CentOS: /etc/openldap/certs/ Specify the path to the certificates in the ldap.conf file: Debian / Ubuntu RHEL and derivatives tee -a /etc/openldap/ldap.conf <<EOF TLS_CACERT /etc/ssl/certs/my_CA.crt EOF tee -a /etc/openldap/ldap.conf <<EOF TLS_CACERT /etc/openldap/certs/my_CA.crt EOF","title":"Configure TLS/SSL connection for Percona Server for MongoDB"},{"location":"ldap-setup.html#create-roles-for-ldap-groups-in-percona-server-for-mongodb","text":"Percona Server for MongoDB authorizes users based on LDAP group membership. For every group, you must create the role in the admin database with the name that exactly matches the of the LDAP group. Percona Server for MongoDB maps the user\u2019s LDAP group to the roles and determines what role is assigned to the user. Percona Server for MongoDB then grants privileges defined by this role. To create the roles, use the following command: var admin = db . getSiblingDB ( \"admin\" ) db . createRole ( { role : \"cn=testusers,dc=percona,dc=com\" , privileges : [], roles : [ \"readWrite\" ] } ) db . createRole ( { role : \"cn=otherusers,dc=percona,dc=com\" , privileges : [], roles : [ \"read\" ] } )","title":"Create roles for LDAP groups in Percona Server for MongoDB"},{"location":"ldap-setup.html#percona-server-for-mongodb-configuration","text":"","title":"Percona Server for MongoDB configuration"},{"location":"ldap-setup.html#active-directory-configuration","text":"Microsoft Active Directory uses a different schema for user and group definition. To illustrate Percona Server for MongoDB configuration, we will use the following AD users: dn:CN=alice,CN=Users,DC=testusers,DC=percona,DC=com userPrincipalName: alice@testusers.percona.com memberOf: CN=testusers,CN=Users,DC=percona,DC=com dn:CN=bob,CN=Users,DC=otherusers,DC=percona,DC=com userPrincipalName: bob@otherusers.percona.com memberOf: CN=otherusers,CN=Users,DC=percona,DC=com The following are respective groups: dn:CN=testusers,CN=Users,DC=percona,DC=com member:CN=alice,CN=Users,DC=testusers,DC=example,DC=com dn:CN=otherusers,CN=Users,DC=percona,DC=com member:CN=bob,CN=Users,DC=otherusers,DC=example,DC=com Use one of the given Percona Server for MongoDB configurations for user authentication and authorization in Active Directory: No username transformation Username substitution LDAP query Edit the /etc/mongod.conf configuration file: ldap : servers : \"ldap.example.com\" authz : queryTemplate : \"DC=percona,DC=com??sub?(&(objectClass=group)(member:1.2.840.113556.1.4.1941:={PROVIDED_USER}))\" setParameter : authenticationMechanisms : \"PLAIN\" Restart the mongod service: $ sudo systemctl restart mongod Test the access to Percona Server for MongoDB: $ mongosh -u \"CN=alice,CN=Users,DC=testusers,DC=percona,DC=com\" -p \"secretpwd\" --authenticationDatabase '$external' --authenticationMechanism 'PLAIN' Edit the /etc/mongod.conf configuration file: ldap : servers : \"ldap.example.com\" authz : queryTemplate : \"DC=percona,DC=com??sub?(&(objectClass=group)(member:1.2.840.113556.1.4.1941:={USER}))\" userToDNMapping : >- [ { match: \"([^@]+)@([^\\\\.]+)\\\\.percona\\\\.com\", substitution: \"CN={0},CN=Users,DC={1},DC=percona,DC=com\" } ] setParameter : authenticationMechanisms : \"PLAIN\" Restart the mongod service: $ sudo systemctl restart mongod Test the access to Percona Server for MongoDB: $ mongosh -u \"alice@percona.com\" -p \"secretpwd\" --authenticationDatabase '$external' --authenticationMechanism 'PLAIN' Edit the /etc/mongod.conf configuration file: ldap : servers : \"ldap.example.com\" authz : queryTemplate : \"DC=percona,DC=com??sub?(&(objectClass=group)(member:1.2.840.113556.1.4.1941:={USER}))\" userToDNMapping : >- [ { match: \"(.+)\", ldapQuery: \"dc=example,dc=com??sub?(&(objectClass=organizationalPerson)(userPrincipalName={0}))\" } ] setParameter : authenticationMechanisms : \"PLAIN\" Restart the mongod service: $ sudo systemctl restart mongod Test the access to Percona Server for MongoDB: $ mongosh -u \"alice\" -p \"secretpwd\" --authenticationDatabase '$external' --authenticationMechanism 'PLAIN' Modify one of this example configuration to match your deployment. This document is based on the following posts from Percona Database Performance Blog: Percona Server for MongoDB LDAP Enhancements: User-to- DN Mapping by Igor Solodovnikov Authenticate Percona Server for MongoDB Users via Native LDAP by Ivan Groenewold","title":"Active Directory configuration"},{"location":"log-redaction.html","text":"Log redaction \u00b6 Percona Server for MongoDB can prevent writing sensitive data to the diagnostic log by redacting messages of events before they are logged. To enable log redaction, run mongod with the --redactClientLogData option. Note Metadata such as error or operation codes, line numbers, and source file names remain visible in the logs. Log redaction is important for comlying with security requirements, but it can make troubleshooting and diagnostics more difficult due to the lack of data related to the log event. For this reason, debug messages are not redacted even when log redaction is enabled. Keep this in mind when switching between log levels. You can permanently enable log redaction by adding the following to the configuration file: security : redactClientLogData : true To enable log redaction at runtime, use the setParameter command as follows: > db . adminCommand ( { setParameter : 1 , redactClientLogData : true } )","title":"Log redaction"},{"location":"log-redaction.html#log-redaction","text":"Percona Server for MongoDB can prevent writing sensitive data to the diagnostic log by redacting messages of events before they are logged. To enable log redaction, run mongod with the --redactClientLogData option. Note Metadata such as error or operation codes, line numbers, and source file names remain visible in the logs. Log redaction is important for comlying with security requirements, but it can make troubleshooting and diagnostics more difficult due to the lack of data related to the log event. For this reason, debug messages are not redacted even when log redaction is enabled. Keep this in mind when switching between log levels. You can permanently enable log redaction by adding the following to the configuration file: security : redactClientLogData : true To enable log redaction at runtime, use the setParameter command as follows: > db . adminCommand ( { setParameter : 1 , redactClientLogData : true } )","title":"Log redaction"},{"location":"ngram-full-text-search.html","text":"Additional text search algorithm - ngram \u00b6 The ngram text search algorithm is useful for searching text for a specific string of characters in a field of a collection. This feature can be used to find exact sub-string matches, which provides an alternative to parsing text from languages other than the list of European languages already supported by MongoDB Community\u2019s full text search engine. It may also turn out to be more convenient when working with the text where symbols like dash(\u2018-\u2018), underscore(\u2018_\u2019), or slash(\u201c/\u201d) are not token delimiters. Unlike MongoDB full text search engine, ngram search algorithm uses only the following token delimiter characters that do not count as word characters in human languages: Horizontal tab Vertical tab Line feed Carriage return Space The ngram text search is slower than MongoDB full text search. Usage \u00b6 To use ngram , create a text index on a collection setting the default_language parameter to ngram : > db . collection . createIndex ({ name : \"text\" }, { default_language : \"ngram\" }) ngram search algorithm treats special characters like individual terms. Therefore, you don\u2019t have to enclose the search string in escaped double quotes ( \\\\\" ) to query the text index. For example, to search for documents that contain the date 2021-02-12 , specify the following: > db . collection . find ({ $text : { $search : \"2021-02-12\" } }) However, both ngram and MongoDB full text search engine treat words with the hyphen-minus - sign in front of them as negated (e.g. \u201c-coffee\u201d) and exclude such words from the search results.","title":"Additional text search algorithm - ngram"},{"location":"ngram-full-text-search.html#additional-text-search-algorithm-ngram","text":"The ngram text search algorithm is useful for searching text for a specific string of characters in a field of a collection. This feature can be used to find exact sub-string matches, which provides an alternative to parsing text from languages other than the list of European languages already supported by MongoDB Community\u2019s full text search engine. It may also turn out to be more convenient when working with the text where symbols like dash(\u2018-\u2018), underscore(\u2018_\u2019), or slash(\u201c/\u201d) are not token delimiters. Unlike MongoDB full text search engine, ngram search algorithm uses only the following token delimiter characters that do not count as word characters in human languages: Horizontal tab Vertical tab Line feed Carriage return Space The ngram text search is slower than MongoDB full text search.","title":"Additional text search algorithm - ngram"},{"location":"ngram-full-text-search.html#usage","text":"To use ngram , create a text index on a collection setting the default_language parameter to ngram : > db . collection . createIndex ({ name : \"text\" }, { default_language : \"ngram\" }) ngram search algorithm treats special characters like individual terms. Therefore, you don\u2019t have to enclose the search string in escaped double quotes ( \\\\\" ) to query the text index. For example, to search for documents that contain the date 2021-02-12 , specify the following: > db . collection . find ({ $text : { $search : \"2021-02-12\" } }) However, both ngram and MongoDB full text search engine treat words with the hyphen-minus - sign in front of them as negated (e.g. \u201c-coffee\u201d) and exclude such words from the search results.","title":"Usage"},{"location":"rate-limit.html","text":"Profiling rate limit \u00b6 Percona Server for MongoDB can limit the number of queries collected by the database profiler to decrease its impact on performance. Rate limit is an integer between 1 and 1000 and represents the fraction of queries to be profiled. For example, if you set it to 20, then every 20 th query will be logged. For compatibility reasons, rate limit of 0 is the same as setting it to 1, and will effectively disable the feature meaning that every query will be profiled. The MongoDB database profiler can operate in one of three modes: 0 : Profiling is disabled. This is the default setting. 1 : The profiler collects data only for slow queries. By default, queries that take more than 100 milliseconds to execute are considered slow . 2 : Collects profiling data for all database operations. Mode 1 ignores all fast queries, which may be the cause of problems that you are trying to find. Mode 2 provides a comprehensive picture of database performance, but may introduce unnecessary overhead. With rate limiting you can collect profiling data for all database operations and reduce overhead by sampling queries. Slow queries ignore rate limiting and are always collected by the profiler. Comparing to the sampleRate option \u00b6 The sampleRate option (= slowOpSampleRate config file option) is a similar concept to rateLimit . But it works at different profile level, completely ignores operations faster than slowOpsThresholdMs (a.k.a. slowMs ), and affects the log file printing, too. sampleRate rateLimit Affects profiling level 1 yes no Affects profiling level 2 no yes Discards/filters slow ops yes no Discards/filters fast ops no yes Affects log file yes no Example value of option 0.02 50 rateLimit is a better way to have continuous profiling for monitoring or live analysis purposes. sampleRate requires setting slowOpsThresholdMs to zero if you want to sample all types of operations. sampleRate has an effect on the log file which may either decrease or increase the log volume. Enabling the rate limit \u00b6 To enable rate limiting, set the profiler mode to 2 and specify the value of the rate limit. Optionally, you can also change the default threshold for slow queries, which will not be sampled by rate limiting. For example, to set the rate limit to 100 (profile every 100 th fast query) and the slow query threshold to 200 (profile all queries slower than 200 milliseconds), run the mongod instance as follows: $ mongod --profile 2 --slowms 200 --rateLimit 100 To do the same at runtime, use the profile command. It returns the previous settings and \"ok\" : 1 indicates that the operation was successful: > db . runCommand ( { profile : 2 , slowms : 200 , ratelimit : 100 } ); { \"was\" : 0 , \"slowms\" : 100 , \"ratelimit\" : 1 , \"ok\" : 1 } To check the current settings, run profile: -1 : > db . runCommand ( { profile : - 1 } ); { \"was\" : 2 , \"slowms\" : 200 , \"ratelimit\" : 100 , \"ok\" : 1 } If you want to set or get just the rate limit value, use the profilingRateLimit parameter on the admin database: > db . getSiblingDB ( 'admin' ). runCommand ( { setParameter : 1 , \"profilingRateLimit\" : 100 } ); { \"was\" : 1 , \"ok\" : 1 } > db . getSiblingDB ( 'admin' ). runCommand ( { getParameter : 1 , \"profilingRateLimit\" : 1 } ); { \"profilingRateLimit\" : 100 , \"ok\" : 1 } If you want rate limiting to persist when you restart mongod , set the corresponding variables in the MongoDB configuration file (by default, /etc/mongod.conf ): operationProfiling : mode : all slowOpThresholdMs : 200 rateLimit : 100 Note The value of the operationProfiling.mode variable is a string, which you can set to either off , slowOp , or all , corresponding to profiling modes 0 , 1 , and 2 . Profiler collection extension \u00b6 Each document in the system.profile collection includes an additional rateLimit field. This field always has the value of 1 for slow queries and the current rate limit value for fast queries.","title":"Profiling rate limit"},{"location":"rate-limit.html#profiling-rate-limit","text":"Percona Server for MongoDB can limit the number of queries collected by the database profiler to decrease its impact on performance. Rate limit is an integer between 1 and 1000 and represents the fraction of queries to be profiled. For example, if you set it to 20, then every 20 th query will be logged. For compatibility reasons, rate limit of 0 is the same as setting it to 1, and will effectively disable the feature meaning that every query will be profiled. The MongoDB database profiler can operate in one of three modes: 0 : Profiling is disabled. This is the default setting. 1 : The profiler collects data only for slow queries. By default, queries that take more than 100 milliseconds to execute are considered slow . 2 : Collects profiling data for all database operations. Mode 1 ignores all fast queries, which may be the cause of problems that you are trying to find. Mode 2 provides a comprehensive picture of database performance, but may introduce unnecessary overhead. With rate limiting you can collect profiling data for all database operations and reduce overhead by sampling queries. Slow queries ignore rate limiting and are always collected by the profiler.","title":"Profiling rate limit"},{"location":"rate-limit.html#comparing-to-the-samplerate-option","text":"The sampleRate option (= slowOpSampleRate config file option) is a similar concept to rateLimit . But it works at different profile level, completely ignores operations faster than slowOpsThresholdMs (a.k.a. slowMs ), and affects the log file printing, too. sampleRate rateLimit Affects profiling level 1 yes no Affects profiling level 2 no yes Discards/filters slow ops yes no Discards/filters fast ops no yes Affects log file yes no Example value of option 0.02 50 rateLimit is a better way to have continuous profiling for monitoring or live analysis purposes. sampleRate requires setting slowOpsThresholdMs to zero if you want to sample all types of operations. sampleRate has an effect on the log file which may either decrease or increase the log volume.","title":"Comparing to the sampleRate option"},{"location":"rate-limit.html#enabling-the-rate-limit","text":"To enable rate limiting, set the profiler mode to 2 and specify the value of the rate limit. Optionally, you can also change the default threshold for slow queries, which will not be sampled by rate limiting. For example, to set the rate limit to 100 (profile every 100 th fast query) and the slow query threshold to 200 (profile all queries slower than 200 milliseconds), run the mongod instance as follows: $ mongod --profile 2 --slowms 200 --rateLimit 100 To do the same at runtime, use the profile command. It returns the previous settings and \"ok\" : 1 indicates that the operation was successful: > db . runCommand ( { profile : 2 , slowms : 200 , ratelimit : 100 } ); { \"was\" : 0 , \"slowms\" : 100 , \"ratelimit\" : 1 , \"ok\" : 1 } To check the current settings, run profile: -1 : > db . runCommand ( { profile : - 1 } ); { \"was\" : 2 , \"slowms\" : 200 , \"ratelimit\" : 100 , \"ok\" : 1 } If you want to set or get just the rate limit value, use the profilingRateLimit parameter on the admin database: > db . getSiblingDB ( 'admin' ). runCommand ( { setParameter : 1 , \"profilingRateLimit\" : 100 } ); { \"was\" : 1 , \"ok\" : 1 } > db . getSiblingDB ( 'admin' ). runCommand ( { getParameter : 1 , \"profilingRateLimit\" : 1 } ); { \"profilingRateLimit\" : 100 , \"ok\" : 1 } If you want rate limiting to persist when you restart mongod , set the corresponding variables in the MongoDB configuration file (by default, /etc/mongod.conf ): operationProfiling : mode : all slowOpThresholdMs : 200 rateLimit : 100 Note The value of the operationProfiling.mode variable is a string, which you can set to either off , slowOp , or all , corresponding to profiling modes 0 , 1 , and 2 .","title":"Enabling the rate limit"},{"location":"rate-limit.html#profiler-collection-extension","text":"Each document in the system.profile collection includes an additional rateLimit field. This field always has the value of 1 for slow queries and the current rate limit value for fast queries.","title":"Profiler collection extension"},{"location":"sasl-auth.html","text":"Set up LDAP authentication with SASL \u00b6 This document describes an example configuration suitable only to test out the external authentication functionality in a non-production environment. Use common sense to adapt these guidelines to your production environment. To learn more about how the authentication works, see LDAP authentication with SASL . Environment setup and configuration \u00b6 The following components are required: slapd : OpenLDAP server. libsasl2 version 2.1.25 or later. saslauthd : Authentication Daemon (distinct from libsasl2 ). The following steps will help you configure your environment: Assumptions \u00b6 Before we move on to the configuration steps, we assume the following: You have the LDAP server up and running and have configured users on it. The LDAP server is accessible to the server with Percona Server for MongoDB installed. This document focuses on OpenLDAP server. If you use Microsoft Windows Active Directory, see to the Microsoft Windows Active Directory section for saslauthd configuration. You must place these two servers behind a firewall as the communications between them will be in plain text. This is because the SASL mechanism of PLAIN can only be used when authenticating and credentials will be sent in plain text. You have sudo privilege to the server with the Percona Server for MongoDB installed. Configuring saslauthd \u00b6 Install the SASL packages. Depending on your OS, use the following command: Debian and Ubuntu RHEL and derivatives $ sudo apt install -y sasl2-bin $ sudo yum install -y cyrus-sasl Configure SASL to use ldap as the authentication mechanism. Note Back up the original configuration file before making changes. Debian and Ubuntu RHEL and derivatives Use the following commands to enable the saslauthd to auto-run on startup and to set the ldap value for the --MECHANISMS option: $ sudo sed -i -e s/^MECH = pam/MECH = ldap/g /etc/sysconfig/saslauthdsudo sed -i -e s/^MECHANISMS = \"pam\" /MECHANISMS = \"ldap\" /g /etc/default/saslauthd $ sudo sed -i -e s/^START = no/START = yes/g /etc/default/saslauthd Alternatively, you can edit the /etc/default/sysconfig/saslauthd configuration file: START=yes MECHANISMS=\"ldap Specify the ldap value for the --MECH option using the following command: $ sudo sed -i -e s/^MECH = pam/MECH = ldap/g /etc/sysconfig/saslauthd Alternatively, you can edit the /etc/sysconfig/saslauthd configuration file: MECH=ldap Create the /etc/saslauthd.conf configuration file and specify the settings that saslauthd requires to connect to a local LDAP service: OpenLDAP server Microsoft Windows Active Directory The following is the example configuration file. Note that the server address MUST match the OpenLDAP installation: ldap_servers: ldap://localhost ldap_mech: PLAIN ldap_search_base: dc=example,dc=com ldap_filter: (cn=%u) ldap_bind_dn: cn=admin,dc=example,dc=com ldap_password: secret Note the LDAP password ( ldap_password ) and bind domain name ( ldap_bind_dn ). This allows the saslauthd service to connect to the LDAP service as admin. In production, this would not be the case; users should not store administrative passwords in unencrypted files. In order for LDAP operations to be performed against a Windows Active Directory server, a user record must be created to perform the lookups. The following example shows configuration parameters for saslauthd to communicate with an Active Directory server: ldap_servers: ldap://localhost ldap_mech: PLAIN ldap_search_base: CN=Users,DC=example,DC=com ldap_filter: (sAMAccountName=%u) ldap_bind_dn: CN=ldapmgr,CN=Users,DC=<AD Domain>,DC=<AD TLD> ldap_password: ld@pmgr_Pa55word In order to determine and test the correct search base and filter for your Active Directory installation, the Microsoft LDP GUI Tool can be used to bind and search the LDAP-compatible directory. Start the saslauthd process and set it to run at restart: $ sudo systemctl start saslauthd $ sudo systemctl enable saslauthd Give write permissions to the /run/saslauthd folder for the mongod . Either change permissions to the /run/saslauthd folder: $ sudo chmod 755 /run/saslauthd Or add the mongod user to the sasl group: $ sudo usermod -a -G sasl mongod Sanity check \u00b6 Verify that the saslauthd service can authenticate against the users created in the LDAP service: $ testsaslauthd -u christian -p secret -f /var/run/saslauthd/mux This should return 0:OK \"Success\" . If it doesn\u2019t, then either the user name and password are not in the LDAP service, or sasaluthd is not configured properly. Configuring libsasl2 \u00b6 The mongod also uses the SASL library for communications. To configure the SASL library, create a configuration file. The configuration file must be named mongodb.conf and placed in a directory where libsasl2 can find and read it. libsasl2 is hard-coded to look in certain directories at build time. This location may be different depending on the installation method. In the configuration file, specify the following: pwcheck_method: saslauthd saslauthd_path: /var/run/saslauthd/mux log_level: 5 mech_list: plain The first two entries ( pwcheck_method and saslauthd_path ) are required for mongod to successfully use the saslauthd service. The log_level is optional but may help determine configuration errors. See also SASL documentation Configuring mongod server \u00b6 The configuration consists of the following steps: Creating a user with the root privileges. This user is required to log in to Percona Server for MongoDB after the external authentication is enabled. Editing the configuration file to enable the external authentication Create a root user \u00b6 Create a user with the root privileges in the admin database. If you have already created this user, skip this step. Otherwise, run the following command to create the admin user: > use admin switched to db admin > db . createUser ({ \"user\" : \"admin\" , \"pwd\" : \"$3cr3tP4ssw0rd\" , \"roles\" : [ \"root\" ]}) Successfully added user : { \"user\" : \"admin\" , \"roles\" : [ \"root\" ] } Enable external authentication \u00b6 Edit the etc/mongod.conf configuration file to enable the external authentication: security : authorization : enabled setParameter : authenticationMechanisms : PLAIN,SCRAM-SHA-1 Restart the mongod service: $ sudo systemctl restart mongod Add an external user to Percona Server for MongoDB \u00b6 User authentication is done by mapping a user object on the LDAP server against a user created in the $external database. Thus, at this step, you create the user in the $external database and they inherit the roles and privileges. Note that the username must exactly match the name of the user object on the LDAP server. Connect to Percona Server for MongoDB and authenticate as the root user. $ mongosh --host localhost --port 27017 -u admin -p '$3cr3tP4ssw0rd' --authenticationDatabase 'admin' Use the following command to add an external user to Percona Server for MongoDB: > db . getSiblingDB ( \"$external\" ). createUser ( { user : \"christian\" , roles : [ { role : \"read\" , db : \"test\" } ]} ); Authenticate as an external user in Percona Server for MongoDB \u00b6 When running the mongo client, a user can authenticate against a given database using the following command: > db . getSiblingDB ( \"$external\" ). auth ({ mechanism : \"PLAIN\" , user : \"christian\" , pwd : \"secret\" , digestPassword : false }) Alternatively, a user can authenticate while connecting to Percona Server for MongoDB : $ mongo --host localhost --port 27017 --authenticationMechanism PLAIN --authenticationDatabase \\$ external -u christian -p This section is based on the blog post Percona Server for MongoDB Authentication Using Active Directory by Doug Duncan :","title":"Set up LDAP authentication with SASL"},{"location":"sasl-auth.html#set-up-ldap-authentication-with-sasl","text":"This document describes an example configuration suitable only to test out the external authentication functionality in a non-production environment. Use common sense to adapt these guidelines to your production environment. To learn more about how the authentication works, see LDAP authentication with SASL .","title":"Set up LDAP authentication with SASL"},{"location":"sasl-auth.html#environment-setup-and-configuration","text":"The following components are required: slapd : OpenLDAP server. libsasl2 version 2.1.25 or later. saslauthd : Authentication Daemon (distinct from libsasl2 ). The following steps will help you configure your environment:","title":"Environment setup and configuration"},{"location":"sasl-auth.html#assumptions","text":"Before we move on to the configuration steps, we assume the following: You have the LDAP server up and running and have configured users on it. The LDAP server is accessible to the server with Percona Server for MongoDB installed. This document focuses on OpenLDAP server. If you use Microsoft Windows Active Directory, see to the Microsoft Windows Active Directory section for saslauthd configuration. You must place these two servers behind a firewall as the communications between them will be in plain text. This is because the SASL mechanism of PLAIN can only be used when authenticating and credentials will be sent in plain text. You have sudo privilege to the server with the Percona Server for MongoDB installed.","title":"Assumptions"},{"location":"sasl-auth.html#configuring-saslauthd","text":"Install the SASL packages. Depending on your OS, use the following command: Debian and Ubuntu RHEL and derivatives $ sudo apt install -y sasl2-bin $ sudo yum install -y cyrus-sasl Configure SASL to use ldap as the authentication mechanism. Note Back up the original configuration file before making changes. Debian and Ubuntu RHEL and derivatives Use the following commands to enable the saslauthd to auto-run on startup and to set the ldap value for the --MECHANISMS option: $ sudo sed -i -e s/^MECH = pam/MECH = ldap/g /etc/sysconfig/saslauthdsudo sed -i -e s/^MECHANISMS = \"pam\" /MECHANISMS = \"ldap\" /g /etc/default/saslauthd $ sudo sed -i -e s/^START = no/START = yes/g /etc/default/saslauthd Alternatively, you can edit the /etc/default/sysconfig/saslauthd configuration file: START=yes MECHANISMS=\"ldap Specify the ldap value for the --MECH option using the following command: $ sudo sed -i -e s/^MECH = pam/MECH = ldap/g /etc/sysconfig/saslauthd Alternatively, you can edit the /etc/sysconfig/saslauthd configuration file: MECH=ldap Create the /etc/saslauthd.conf configuration file and specify the settings that saslauthd requires to connect to a local LDAP service: OpenLDAP server Microsoft Windows Active Directory The following is the example configuration file. Note that the server address MUST match the OpenLDAP installation: ldap_servers: ldap://localhost ldap_mech: PLAIN ldap_search_base: dc=example,dc=com ldap_filter: (cn=%u) ldap_bind_dn: cn=admin,dc=example,dc=com ldap_password: secret Note the LDAP password ( ldap_password ) and bind domain name ( ldap_bind_dn ). This allows the saslauthd service to connect to the LDAP service as admin. In production, this would not be the case; users should not store administrative passwords in unencrypted files. In order for LDAP operations to be performed against a Windows Active Directory server, a user record must be created to perform the lookups. The following example shows configuration parameters for saslauthd to communicate with an Active Directory server: ldap_servers: ldap://localhost ldap_mech: PLAIN ldap_search_base: CN=Users,DC=example,DC=com ldap_filter: (sAMAccountName=%u) ldap_bind_dn: CN=ldapmgr,CN=Users,DC=<AD Domain>,DC=<AD TLD> ldap_password: ld@pmgr_Pa55word In order to determine and test the correct search base and filter for your Active Directory installation, the Microsoft LDP GUI Tool can be used to bind and search the LDAP-compatible directory. Start the saslauthd process and set it to run at restart: $ sudo systemctl start saslauthd $ sudo systemctl enable saslauthd Give write permissions to the /run/saslauthd folder for the mongod . Either change permissions to the /run/saslauthd folder: $ sudo chmod 755 /run/saslauthd Or add the mongod user to the sasl group: $ sudo usermod -a -G sasl mongod","title":"Configuring saslauthd"},{"location":"sasl-auth.html#sanity-check","text":"Verify that the saslauthd service can authenticate against the users created in the LDAP service: $ testsaslauthd -u christian -p secret -f /var/run/saslauthd/mux This should return 0:OK \"Success\" . If it doesn\u2019t, then either the user name and password are not in the LDAP service, or sasaluthd is not configured properly.","title":"Sanity check"},{"location":"sasl-auth.html#configuring-libsasl2","text":"The mongod also uses the SASL library for communications. To configure the SASL library, create a configuration file. The configuration file must be named mongodb.conf and placed in a directory where libsasl2 can find and read it. libsasl2 is hard-coded to look in certain directories at build time. This location may be different depending on the installation method. In the configuration file, specify the following: pwcheck_method: saslauthd saslauthd_path: /var/run/saslauthd/mux log_level: 5 mech_list: plain The first two entries ( pwcheck_method and saslauthd_path ) are required for mongod to successfully use the saslauthd service. The log_level is optional but may help determine configuration errors. See also SASL documentation","title":"Configuring libsasl2"},{"location":"sasl-auth.html#configuring-mongod-server","text":"The configuration consists of the following steps: Creating a user with the root privileges. This user is required to log in to Percona Server for MongoDB after the external authentication is enabled. Editing the configuration file to enable the external authentication","title":"Configuring mongod server"},{"location":"sasl-auth.html#authenticate-as-an-external-user-in-percona-server-for-mongodb","text":"When running the mongo client, a user can authenticate against a given database using the following command: > db . getSiblingDB ( \"$external\" ). auth ({ mechanism : \"PLAIN\" , user : \"christian\" , pwd : \"secret\" , digestPassword : false }) Alternatively, a user can authenticate while connecting to Percona Server for MongoDB : $ mongo --host localhost --port 27017 --authenticationMechanism PLAIN --authenticationDatabase \\$ external -u christian -p This section is based on the blog post Percona Server for MongoDB Authentication Using Active Directory by Doug Duncan :","title":"Authenticate as an external user in Percona Server for MongoDB"},{"location":"set-parameter.html","text":"Percona Server for MongoDB parameter tuning guide \u00b6 Percona Server for MongoDB includes several parameters that can be changed in one of the following ways: The setParameter admonitions in the configuration file for persistent changes in production: setParameter : cursorTimeoutMillis : <int> failIndexKeyTooLong : <boolean> internalQueryPlannerEnableIndexIntersection : <boolean> ttlMonitorEnabled : <boolean> ttlMonitorSleepSecs : <int> The --setParameter option arguments when running the mongod process for development or testing purposes: $ mongod \\ --setParameter cursorTimeoutMillis = <int> \\ --setParameter failIndexKeyTooLong = <boolean> \\ --setParameter internalQueryPlannerEnableIndexIntersection = <boolean> \\ --setParameter ttlMonitorEnabled = <boolean> \\ --setParameter ttlMonitorSleepSecs = <int> The setParameter command on the admin database to make changes at runtime: > db = db . getSiblingDB ( 'admin' ) > db . runCommand ( { setParameter : 1 , cursorTimeoutMillis : < int > } ) > db . runCommand ( { setParameter : 1 , failIndexKeyTooLong : < boolean > } ) > db . runCommand ( { setParameter : 1 , internalQueryPlannerEnableIndexIntersection : < boolean > } ) > db . runCommand ( { setParameter : 1 , ttlMonitorEnabled : < int > } ) > db . runCommand ( { setParameter : 1 , ttlMonitorSleepSecs : < int > } ) Parameters \u00b6 cursorTimeoutMillis \u00b6 Type : integer Default : 600000 (ten minutes) Sets the duration of time after which idle query cursors are removed from memory. failIndexKeyTooLong \u00b6 Type : boolean Default : true Versions of MongoDB prior to 2.6 would insert and update documents even if an index key was too long. The documents would not be included in the index. Newer versions of MongoDB ignore documents with long index key. By setting this value to false , the old behavior is enabled. internalQueryPlannerEnableIndexIntersection \u00b6 Type : boolean Default : true Due to changes introduced in MongoDB 2.6.4, some queries that reference multiple indexed fields, where one field matches no documents, may choose a non-optimal single-index plan. Setting this value to false will enable the old behavior and select the index intersection plan. ttlMonitorEnabled \u00b6 Type : boolean Default : true If this option is set to false , the worker thread that monitors TTL Indexes and removes old documents will be disabled. ttlMonitorSleepSecs \u00b6 Type : integer Default : 60 (one minute) Defines the number of seconds to wait between checking TTL Indexes for old documents and removing them.","title":"Tune parameters"},{"location":"set-parameter.html#percona-server-for-mongodb-parameter-tuning-guide","text":"Percona Server for MongoDB includes several parameters that can be changed in one of the following ways: The setParameter admonitions in the configuration file for persistent changes in production: setParameter : cursorTimeoutMillis : <int> failIndexKeyTooLong : <boolean> internalQueryPlannerEnableIndexIntersection : <boolean> ttlMonitorEnabled : <boolean> ttlMonitorSleepSecs : <int> The --setParameter option arguments when running the mongod process for development or testing purposes: $ mongod \\ --setParameter cursorTimeoutMillis = <int> \\ --setParameter failIndexKeyTooLong = <boolean> \\ --setParameter internalQueryPlannerEnableIndexIntersection = <boolean> \\ --setParameter ttlMonitorEnabled = <boolean> \\ --setParameter ttlMonitorSleepSecs = <int> The setParameter command on the admin database to make changes at runtime: > db = db . getSiblingDB ( 'admin' ) > db . runCommand ( { setParameter : 1 , cursorTimeoutMillis : < int > } ) > db . runCommand ( { setParameter : 1 , failIndexKeyTooLong : < boolean > } ) > db . runCommand ( { setParameter : 1 , internalQueryPlannerEnableIndexIntersection : < boolean > } ) > db . runCommand ( { setParameter : 1 , ttlMonitorEnabled : < int > } ) > db . runCommand ( { setParameter : 1 , ttlMonitorSleepSecs : < int > } )","title":"Percona Server for MongoDB parameter tuning guide"},{"location":"set-parameter.html#parameters","text":"","title":"Parameters"},{"location":"set-parameter.html#cursortimeoutmillis","text":"Type : integer Default : 600000 (ten minutes) Sets the duration of time after which idle query cursors are removed from memory.","title":"cursorTimeoutMillis"},{"location":"set-parameter.html#failindexkeytoolong","text":"Type : boolean Default : true Versions of MongoDB prior to 2.6 would insert and update documents even if an index key was too long. The documents would not be included in the index. Newer versions of MongoDB ignore documents with long index key. By setting this value to false , the old behavior is enabled.","title":"failIndexKeyTooLong"},{"location":"set-parameter.html#internalqueryplannerenableindexintersection","text":"Type : boolean Default : true Due to changes introduced in MongoDB 2.6.4, some queries that reference multiple indexed fields, where one field matches no documents, may choose a non-optimal single-index plan. Setting this value to false will enable the old behavior and select the index intersection plan.","title":"internalQueryPlannerEnableIndexIntersection"},{"location":"set-parameter.html#ttlmonitorenabled","text":"Type : boolean Default : true If this option is set to false , the worker thread that monitors TTL Indexes and removes old documents will be disabled.","title":"ttlMonitorEnabled"},{"location":"set-parameter.html#ttlmonitorsleepsecs","text":"Type : integer Default : 60 (one minute) Defines the number of seconds to wait between checking TTL Indexes for old documents and removing them.","title":"ttlMonitorSleepSecs"},{"location":"trademark-policy.html","text":"Trademark Policy \u00b6 This Trademark Policy is to ensure that users of Percona-branded products or services know that what they receive has really been developed, approved, tested and maintained by Percona. Trademarks help to prevent confusion in the marketplace, by distinguishing one company\u2019s or person\u2019s products and services from another\u2019s. Percona owns a number of marks, including but not limited to Percona, XtraDB, Percona XtraDB, XtraBackup, Percona XtraBackup, Percona Server, and Percona Live, plus the distinctive visual icons and logos associated with these marks. Both the unregistered and registered marks of Percona are protected. Use of any Percona trademark in the name, URL, or other identifying characteristic of any product, service, website, or other use is not permitted without Percona\u2019s written permission with the following three limited exceptions. First , you may use the appropriate Percona mark when making a nominative fair use reference to a bona fide Percona product. Second , when Percona has released a product under a version of the GNU General Public License (\u201cGPL\u201d), you may use the appropriate Percona mark when distributing a verbatim copy of that product in accordance with the terms and conditions of the GPL. Third , you may use the appropriate Percona mark to refer to a distribution of GPL-released Percona software that has been modified with minor changes for the sole purpose of allowing the software to operate on an operating system or hardware platform for which Percona has not yet released the software, provided that those third party changes do not affect the behavior, functionality, features, design or performance of the software. Users who acquire this Percona-branded software receive substantially exact implementations of the Percona software. Percona reserves the right to revoke this authorization at any time in its sole discretion. For example, if Percona believes that your modification is beyond the scope of the limited license granted in this Policy or that your use of the Percona mark is detrimental to Percona, Percona will revoke this authorization. Upon revocation, you must immediately cease using the applicable Percona mark. If you do not immediately cease using the Percona mark upon revocation, Percona may take action to protect its rights and interests in the Percona mark. Percona does not grant any license to use any Percona mark for any other modified versions of Percona software; such use will require our prior written permission. Neither trademark law nor any of the exceptions set forth in this Trademark Policy permit you to truncate, modify or otherwise use any Percona mark as part of your own brand. For example, if XYZ creates a modified version of the Percona Server, XYZ may not brand that modification as \u201cXYZ Percona Server\u201d or \u201cPercona XYZ Server\u201d, even if that modification otherwise complies with the third exception noted above. In all cases, you must comply with applicable law, the underlying license, and this Trademark Policy, as amended from time to time. For instance, any mention of Percona trademarks should include the full trademarked name, with proper spelling and capitalization, along with attribution of ownership to Percona Inc. For example, the full proper name for XtraBackup is Percona XtraBackup. However, it is acceptable to omit the word \u201cPercona\u201d for brevity on the second and subsequent uses, where such omission does not cause confusion. In the event of doubt as to any of the conditions or exceptions outlined in this Trademark Policy, please contact trademarks@percona.com for assistance and we will do our very best to be helpful.","title":"Trademark policy"},{"location":"trademark-policy.html#trademark-policy","text":"This Trademark Policy is to ensure that users of Percona-branded products or services know that what they receive has really been developed, approved, tested and maintained by Percona. Trademarks help to prevent confusion in the marketplace, by distinguishing one company\u2019s or person\u2019s products and services from another\u2019s. Percona owns a number of marks, including but not limited to Percona, XtraDB, Percona XtraDB, XtraBackup, Percona XtraBackup, Percona Server, and Percona Live, plus the distinctive visual icons and logos associated with these marks. Both the unregistered and registered marks of Percona are protected. Use of any Percona trademark in the name, URL, or other identifying characteristic of any product, service, website, or other use is not permitted without Percona\u2019s written permission with the following three limited exceptions. First , you may use the appropriate Percona mark when making a nominative fair use reference to a bona fide Percona product. Second , when Percona has released a product under a version of the GNU General Public License (\u201cGPL\u201d), you may use the appropriate Percona mark when distributing a verbatim copy of that product in accordance with the terms and conditions of the GPL. Third , you may use the appropriate Percona mark to refer to a distribution of GPL-released Percona software that has been modified with minor changes for the sole purpose of allowing the software to operate on an operating system or hardware platform for which Percona has not yet released the software, provided that those third party changes do not affect the behavior, functionality, features, design or performance of the software. Users who acquire this Percona-branded software receive substantially exact implementations of the Percona software. Percona reserves the right to revoke this authorization at any time in its sole discretion. For example, if Percona believes that your modification is beyond the scope of the limited license granted in this Policy or that your use of the Percona mark is detrimental to Percona, Percona will revoke this authorization. Upon revocation, you must immediately cease using the applicable Percona mark. If you do not immediately cease using the Percona mark upon revocation, Percona may take action to protect its rights and interests in the Percona mark. Percona does not grant any license to use any Percona mark for any other modified versions of Percona software; such use will require our prior written permission. Neither trademark law nor any of the exceptions set forth in this Trademark Policy permit you to truncate, modify or otherwise use any Percona mark as part of your own brand. For example, if XYZ creates a modified version of the Percona Server, XYZ may not brand that modification as \u201cXYZ Percona Server\u201d or \u201cPercona XYZ Server\u201d, even if that modification otherwise complies with the third exception noted above. In all cases, you must comply with applicable law, the underlying license, and this Trademark Policy, as amended from time to time. For instance, any mention of Percona trademarks should include the full trademarked name, with proper spelling and capitalization, along with attribution of ownership to Percona Inc. For example, the full proper name for XtraBackup is Percona XtraBackup. However, it is acceptable to omit the word \u201cPercona\u201d for brevity on the second and subsequent uses, where such omission does not cause confusion. In the event of doubt as to any of the conditions or exceptions outlined in this Trademark Policy, please contact trademarks@percona.com for assistance and we will do our very best to be helpful.","title":"Trademark Policy"},{"location":"vault.html","text":"HashiCorp Vault integration \u00b6 Percona Server for MongoDB is integrated with HashiCorp Vault. HashiCorp Vault supports different secrets engines. Percona Server for MongoDB only supports the HashiCorp Vault back end with KV Secrets Engine - Version 2 (API) with versioning enabled. See also Percona Blog: Using Vault to Store the Master Key for Data at Rest Encryption on Percona Server for MongoDB HashiCorp Vault Documentation: How to configure the KV Engine HashiCorp Vault Parameters \u00b6 Command line Configuration file Type Description vaultServerName security.vault.serverName string The IP address of the Vault server vaultPort security.vault.port int The port on the Vault server vaultTokenFile security.vault.tokenFile string The path to the vault token file. The token file is used by MongoDB to access HashiCorp Vault. The vault token file consists of the raw vault token and does not include any additional strings or parameters. Example of a vault token file: s.uTrHtzsZnEE7KyHeA797CkWA Config file example security : enableEncryption : true vault : serverName : 127.0.0.1 port : 8200 tokenFile : /home/user/path/token secret : secret/data/hello During the first run of the Percona Server for MongoDB, the process generates a secure key and writes the key to the vault. During the subsequent start, the server tries to read the master key from the vault. If the configured secret does not exist, vault responds with HTTP 404 error. Namespaces \u00b6 Namespaces are isolated environments in Vault that allow for separate secret key and policy management. You can use Vault namespaces with Percona Server for MongoDB. Specify the namespace(s) for the security.vault.secret option value as follows: <namespace>/secret/data/<secret_path> For example, the path to secret keys for namespace test on the secrets engine secret will be test/secret/<my_secret_path> . Targeting a namespace in Vault configuration \u00b6 You have the following options of how to target a particular namespace when configuring Vault: Set the VAULT_NAMESPACE environment variable so that all subsequent commands are executed against that namespace. Use the following command to set the environment variable for the namespace test : $ export VAULT_NAMESPACE = test 2. Provide the namespace with the -namespace flag in commands See also HashiCorp Vault Documentation: Namespaces Secure Multi-Tenancy with Namespaces Key Rotation \u00b6 Key rotation is replacing the old master key with a new one. This process helps to comply with regulatory requirements. To rotate the keys for a single mongod instance, do the following: Stop the mongod process Add --vaultRotateMasterKey option via the command line or security.vault.rotateMasterKey to the config file. Run the mongod process with the selected option, the process will perform the key rotation and exit. Remove the selected option from the startup command or the config file. Start mongod again. Rotating the master key process also re-encrypts the keystore using the new master key. The new master key is stored in the vault. The entire dataset is not re-encrypted. Key rotation in replica sets \u00b6 Every mongod node in a replica set must have its own master key. The key rotation steps are the following: Rotate the master key for the secondary nodes one by one. Step down the primary and wait for another primary to be elected. Rotate the master key for the previous primary node.","title":"HashiCorp Vault integration"},{"location":"vault.html#hashicorp-vault-integration","text":"Percona Server for MongoDB is integrated with HashiCorp Vault. HashiCorp Vault supports different secrets engines. Percona Server for MongoDB only supports the HashiCorp Vault back end with KV Secrets Engine - Version 2 (API) with versioning enabled. See also Percona Blog: Using Vault to Store the Master Key for Data at Rest Encryption on Percona Server for MongoDB HashiCorp Vault Documentation: How to configure the KV Engine","title":"HashiCorp Vault integration"},{"location":"vault.html#hashicorp-vault-parameters","text":"Command line Configuration file Type Description vaultServerName security.vault.serverName string The IP address of the Vault server vaultPort security.vault.port int The port on the Vault server vaultTokenFile security.vault.tokenFile string The path to the vault token file. The token file is used by MongoDB to access HashiCorp Vault. The vault token file consists of the raw vault token and does not include any additional strings or parameters. Example of a vault token file: s.uTrHtzsZnEE7KyHeA797CkWA Config file example security : enableEncryption : true vault : serverName : 127.0.0.1 port : 8200 tokenFile : /home/user/path/token secret : secret/data/hello During the first run of the Percona Server for MongoDB, the process generates a secure key and writes the key to the vault. During the subsequent start, the server tries to read the master key from the vault. If the configured secret does not exist, vault responds with HTTP 404 error.","title":"HashiCorp Vault Parameters"},{"location":"vault.html#namespaces","text":"Namespaces are isolated environments in Vault that allow for separate secret key and policy management. You can use Vault namespaces with Percona Server for MongoDB. Specify the namespace(s) for the security.vault.secret option value as follows: <namespace>/secret/data/<secret_path> For example, the path to secret keys for namespace test on the secrets engine secret will be test/secret/<my_secret_path> .","title":"Namespaces"},{"location":"vault.html#targeting-a-namespace-in-vault-configuration","text":"You have the following options of how to target a particular namespace when configuring Vault: Set the VAULT_NAMESPACE environment variable so that all subsequent commands are executed against that namespace. Use the following command to set the environment variable for the namespace test : $ export VAULT_NAMESPACE = test 2. Provide the namespace with the -namespace flag in commands See also HashiCorp Vault Documentation: Namespaces Secure Multi-Tenancy with Namespaces","title":"Targeting a namespace in Vault configuration"},{"location":"vault.html#key-rotation","text":"Key rotation is replacing the old master key with a new one. This process helps to comply with regulatory requirements. To rotate the keys for a single mongod instance, do the following: Stop the mongod process Add --vaultRotateMasterKey option via the command line or security.vault.rotateMasterKey to the config file. Run the mongod process with the selected option, the process will perform the key rotation and exit. Remove the selected option from the startup command or the config file. Start mongod again. Rotating the master key process also re-encrypts the keystore using the new master key. The new master key is stored in the vault. The entire dataset is not re-encrypted.","title":"Key Rotation"},{"location":"vault.html#key-rotation-in-replica-sets","text":"Every mongod node in a replica set must have its own master key. The key rotation steps are the following: Rotate the master key for the secondary nodes one by one. Step down the primary and wait for another primary to be elected. Rotate the master key for the previous primary node.","title":"Key rotation in replica sets"},{"location":"x509-ldap.html","text":"Set up x.509 authentication and LDAP authorization \u00b6 x.509 certificate authentication is one of the supported authentication mechanisms in Percona Server for MongoDB. It is compatible with LDAP authorization to enable you to control user access and operations in your database environment. This document provides the steps on how to configure and use x.509 certificates for authentication in Percona Server for MongoDB and authorize users in the LDAP server. Considerations \u00b6 For testing purposes, in this tutorial we use OpenSSL to issue self-signed certificates. For production use, we recommend using certificates issued and signed by the CA in Percona Server for MongoDB. Client certificates must meet the client certificate requirements . The setup of the LDAP server and the configuration of the LDAP schema is out of scope of this document. We assume that you have the LDAP server up and running and accessible to Percona Server for MongoDB. Setup procedure \u00b6 Issue certificates \u00b6 Create a directory to store the certificates. For example, /var/lib/mongocerts . $ sudo mkdir -p /var/lib/mongocerts Grant access to the mongod user to this directory: $ sudo chown mongod:mongod /var/lib/mongocerts Generate the root Certificate Authority certificate \u00b6 The root Certificate Authority certificate will be used to sign the SSL certificates. Run the following command and in the -subj flag, provide the details about your organization: C - Country Name (2 letter code); ST - State or Province Name (full name); L - Locality Name (city); O - Organization Name (company); CN - Common Name (your name or your server\u2019s hostname) . $ cd /var/lib/mongocerts $ sudo openssl req -nodes -x509 -newkey rsa:4096 -keyout ca.key -out ca.crt -subj \"/C=US/ST=California/L=SanFrancisco/O=Percona/OU=root/CN=localhost\" Generate server certificate \u00b6 Create the server certificate request and key. In the -subj flag, provide the details about your organization: C - Country Name (2 letter code); ST - State or Province Name (full name); L - Locality Name (city); O - Organization Name (company); CN - Common Name (your name or your server\u2019s hostname) . $ sudo openssl req -nodes -newkey rsa:4096 -keyout server.key -out server.csr -subj \"/C=US/ST=California/L=SanFrancisco/O=Percona/OU=server/CN=localhost\" Sign the server certificate request with the root CA certificate: $ sudo openssl x509 -req -in server.csr -CA ca.crt -CAkey ca.key -set_serial 01 -out server.crt Combine the server certificate and key to create a certificate key file. Run this command as the root user: $ cat server.key server.crt > server.pem Generate client certificates \u00b6 Generate client certificate request and key. In the -subj flag, specify the information about clients in the format. $ openssl req -nodes -newkey rsa:4096 -keyout client.key -out client.csr -subj \"/DC=com/DC=percona/CN=John Doe\" Sign the client certificate request with the root CA certificate. $ openssl x509 -req -in client.csr -CA ca.crt -CAkey ca.key -set_serial 02 -out client.crt Combine the client certificate and key to create a certificate key file. $ cat client.key client.crt > client.pem Set up the LDAP server \u00b6 The setup of the LDAP server is out of scope of this document. Please work with your LDAP administrators to set up the LDAP server and configure the LDAP schema. Configure the mongod server \u00b6 The configuration consists of the following steps: Creating a role that matches the user group on the LDAP server Editing the configuration file to enable the x.509 authentication Note When you use x.509 authentication with LDAP authorization, you don\u2019t need to create users in the $external database. User management is done on the LDAP server so when a client connects to the database, they are authenticated and authorized through the LDAP server. Create roles \u00b6 At this step, create the roles in the admin database with the names that exactly match the names of the user groups on the LDAP server. These roles are used for user LDAP authorization in Percona Server for MongoDB. In our example, we create the role cn=otherusers,dc=percona,dc=com that has the corresponding LDAP group. var admin = db . getSiblingDB ( \"admin\" ) db . createRole ( { role : \"cn=otherusers,dc=percona,dc=com\" , privileges : [], roles : [ \"userAdminAnyDatabase\" , \"clusterMonitor\" , \"clusterManager\" , \"clusterAdmin\" ] } ) Output: { \"role\" : \"cn=otherusers,dc=percona,dc=com\" , \"privileges\" : [ ], \"roles\" : [ \"userAdminAnyDatabase\" , \"clusterMonitor\" , \"clusterManager\" , \"clusterAdmin\" ] } Enable x.509 authentication \u00b6 Stop the mongod service $ sudo systemctl stop mongod Edit the /etc/mongod.conf configuration file. net : port : 27017 bindIp : 127.0.0.1 tls : mode : requireTLS certificateKeyFile : /var/lib/mongocerts/server.pem CAFile : /var/lib/mongocerts/ca.crt security : authorization : enabled ldap : servers : \"ldap.example.com\" transportSecurity : none authz : queryTemplate : \"dc=percona,dc=com??sub?(&(objectClass=groupOfNames)(member={USER}))\" setParameter : authenticationMechanisms : PLAIN,MONGODB-X509 Replace ldap.example.com with the hostname of your LDAP server. In the LDAP query template, replace the domain controllers percona and com with those relevant to your organization. Start the mongod service $ sudo systemctl start mongod Authenticate with the x.509 certificate \u00b6 To test the authentication, connect to Percona Server for MongoDB using the following command: $ mongosh --host localhost --tls --tlsCAFile /var/lib/mongocerts/ca.crt --tlsCertificateKeyFile <path_to_client_certificate>/client.pem --authenticationMechanism MONGODB-X509 --authenticationDatabase = '$external' The result should look like the following: > db . runCommand ({ connectionStatus : 1 }) { \"authInfo\" : { \"authenticatedUsers\" : [ { \"user\" : \"CN=John Doe,DC=percona,DC=com\" , \"db\" : \"$external\" } ], \"authenticatedUserRoles\" : [ { \"role\" : \"cn=otherreaders,dc=percona,dc=com\" , \"db\" : \"admin\" }, { \"role\" : \"clusterAdmin\" , \"db\" : \"admin\" }, { \"role\" : \"userAdminAnyDatabase\" , \"db\" : \"admin\" }, { \"role\" : \"clusterManager\" , \"db\" : \"admin\" }, { \"role\" : \"clusterMonitor\" , \"db\" : \"admin\" } ] }, \"ok\" : 1 }","title":"Set up x.509 authentication and LDAP authorization"},{"location":"x509-ldap.html#set-up-x509-authentication-and-ldap-authorization","text":"x.509 certificate authentication is one of the supported authentication mechanisms in Percona Server for MongoDB. It is compatible with LDAP authorization to enable you to control user access and operations in your database environment. This document provides the steps on how to configure and use x.509 certificates for authentication in Percona Server for MongoDB and authorize users in the LDAP server.","title":"Set up x.509 authentication and LDAP authorization"},{"location":"x509-ldap.html#considerations","text":"For testing purposes, in this tutorial we use OpenSSL to issue self-signed certificates. For production use, we recommend using certificates issued and signed by the CA in Percona Server for MongoDB. Client certificates must meet the client certificate requirements . The setup of the LDAP server and the configuration of the LDAP schema is out of scope of this document. We assume that you have the LDAP server up and running and accessible to Percona Server for MongoDB.","title":"Considerations"},{"location":"x509-ldap.html#setup-procedure","text":"","title":"Setup procedure"},{"location":"x509-ldap.html#issue-certificates","text":"Create a directory to store the certificates. For example, /var/lib/mongocerts . $ sudo mkdir -p /var/lib/mongocerts Grant access to the mongod user to this directory: $ sudo chown mongod:mongod /var/lib/mongocerts","title":"Issue certificates"},{"location":"x509-ldap.html#set-up-the-ldap-server","text":"The setup of the LDAP server is out of scope of this document. Please work with your LDAP administrators to set up the LDAP server and configure the LDAP schema.","title":"Set up the LDAP server"},{"location":"x509-ldap.html#configure-the-mongod-server","text":"The configuration consists of the following steps: Creating a role that matches the user group on the LDAP server Editing the configuration file to enable the x.509 authentication Note When you use x.509 authentication with LDAP authorization, you don\u2019t need to create users in the $external database. User management is done on the LDAP server so when a client connects to the database, they are authenticated and authorized through the LDAP server.","title":"Configure the mongod server"},{"location":"x509-ldap.html#authenticate-with-the-x509-certificate","text":"To test the authentication, connect to Percona Server for MongoDB using the following command: $ mongosh --host localhost --tls --tlsCAFile /var/lib/mongocerts/ca.crt --tlsCertificateKeyFile <path_to_client_certificate>/client.pem --authenticationMechanism MONGODB-X509 --authenticationDatabase = '$external' The result should look like the following: > db . runCommand ({ connectionStatus : 1 }) { \"authInfo\" : { \"authenticatedUsers\" : [ { \"user\" : \"CN=John Doe,DC=percona,DC=com\" , \"db\" : \"$external\" } ], \"authenticatedUserRoles\" : [ { \"role\" : \"cn=otherreaders,dc=percona,dc=com\" , \"db\" : \"admin\" }, { \"role\" : \"clusterAdmin\" , \"db\" : \"admin\" }, { \"role\" : \"userAdminAnyDatabase\" , \"db\" : \"admin\" }, { \"role\" : \"clusterManager\" , \"db\" : \"admin\" }, { \"role\" : \"clusterMonitor\" , \"db\" : \"admin\" } ] }, \"ok\" : 1 }","title":"Authenticate with the x.509 certificate"},{"location":"install/index.html","text":"Install Percona Server for MongoDB \u00b6 Percona provides installation packages of Percona Server for MongoDB for the most 64-bit Linux distributions. Find the full list of supported platforms on the Percona Software and Platform Lifecycle page. System requirements \u00b6 x86_64 \u00b6 Percona Server for MongoDB has the same system requirements as the MongoDB Community Edition. Starting in MongoDB 5.0, mongod , mongos , and the legacy mongo shell are supported on x86_64 platforms that must meet these minimum micro-architecture requirements: Only Oracle Linux running the Red Hat Compatible Kernel (RHCK) is supported. MongoDB does not support the Unbreakable Enterprise Kernel (UEK). MongoDB 5.0 and above requires use of the AVX instruction set, available on select Intel and AMD processors . ARM64 \u00b6 Percona Server for MongoDB requires the ARMv8.2-A or later microarchitecture. Installation instructions \u00b6 Choose how you wish to install Percona Server for MongoDB: From Percona repositories (recommended): on Debian or Ubuntu on RHEL or CentOS From binary tarballs Manually from Percona website Note Make sure that all dependencies are satisfied Run in Docker Upgrade instructions \u00b6 If you are currently using MongoDB, see Upgrading from MongoDB . If you are running an earlier version of Percona Server for MongoDB, see Upgrading from Version 5.0 .","title":"System requirements"},{"location":"install/index.html#install-percona-server-for-mongodb","text":"Percona provides installation packages of Percona Server for MongoDB for the most 64-bit Linux distributions. Find the full list of supported platforms on the Percona Software and Platform Lifecycle page.","title":"Install Percona Server for MongoDB"},{"location":"install/index.html#system-requirements","text":"","title":"System requirements"},{"location":"install/index.html#x86_64","text":"Percona Server for MongoDB has the same system requirements as the MongoDB Community Edition. Starting in MongoDB 5.0, mongod , mongos , and the legacy mongo shell are supported on x86_64 platforms that must meet these minimum micro-architecture requirements: Only Oracle Linux running the Red Hat Compatible Kernel (RHCK) is supported. MongoDB does not support the Unbreakable Enterprise Kernel (UEK). MongoDB 5.0 and above requires use of the AVX instruction set, available on select Intel and AMD processors .","title":"x86_64"},{"location":"install/index.html#arm64","text":"Percona Server for MongoDB requires the ARMv8.2-A or later microarchitecture.","title":"ARM64"},{"location":"install/index.html#installation-instructions","text":"Choose how you wish to install Percona Server for MongoDB: From Percona repositories (recommended): on Debian or Ubuntu on RHEL or CentOS From binary tarballs Manually from Percona website Note Make sure that all dependencies are satisfied Run in Docker","title":"Installation instructions"},{"location":"install/index.html#upgrade-instructions","text":"If you are currently using MongoDB, see Upgrading from MongoDB . If you are running an earlier version of Percona Server for MongoDB, see Upgrading from Version 5.0 .","title":"Upgrade instructions"},{"location":"install/apt.html","text":"Install Percona Server for MongoDB on Debian and Ubuntu \u00b6 This document describes how to install Percona Server for MongoDB from Percona repositories on DEB-based distributions such as Debian and Ubuntu. Note Percona Server for MongoDB should work on other DEB-based distributions, but it is tested only on platforms listed on the Percona Software and Platform Lifecycle page. Package Contents \u00b6 Package Contains percona-server-mongodb The mongosh shell, import/export tools, other client utilities, server software, default configuration, and init.d scripts. percona-server-mongodb-server The mongod server, default configuration files, and init.d scripts percona-server-mongodb-shell The mongosh shell percona-server-mongodb-mongos The mongos sharded cluster query router percona-server-mongodb-tools Mongo tools for high-performance MongoDB fork from Percona percona-server-mongodb-dbg Debug symbols for the server Procedure \u00b6 Configure Percona repository \u00b6 Percona provides the percona-release configuration tool that simplifies operating repositories and enables to install and update both Percona Backup for MongoDB packages and required dependencies smoothly. Fetch percona-release packages from Percona web: $ wget https://repo.percona.com/apt/percona-release_latest. $( lsb_release -sc ) _all.deb Install the downloaded package with dpkg : $ sudo dpkg -i percona-release_latest. $( lsb_release -sc ) _all.deb After you install this package, you have the access to Percona repositories. You can check the repository setup in the /etc/apt/sources.list.d/percona-release.list file. Enable the repository: $ sudo percona-release enable psmdb-60 release Remember to update the local cache: $ sudo apt update Install Percona Server for MongoDB \u00b6 Install the latest version Install a specific version Run the following command to install the latest version of Percona Server for MongoDB: $ sudo apt install percona-server-mongodb To install a specific version of Percona Server for MongoDB, do the following: List available versions: $ sudo apt-cache madison percona-server-mongodb Sample output: percona-server-mongodb | 6.0.2-1.buster | http://repo.percona.com/psmdb-60/apt buster/main amd64 Packages Install a specific version packages. You must specify each package with the version number. For example, to install Percona Server for MongoDB 6.0.2-1, run the following command: $ sudo apt install percona-server-mongodb = 6 .0.2-1.buster percona-server-mongodb-mongos = 6 .0.2-1.buster percona-server-mongodb-shell = 6 .0.2-1.buster percona-server-mongodb-server = 6 .0.2-1.buster percona-server-mongodb-tools = 6 .0.2-1.buster Run Percona Server for MongoDB \u00b6 By default, Percona Server for MongoDB stores data files in /var/lib/mongodb/ and configuration parameters in /etc/mongod.conf . Starting the service Percona Server for MongoDB is started automatically after installation unless it encounters errors during the installation process. You can also manually start it using the following command: $ sudo systemctl start mongod Confirming that the service is running Check the service status using the following command: $ sudo systemctl status mongod Stopping the service Stop the service using the following command: $ sudo systemctl stop mongod Restarting the service Restart the service using the following command: $ sudo systemctl restart mongod","title":"Install Percona Server for MongoDB on Debian and Ubuntu"},{"location":"install/apt.html#install-percona-server-for-mongodb-on-debian-and-ubuntu","text":"This document describes how to install Percona Server for MongoDB from Percona repositories on DEB-based distributions such as Debian and Ubuntu. Note Percona Server for MongoDB should work on other DEB-based distributions, but it is tested only on platforms listed on the Percona Software and Platform Lifecycle page.","title":"Install Percona Server for MongoDB on Debian and Ubuntu"},{"location":"install/apt.html#package-contents","text":"Package Contains percona-server-mongodb The mongosh shell, import/export tools, other client utilities, server software, default configuration, and init.d scripts. percona-server-mongodb-server The mongod server, default configuration files, and init.d scripts percona-server-mongodb-shell The mongosh shell percona-server-mongodb-mongos The mongos sharded cluster query router percona-server-mongodb-tools Mongo tools for high-performance MongoDB fork from Percona percona-server-mongodb-dbg Debug symbols for the server","title":"Package Contents"},{"location":"install/apt.html#procedure","text":"","title":"Procedure"},{"location":"install/apt.html#configure-percona-repository","text":"Percona provides the percona-release configuration tool that simplifies operating repositories and enables to install and update both Percona Backup for MongoDB packages and required dependencies smoothly. Fetch percona-release packages from Percona web: $ wget https://repo.percona.com/apt/percona-release_latest. $( lsb_release -sc ) _all.deb Install the downloaded package with dpkg : $ sudo dpkg -i percona-release_latest. $( lsb_release -sc ) _all.deb After you install this package, you have the access to Percona repositories. You can check the repository setup in the /etc/apt/sources.list.d/percona-release.list file. Enable the repository: $ sudo percona-release enable psmdb-60 release Remember to update the local cache: $ sudo apt update","title":"Configure Percona repository"},{"location":"install/apt.html#install-percona-server-for-mongodb","text":"Install the latest version Install a specific version Run the following command to install the latest version of Percona Server for MongoDB: $ sudo apt install percona-server-mongodb To install a specific version of Percona Server for MongoDB, do the following: List available versions: $ sudo apt-cache madison percona-server-mongodb Sample output: percona-server-mongodb | 6.0.2-1.buster | http://repo.percona.com/psmdb-60/apt buster/main amd64 Packages Install a specific version packages. You must specify each package with the version number. For example, to install Percona Server for MongoDB 6.0.2-1, run the following command: $ sudo apt install percona-server-mongodb = 6 .0.2-1.buster percona-server-mongodb-mongos = 6 .0.2-1.buster percona-server-mongodb-shell = 6 .0.2-1.buster percona-server-mongodb-server = 6 .0.2-1.buster percona-server-mongodb-tools = 6 .0.2-1.buster","title":"Install Percona Server for MongoDB"},{"location":"install/apt.html#run-percona-server-for-mongodb","text":"By default, Percona Server for MongoDB stores data files in /var/lib/mongodb/ and configuration parameters in /etc/mongod.conf . Starting the service Percona Server for MongoDB is started automatically after installation unless it encounters errors during the installation process. You can also manually start it using the following command: $ sudo systemctl start mongod Confirming that the service is running Check the service status using the following command: $ sudo systemctl status mongod Stopping the service Stop the service using the following command: $ sudo systemctl stop mongod Restarting the service Restart the service using the following command: $ sudo systemctl restart mongod","title":"Run Percona Server for MongoDB"},{"location":"install/docker.html","text":"Run Percona Server for MongoDB in a Docker container \u00b6 Docker images of Percona Server for MongoDB are hosted publicly on Docker Hub . For more information about using Docker, see the Docker Docs . Note Make sure that you are using the latest version of Docker. The ones provided via apt and yum may be outdated and cause errors. By default, Docker will pull the image from Docker Hub if it is not available locally. To run the latest Percona Server for MongoDB 6.0 in a Docker container, run the following command as the root user or via sudo : On x86_64 platforms On ARM64 platforms $ docker run -d --name psmdb --restart always \\ percona/percona-server-mongodb:6.0 $ docker run -d --name psmdb --restart always \\ percona/percona-server-mongodb:<TAG>-arm64 Replace the <TAG> with the desired version (for example, 6.0.4-3-arm64) The command does the following: The docker run command instructs the docker daemon to run a container from an image. The -d option starts the container in detached mode (that is, in the background). The --name option assigns a custom name for the container that you can use to reference the container within a Docker network. In this case: psmdb . The --restart option defines the container\u2019s restart policy. Setting it to always ensures that the Docker daemon will start the container on startup and restart it if the container exits. percona/percona-server-mongodb:6.0 / percona/percona-server-mongodb:<TAG>-arm64 is the name and version tag of the image to derive the container from. Connecting from another Docker container \u00b6 The Percona Server for MongoDB container exposes standard MongoDB port (27017), which can be used for connection from an application running in another container. To link the application container to the psmdb container, use the --link psmdb option when running the container with your app. Connecting with the mongosh shell \u00b6 To start another container with the mongosh shell that connects to your Percona Server for MongoDB container, run the following command: $ docker run -it --link psmdb --rm percona/percona-server-mongodb:6.0 mongosh mongodb://MONGODB_SERVER:PORT/DB_NAME Set MONGODB_SERVER , PORT , and DB_NAME with the IP address of the psmdb container, the port of your MongoDB Server (default value is 27017), and the name of the database you want to connect to. You can get the IP address by running this command: $ docker inspect -f '{{range.NetworkSettings.Networks}}{{.IPAddress}}{{end}}' psmdb","title":"Run Percona Server for MongoDB in a Docker container"},{"location":"install/docker.html#run-percona-server-for-mongodb-in-a-docker-container","text":"Docker images of Percona Server for MongoDB are hosted publicly on Docker Hub . For more information about using Docker, see the Docker Docs . Note Make sure that you are using the latest version of Docker. The ones provided via apt and yum may be outdated and cause errors. By default, Docker will pull the image from Docker Hub if it is not available locally. To run the latest Percona Server for MongoDB 6.0 in a Docker container, run the following command as the root user or via sudo : On x86_64 platforms On ARM64 platforms $ docker run -d --name psmdb --restart always \\ percona/percona-server-mongodb:6.0 $ docker run -d --name psmdb --restart always \\ percona/percona-server-mongodb:<TAG>-arm64 Replace the <TAG> with the desired version (for example, 6.0.4-3-arm64) The command does the following: The docker run command instructs the docker daemon to run a container from an image. The -d option starts the container in detached mode (that is, in the background). The --name option assigns a custom name for the container that you can use to reference the container within a Docker network. In this case: psmdb . The --restart option defines the container\u2019s restart policy. Setting it to always ensures that the Docker daemon will start the container on startup and restart it if the container exits. percona/percona-server-mongodb:6.0 / percona/percona-server-mongodb:<TAG>-arm64 is the name and version tag of the image to derive the container from.","title":"Run Percona Server for MongoDB in a Docker container"},{"location":"install/docker.html#connecting-from-another-docker-container","text":"The Percona Server for MongoDB container exposes standard MongoDB port (27017), which can be used for connection from an application running in another container. To link the application container to the psmdb container, use the --link psmdb option when running the container with your app.","title":"Connecting from another Docker container"},{"location":"install/docker.html#connecting-with-the-mongosh-shell","text":"To start another container with the mongosh shell that connects to your Percona Server for MongoDB container, run the following command: $ docker run -it --link psmdb --rm percona/percona-server-mongodb:6.0 mongosh mongodb://MONGODB_SERVER:PORT/DB_NAME Set MONGODB_SERVER , PORT , and DB_NAME with the IP address of the psmdb container, the port of your MongoDB Server (default value is 27017), and the name of the database you want to connect to. You can get the IP address by running this command: $ docker inspect -f '{{range.NetworkSettings.Networks}}{{.IPAddress}}{{end}}' psmdb","title":"Connecting with the mongosh shell"},{"location":"install/tarball.html","text":"Install Percona Server for MongoDB from binary tarball \u00b6 You can find links to the binary tarballs under the Generic Linux menu item on the Percona website There are the following tarballs available: percona-server-mongodb-<version>-x86_64.glibc2.17.tar.gz is the general tarball, compatible with any supported operating system except Ubuntu 22.04. percona-server-mongodb-<version>-x86_64.glibc2.35.tar.gz is the tarball for Ubuntu 22.04. percona-mongodb-mongosh-<version>-x86_64.tar.gz is the tarball for mongosh shell. Preconditions \u00b6 The following packages are required for the installation. On Debian and Ubuntu On Red hat Enterprise Linux and derivatives libcurl4 libsasl2-modules libsasl2-modules-gssapi-mit libcurl cyrus-sasl-gssapi cyrus-sasl-plain Procedure \u00b6 The steps below describe the installation on Debian 10 (\u201cbuster\u201d). Fetch and the binary tarballs: $ wget https://www.percona.com/downloads/percona-server-mongodb-6.0/percona-server-mongodb-6.0.2-1/binary/tarball/percona-server-mongodb-6.0.2-1-x86_64.glibc2.17.tar.gz \\ $ wget https://www.percona.com/downloads/percona-server-mongodb-6.0/percona-server-mongodb-6.0.2-1/binary/tarball/percona-mongodb-mongosh-1.6.0-x86_64.tar.gz 2. Extract the tarballs $ tar -xf percona-server-mongodb-6.0.2-1-x86_64.glibc2.17.tar.gz $ tar -xf percona-mongodb-mongosh-1.6.0-x86_64.tar.gz Add the location of the binaries to the PATH variable: $ export PATH = ~/percona-server-mongodb-6.0.2-1/bin/:~/percona-mongodb-mongosh-1.6.0/bin/: $PATH Create the default data directory: $ mkdir -p /data/db Make sure that you have read and write permissions for the data directory and run mongod .","title":"Install Percona Server for MongoDB from binary tarball"},{"location":"install/tarball.html#install-percona-server-for-mongodb-from-binary-tarball","text":"You can find links to the binary tarballs under the Generic Linux menu item on the Percona website There are the following tarballs available: percona-server-mongodb-<version>-x86_64.glibc2.17.tar.gz is the general tarball, compatible with any supported operating system except Ubuntu 22.04. percona-server-mongodb-<version>-x86_64.glibc2.35.tar.gz is the tarball for Ubuntu 22.04. percona-mongodb-mongosh-<version>-x86_64.tar.gz is the tarball for mongosh shell.","title":"Install Percona Server for MongoDB from binary tarball"},{"location":"install/tarball.html#preconditions","text":"The following packages are required for the installation. On Debian and Ubuntu On Red hat Enterprise Linux and derivatives libcurl4 libsasl2-modules libsasl2-modules-gssapi-mit libcurl cyrus-sasl-gssapi cyrus-sasl-plain","title":"Preconditions"},{"location":"install/tarball.html#procedure","text":"The steps below describe the installation on Debian 10 (\u201cbuster\u201d). Fetch and the binary tarballs: $ wget https://www.percona.com/downloads/percona-server-mongodb-6.0/percona-server-mongodb-6.0.2-1/binary/tarball/percona-server-mongodb-6.0.2-1-x86_64.glibc2.17.tar.gz \\ $ wget https://www.percona.com/downloads/percona-server-mongodb-6.0/percona-server-mongodb-6.0.2-1/binary/tarball/percona-mongodb-mongosh-1.6.0-x86_64.tar.gz 2. Extract the tarballs $ tar -xf percona-server-mongodb-6.0.2-1-x86_64.glibc2.17.tar.gz $ tar -xf percona-mongodb-mongosh-1.6.0-x86_64.tar.gz Add the location of the binaries to the PATH variable: $ export PATH = ~/percona-server-mongodb-6.0.2-1/bin/:~/percona-mongodb-mongosh-1.6.0/bin/: $PATH Create the default data directory: $ mkdir -p /data/db Make sure that you have read and write permissions for the data directory and run mongod .","title":"Procedure"},{"location":"install/uninstall.html","text":"Uninstall Percona Server for MongoDB \u00b6 To completely remove Percona Server for MongoDB you need to remove all the installed packages, data and configuration files. If you need the data, consider making a backup before uninstalling Percona Server for MongoDB. Follow the instructions, relevant to your operating system: Uninstall on Debian and Ubuntu Uninstall on Red Hat Enterprise Linux and derivatives You can remove Percona Server for MongoDB packages with one of the following commands: apt remove will only remove the packages and leave the configuration and data files. apt purge will remove all the packages with configuration files and data. Choose which command better suits you depending on your needs. Stop the mongod server: $ sudo systemctl stop mongod Remove the packages. There are two options. Keep the configuration and data files Delete configuration and data files $ sudo apt remove percona-server-mongodb* $ sudo apt purge percona-server-mongodb* Stop the mongod service: $ sudo systemctl stop mongod Remove the packages: $ sudo yum remove percona-server-mongodb* Remove the data and configuration files: $ sudo rm -rf /var/lib/mongodb $ sudo rm -f /etc/mongod.conf Warning This will remove all the packages and delete all the data files (databases, tables, logs, etc.). You might want to back up your data before doing this in case you need the data later.","title":"Uninstall Percona Server for MongoDB"},{"location":"install/uninstall.html#uninstall-percona-server-for-mongodb","text":"To completely remove Percona Server for MongoDB you need to remove all the installed packages, data and configuration files. If you need the data, consider making a backup before uninstalling Percona Server for MongoDB. Follow the instructions, relevant to your operating system: Uninstall on Debian and Ubuntu Uninstall on Red Hat Enterprise Linux and derivatives You can remove Percona Server for MongoDB packages with one of the following commands: apt remove will only remove the packages and leave the configuration and data files. apt purge will remove all the packages with configuration files and data. Choose which command better suits you depending on your needs. Stop the mongod server: $ sudo systemctl stop mongod Remove the packages. There are two options. Keep the configuration and data files Delete configuration and data files $ sudo apt remove percona-server-mongodb* $ sudo apt purge percona-server-mongodb* Stop the mongod service: $ sudo systemctl stop mongod Remove the packages: $ sudo yum remove percona-server-mongodb* Remove the data and configuration files: $ sudo rm -rf /var/lib/mongodb $ sudo rm -f /etc/mongod.conf Warning This will remove all the packages and delete all the data files (databases, tables, logs, etc.). You might want to back up your data before doing this in case you need the data later.","title":"Uninstall Percona Server for MongoDB"},{"location":"install/upgrade-from-50.html","text":"Upgrading from Percona Server for MongoDB 5.0 to 6.0 \u00b6 To upgrade Percona Server for MongoDB to version 6.0, you must be running version 5.0. Upgrades from earlier versions are not supported. Before upgrading your production Percona Server for MongoDB deployments, test all your applications in a testing environment to make sure they are compatible with the new version. For more information, see Compatibility Changes in MongoDB 6.0 We recommend to upgrade Percona Server for MongoDB from official Percona repositories using percona-release repository management tool and the corresponding package manager for your system. This document describes this method for the in-place upgrade (where your existing data and configuration files are preserved). Warning Perform a full backup of your data and configuration files before upgrading. Upgrade on Debian and Ubuntu Upgrade on Red Hat Enterprise Linux and derivatives Stop the mongod service: $ sudo systemctl stop mongod Enable Percona repository for Percona Server for MongoDB 6.0: $ sudo percona-release enable psmdb-60 Update the local cache: $ sudo apt update Install Percona Server for MongoDB 6.0 packages: $ sudo apt install percona-server-mongodb Start the mongod instance: $ sudo systemctl start mongod For more information, see Installing Percona Server for MongoDB on Debian and Ubuntu . Stop the mongod service: $ sudo systemctl stop mongod Enable Percona repository for Percona Server for MongoDB 6.0: $ sudo percona-release enable psmdb-60 Install Percona Server for MongoDB 6.0 packages: $ sudo yum install percona-server-mongodb Start the mongod instance: $ sudo systemctl start mongod After the upgrade, Percona Server for MongoDB is started with the feature set of 5.0 version. Assuming that your applications are compatible with the new version, enable 6.0 version features. Run the following command against the admin database: > db . adminCommand ( { setFeatureCompatibilityVersion : \"6.0\" } ) See also MongoDB Documentation: Upgrade a Standalone Upgrade a Replica Set Upgrade a Sharded Cluster","title":"Upgrade PSMDB from 5.0 to 6.0"},{"location":"install/upgrade-from-50.html#upgrading-from-percona-server-for-mongodb-50-to-60","text":"To upgrade Percona Server for MongoDB to version 6.0, you must be running version 5.0. Upgrades from earlier versions are not supported. Before upgrading your production Percona Server for MongoDB deployments, test all your applications in a testing environment to make sure they are compatible with the new version. For more information, see Compatibility Changes in MongoDB 6.0 We recommend to upgrade Percona Server for MongoDB from official Percona repositories using percona-release repository management tool and the corresponding package manager for your system. This document describes this method for the in-place upgrade (where your existing data and configuration files are preserved). Warning Perform a full backup of your data and configuration files before upgrading. Upgrade on Debian and Ubuntu Upgrade on Red Hat Enterprise Linux and derivatives Stop the mongod service: $ sudo systemctl stop mongod Enable Percona repository for Percona Server for MongoDB 6.0: $ sudo percona-release enable psmdb-60 Update the local cache: $ sudo apt update Install Percona Server for MongoDB 6.0 packages: $ sudo apt install percona-server-mongodb Start the mongod instance: $ sudo systemctl start mongod For more information, see Installing Percona Server for MongoDB on Debian and Ubuntu . Stop the mongod service: $ sudo systemctl stop mongod Enable Percona repository for Percona Server for MongoDB 6.0: $ sudo percona-release enable psmdb-60 Install Percona Server for MongoDB 6.0 packages: $ sudo yum install percona-server-mongodb Start the mongod instance: $ sudo systemctl start mongod After the upgrade, Percona Server for MongoDB is started with the feature set of 5.0 version. Assuming that your applications are compatible with the new version, enable 6.0 version features. Run the following command against the admin database: > db . adminCommand ( { setFeatureCompatibilityVersion : \"6.0\" } ) See also MongoDB Documentation: Upgrade a Standalone Upgrade a Replica Set Upgrade a Sharded Cluster","title":"Upgrading from Percona Server for MongoDB 5.0 to 6.0"},{"location":"install/upgrade-from-mongodb.html","text":"Upgrade Percona Server for MongoDB \u00b6 An in-place upgrade is done by keeping the existing data in the server. It involves changing out the MongoDB binaries. Generally speaking, the upgrade steps include: Stopping the mongod service Removing the old binaries Installing the new server version binaries Restarting the mongod service with the same dbpath data directory. An in-place upgrade is suitable for most environments except the ones that use ephemeral storage and/or host addresses. This document provides upgrade instructions for the following use cases: Upgrading from MongoDB 6.0 Community Edition Minor upgrade of Percona Server for MongoDB Upgrading from MongoDB 6.0 Community Edition \u00b6 Note MongoDB creates a user that belongs to two groups, which is a potential security risk. This is fixed in Percona Server for MongoDB: the user is included only in the mongod group. To avoid problems with current MongoDB setups, existing user group membership is not changed when you migrate to Percona Server for MongoDB. Instead, a new mongod user is created during installation, and it belongs to the mongod group. This section describes an in-place upgrade of a mongod instance. If you are using data at rest encryption, refer to the Upgrading to Percona Server for MongoDB with data at rest encryption enabled section. Prerequisites \u00b6 Before you start the upgrade, update the MongoDB configuration file ( /etc/mongod.conf ) to contain the following settings. processManagement : fork : true pidFilePath : /var/run/mongod.pid Troubleshooting tip : The pidFilePath setting in mongod.conf must match the PIDFile option in the systemd mongod service unit. Otherwise, the service will kill the mongod process after a timeout. Warning Before starting the upgrade, we recommend to perform a full backup of your data. Upgrade on Debian and Ubuntu Upgrade on Red Hat Enterprise Linux and derivatives Stop the mongod service: $ sudo systemctl stop mongod Check for installed packages: $ sudo dpkg -l | grep mongod Output: ii mongodb-org 6.0.2 amd64 MongoDB open source document-oriented database system (metapackage) ii mongodb-org-database 6.0.2 amd64 MongoDB open source document-oriented database system (metapackage) ii mongodb-org-database-tools-extra 6.0.2 amd64 Extra MongoDB database tools ii mongodb-org-mongos 6.0.2 amd64 MongoDB sharded cluster query router ii mongodb-org-server 6.0.2 amd64 MongoDB database server ii mongodb-org-shell 6.0.2 amd64 MongoDB shell client ii mongodb-org-tools 6.0.2 amd64 MongoDB tools Remove the installed packages: $ sudo apt remove \\ mongodb-org \\ mongodb-org-mongos \\ mongodb-org-server \\ mongodb-org-shell \\ mongodb-org-tools Remove log files: $ sudo rm -r /var/log/mongodb Install Percona Server for MongoDB Verify that the configuration file includes the correct options. For example, Percona Server for MongoDB stores data files in /var/lib/mongodb by default. If you used another dbPath data directory, edit the configuration file accordingly Start the mongod service: $ sudo systemctl start mongod Stop the mongod service: $ sudo systemctl stop mongod Check for installed packages: $ sudo rpm -qa | grep mongo Output: mongodb-org-shell-6.0.2-1.el8.x86_64 mongodb-org-database-6.0.0-1.el8.x86_64 mongodb-org-6.0.0-1.el8.x86_64 mongodb-database-tools-100.4.1-1.x86_64 mongodb-org-server-6.0.2-1.el8.x86_64 mongodb-org-mongos-6.0.2-1.el8.x86_64 mongodb-org-tools-6.0.0-1.el8.x86_64 Remove the installed packages: $ sudo yum remove \\ mongodb-org-shell-6.0.2-1.el8.x86_64 mongodb-org-database-6.0.0-1.el8.x86_64 mongodb-org-6.0.0-1.el8.x86_64 mongodb-database-tools-100.4.1-1.x86_64 mongodb-org-server-6.0.2-1.el8.x86_64 mongodb-org-mongos-6.0.2-1.el8.x86_64 mongodb-org-tools-6.0.0-1.el8.x86_64 Remove log files: $ sudo rm -r /var/log/mongodb Install Percona Server for MongoDB Note When you remove old packages, your existing configuration file is saved as /etc/mongod.conf.rpmsave . If you want to use this configuration with the new version, replace the default /etc/mongod.conf file. For example, existing data may not be compatible with the default WiredTiger storage engine. Start the mongod service: $ sudo systemctl start mongod To upgrade a replica set or a sharded cluster, use the rolling restart method. It allows you to perform the upgrade with minimum downtime. You upgrade the nodes one by one, while the whole cluster / replica set remains operational. See also MongoDB Documentation: Upgrade a Replica Set Upgrade a Sharded Cluster Minor upgrade of Percona Server for MongoDB \u00b6 To upgrade Percona Server for MongoDB to the latest version, follow these steps: Stop the mongod service: $ sudo systemctl stop mongod Install the latest version packages . Use the command relevant to your operating system. Start the mongod service: $ sudo systemctl start mongod To upgrade a replica set or a sharded cluster, use the rolling restart method. It allows you to perform the upgrade with minimum downtime. You upgrade the nodes one by one, while the whole cluster / replica set remains operational. Upgrading to Percona Server for MongoDB with data at rest encryption enabled \u00b6 Steps to upgrade from MongoDB 6.0 Community Edition with data encryption enabled to Percona Server for MongoDB are different. mongod requires an empty dbPath data directory because it cannot encrypt data files in place. It must receive data from other replica set members during the initial sync. Please refer to the Switching storage engines for more information on migration of encrypted data. Contact us for working at the detailed migration steps, if further assistance is needed.","title":"Upgrade Percona Server for MongoDB"},{"location":"install/upgrade-from-mongodb.html#upgrade-percona-server-for-mongodb","text":"An in-place upgrade is done by keeping the existing data in the server. It involves changing out the MongoDB binaries. Generally speaking, the upgrade steps include: Stopping the mongod service Removing the old binaries Installing the new server version binaries Restarting the mongod service with the same dbpath data directory. An in-place upgrade is suitable for most environments except the ones that use ephemeral storage and/or host addresses. This document provides upgrade instructions for the following use cases: Upgrading from MongoDB 6.0 Community Edition Minor upgrade of Percona Server for MongoDB","title":"Upgrade Percona Server for MongoDB"},{"location":"install/upgrade-from-mongodb.html#upgrading-from-mongodb-60-community-edition","text":"Note MongoDB creates a user that belongs to two groups, which is a potential security risk. This is fixed in Percona Server for MongoDB: the user is included only in the mongod group. To avoid problems with current MongoDB setups, existing user group membership is not changed when you migrate to Percona Server for MongoDB. Instead, a new mongod user is created during installation, and it belongs to the mongod group. This section describes an in-place upgrade of a mongod instance. If you are using data at rest encryption, refer to the Upgrading to Percona Server for MongoDB with data at rest encryption enabled section.","title":"Upgrading from MongoDB 6.0 Community Edition"},{"location":"install/upgrade-from-mongodb.html#prerequisites","text":"Before you start the upgrade, update the MongoDB configuration file ( /etc/mongod.conf ) to contain the following settings. processManagement : fork : true pidFilePath : /var/run/mongod.pid Troubleshooting tip : The pidFilePath setting in mongod.conf must match the PIDFile option in the systemd mongod service unit. Otherwise, the service will kill the mongod process after a timeout. Warning Before starting the upgrade, we recommend to perform a full backup of your data. Upgrade on Debian and Ubuntu Upgrade on Red Hat Enterprise Linux and derivatives Stop the mongod service: $ sudo systemctl stop mongod Check for installed packages: $ sudo dpkg -l | grep mongod Output: ii mongodb-org 6.0.2 amd64 MongoDB open source document-oriented database system (metapackage) ii mongodb-org-database 6.0.2 amd64 MongoDB open source document-oriented database system (metapackage) ii mongodb-org-database-tools-extra 6.0.2 amd64 Extra MongoDB database tools ii mongodb-org-mongos 6.0.2 amd64 MongoDB sharded cluster query router ii mongodb-org-server 6.0.2 amd64 MongoDB database server ii mongodb-org-shell 6.0.2 amd64 MongoDB shell client ii mongodb-org-tools 6.0.2 amd64 MongoDB tools Remove the installed packages: $ sudo apt remove \\ mongodb-org \\ mongodb-org-mongos \\ mongodb-org-server \\ mongodb-org-shell \\ mongodb-org-tools Remove log files: $ sudo rm -r /var/log/mongodb Install Percona Server for MongoDB Verify that the configuration file includes the correct options. For example, Percona Server for MongoDB stores data files in /var/lib/mongodb by default. If you used another dbPath data directory, edit the configuration file accordingly Start the mongod service: $ sudo systemctl start mongod Stop the mongod service: $ sudo systemctl stop mongod Check for installed packages: $ sudo rpm -qa | grep mongo Output: mongodb-org-shell-6.0.2-1.el8.x86_64 mongodb-org-database-6.0.0-1.el8.x86_64 mongodb-org-6.0.0-1.el8.x86_64 mongodb-database-tools-100.4.1-1.x86_64 mongodb-org-server-6.0.2-1.el8.x86_64 mongodb-org-mongos-6.0.2-1.el8.x86_64 mongodb-org-tools-6.0.0-1.el8.x86_64 Remove the installed packages: $ sudo yum remove \\ mongodb-org-shell-6.0.2-1.el8.x86_64 mongodb-org-database-6.0.0-1.el8.x86_64 mongodb-org-6.0.0-1.el8.x86_64 mongodb-database-tools-100.4.1-1.x86_64 mongodb-org-server-6.0.2-1.el8.x86_64 mongodb-org-mongos-6.0.2-1.el8.x86_64 mongodb-org-tools-6.0.0-1.el8.x86_64 Remove log files: $ sudo rm -r /var/log/mongodb Install Percona Server for MongoDB Note When you remove old packages, your existing configuration file is saved as /etc/mongod.conf.rpmsave . If you want to use this configuration with the new version, replace the default /etc/mongod.conf file. For example, existing data may not be compatible with the default WiredTiger storage engine. Start the mongod service: $ sudo systemctl start mongod To upgrade a replica set or a sharded cluster, use the rolling restart method. It allows you to perform the upgrade with minimum downtime. You upgrade the nodes one by one, while the whole cluster / replica set remains operational. See also MongoDB Documentation: Upgrade a Replica Set Upgrade a Sharded Cluster","title":"Prerequisites"},{"location":"install/upgrade-from-mongodb.html#minor-upgrade-of-percona-server-for-mongodb","text":"To upgrade Percona Server for MongoDB to the latest version, follow these steps: Stop the mongod service: $ sudo systemctl stop mongod Install the latest version packages . Use the command relevant to your operating system. Start the mongod service: $ sudo systemctl start mongod To upgrade a replica set or a sharded cluster, use the rolling restart method. It allows you to perform the upgrade with minimum downtime. You upgrade the nodes one by one, while the whole cluster / replica set remains operational.","title":"Minor upgrade of Percona Server for MongoDB"},{"location":"install/upgrade-from-mongodb.html#upgrading-to-percona-server-for-mongodb-with-data-at-rest-encryption-enabled","text":"Steps to upgrade from MongoDB 6.0 Community Edition with data encryption enabled to Percona Server for MongoDB are different. mongod requires an empty dbPath data directory because it cannot encrypt data files in place. It must receive data from other replica set members during the initial sync. Please refer to the Switching storage engines for more information on migration of encrypted data. Contact us for working at the detailed migration steps, if further assistance is needed.","title":"Upgrading to Percona Server for MongoDB with data at rest encryption enabled"},{"location":"install/yum.html","text":"Install Percona Server for MongoDB on Red Hat Enterprise Linux and derivatives \u00b6 This document describes how to install Percona Server for MongoDB on RPM-based distributions such as Red Hat Enterprise Linux and compatible derivatives. Note Percona Server for MongoDB should work on other RPM-based distributions (for example, Amazon Linux AMI and Oracle Linux), but it is tested only on platforms listed on the Percona Software and Platform Lifecycle page. Package Contents \u00b6 Package Contains percona-server-mongodb The mongosh shell, import/export tools, other client utilities, server software, default configuration, and init.d scripts. percona-server-mongodb-server The mongod server, default configuration files, and init.d scripts percona-server-mongodb-shell The mongosh shell percona-server-mongodb-mongos The mongos sharded cluster query router percona-server-mongodb-tools Mongo tools for high-performance MongoDB fork from Percona percona-server-mongodb-dbg Debug symbols for the server Procedure \u00b6 Percona provides the percona-release configuration tool that simplifies operating repositories and enables to install and update both Percona Backup for MongoDB packages and required dependencies smoothly. Configure Percona repository \u00b6 Install percona-release : $ sudo yum install https://repo.percona.com/yum/percona-release-latest.noarch.rpm Example output Retrieving https://repo.percona.com/yum/percona-release-latest.noarch.rpm Preparing... ########################################### [100%] 1:percona-release ########################################### [100%] Enable the repository: $ sudo percona-release enable psmdb-60 release See also Percona Software Repositories Documentation Install Percona Server for MongoDB packages \u00b6 Install the latest version Install a specific version To install the latest version of Percona Server for MongoDB , use the following command: $ sudo yum install percona-server-mongodb To install a specific version of Percona Server for MongoDB , do the following: List available versions: $ sudo yum list percona-server-mongodb --showduplicates Sample output: Available Packages percona-server-mongodb.x86_64 6.0.2-1.el8 psmdb-60-release-x86_64 Install a specific version packages. For example, to install Percona Server for MongoDB 6.0.2-1, run the following command: $ sudo yum install percona-server-mongodb-6.0.2-1.el8 Run Percona Server for MongoDB \u00b6 Note If you use SELinux in enforcing mode, you must customize your SELinux user policies to allow access to certain /sys and /proc files for OS-level statistics. Also, you must customize directory and port access policies if you are using non-default locations. Please refer to Configure SELinux section of MongoDB Documentation for policy configuration guidelines. By default, Percona Server for MongoDB stores data files in /var/lib/mongodb/ and configuration parameters in /etc/mongod.conf . Starting the service Percona Server for MongoDB is not started automatically after installation. Start it manually using the following command: $ sudo systemctl start mongod Confirming that service is running Check the service status using the following command: service mongod status $ sudo systemctl status mongod Stopping the service Stop the service using the following command: service mongod stop $ sudo systemctl stop mongod Restarting the service Restart the service using the following command: service mongod restart $ sudo systemctl restart mongod Run after reboot \u00b6 The mongod service is not automatically started after you reboot the system. To make it start automatically after reboot, enable it using the systemctl utility: $ sudo systemctl enable mongod Then start the mongod service: $ sudo systemctl start mongod","title":"Install Percona Server for MongoDB on Red Hat Enterprise Linux and derivatives"},{"location":"install/yum.html#install-percona-server-for-mongodb-on-red-hat-enterprise-linux-and-derivatives","text":"This document describes how to install Percona Server for MongoDB on RPM-based distributions such as Red Hat Enterprise Linux and compatible derivatives. Note Percona Server for MongoDB should work on other RPM-based distributions (for example, Amazon Linux AMI and Oracle Linux), but it is tested only on platforms listed on the Percona Software and Platform Lifecycle page.","title":"Install Percona Server for MongoDB on Red Hat Enterprise Linux and derivatives"},{"location":"install/yum.html#package-contents","text":"Package Contains percona-server-mongodb The mongosh shell, import/export tools, other client utilities, server software, default configuration, and init.d scripts. percona-server-mongodb-server The mongod server, default configuration files, and init.d scripts percona-server-mongodb-shell The mongosh shell percona-server-mongodb-mongos The mongos sharded cluster query router percona-server-mongodb-tools Mongo tools for high-performance MongoDB fork from Percona percona-server-mongodb-dbg Debug symbols for the server","title":"Package Contents"},{"location":"install/yum.html#procedure","text":"Percona provides the percona-release configuration tool that simplifies operating repositories and enables to install and update both Percona Backup for MongoDB packages and required dependencies smoothly.","title":"Procedure"},{"location":"install/yum.html#configure-percona-repository","text":"Install percona-release : $ sudo yum install https://repo.percona.com/yum/percona-release-latest.noarch.rpm Example output Retrieving https://repo.percona.com/yum/percona-release-latest.noarch.rpm Preparing... ########################################### [100%] 1:percona-release ########################################### [100%] Enable the repository: $ sudo percona-release enable psmdb-60 release See also Percona Software Repositories Documentation","title":"Configure Percona repository"},{"location":"install/yum.html#install-percona-server-for-mongodb-packages","text":"Install the latest version Install a specific version To install the latest version of Percona Server for MongoDB , use the following command: $ sudo yum install percona-server-mongodb To install a specific version of Percona Server for MongoDB , do the following: List available versions: $ sudo yum list percona-server-mongodb --showduplicates Sample output: Available Packages percona-server-mongodb.x86_64 6.0.2-1.el8 psmdb-60-release-x86_64 Install a specific version packages. For example, to install Percona Server for MongoDB 6.0.2-1, run the following command: $ sudo yum install percona-server-mongodb-6.0.2-1.el8","title":"Install Percona Server for MongoDB packages"},{"location":"install/yum.html#run-percona-server-for-mongodb","text":"Note If you use SELinux in enforcing mode, you must customize your SELinux user policies to allow access to certain /sys and /proc files for OS-level statistics. Also, you must customize directory and port access policies if you are using non-default locations. Please refer to Configure SELinux section of MongoDB Documentation for policy configuration guidelines. By default, Percona Server for MongoDB stores data files in /var/lib/mongodb/ and configuration parameters in /etc/mongod.conf . Starting the service Percona Server for MongoDB is not started automatically after installation. Start it manually using the following command: $ sudo systemctl start mongod Confirming that service is running Check the service status using the following command: service mongod status $ sudo systemctl status mongod Stopping the service Stop the service using the following command: service mongod stop $ sudo systemctl stop mongod Restarting the service Restart the service using the following command: service mongod restart $ sudo systemctl restart mongod","title":"Run Percona Server for MongoDB"},{"location":"install/yum.html#run-after-reboot","text":"The mongod service is not automatically started after you reboot the system. To make it start automatically after reboot, enable it using the systemctl utility: $ sudo systemctl enable mongod Then start the mongod service: $ sudo systemctl start mongod","title":"Run after reboot"},{"location":"release_notes/index.html","text":"Percona Server for MongoDB 6.0 Release Notes \u00b6 Percona Server for MongoDB 6.0.4-3 (2022-12-07) Percona Server for MongoDB 6.0.3-2 (2022-12-07) Percona Server for MongoDB 6.0.2-1 (2022-10-31)","title":"Release notes index"},{"location":"release_notes/index.html#percona-server-for-mongodb-60-release-notes","text":"Percona Server for MongoDB 6.0.4-3 (2022-12-07) Percona Server for MongoDB 6.0.3-2 (2022-12-07) Percona Server for MongoDB 6.0.2-1 (2022-10-31)","title":"Percona Server for MongoDB 6.0 Release Notes"},{"location":"release_notes/6.0.2-1.html","text":"Percona Server for MongoDB 6.0.2-1 (2022-10-31) \u00b6 Release date October 31, 2022 Installation Installing Percona Backup for MongoDB We are pleased to announce the availability of Percona Server for MongoDB (PSMDB) 6.0.2-1 \u2013 the new major version of the source available, drop-in replacement of MongoDB 6.0 Community edition . It is available for download from Percona website and for installation from Percona Software Repositories . Percona Server for MongoDB 6.0.2-1 fully supports MongoDB 6.0 protocols and drivers and does not require any code modifications. Release Highlights \u00b6 Data-at-rest encryption using the Key Management Interoperability Protocol (KMIP) is generally available enabling you to use it in your production environment $backupCursor and $backupCursorExtend aggregation stages functionality is generally available, enabling your application developers to use it for building custom backup solutions. Note Percona provides Percona Backup for MongoDB - the open source tool for consistent backups and restores in MongoDB sharded clusters. Percona Server for MongoDB packages now include mongosh of the previous mongo shell. The previous legacy mongo shell was deprecated in MongoDB 5.0 and has been removed in version 6.0. Some older methods are unavailable or have been replaced with newer ones for the new mongosh . Please review any methods for compatibility. If you install Percona Server for MongoDB from tarballs , you must install mongosh from a separate tarball. Percona Server for MongoDB 6.0.2-1 includes all the features of MongoDB 6.0.2 Community Edition, among which are the following: Enhanced time series collections enable you to: Get deeper data analysis insights by building compound and secondary indexes on time, metadata and measurement fields. Distribute the load among nodes in the cluster by sharding new and existing time series collections . Benefit from faster reads and improved performance by applying the sorting on the most recent entry instead of the whole collection. The following change streams optimizations help you enhance your event-driven solutions: Improve in-app notifications, reference deleted documents or feed the updated version of the entire doc to the downstream system using the before and after states of a document that was changed . React not only to data changes but also to database change events like creating or dropping of collections with the Data Definition Language (DDL) support. New aggregation stages like $densify , $documents , $fill and operators like $bottom , $firstN , $lastN , $maxN / $minN and others enable you to off load work from your developers to the database. These operators allow automating key commands, getting required data insights by combining individual operators into aggregation pipelines. As a result, your developers spend less time on writing complex code or manipulating data manually and can focus on other activities. Cluster-wide configuration parameters and commands save your DBAs\u2019 time on cluster administration. The Stable API (formerly known as versioned API) features the extended set of new database commands and aggregation operators which enables you to improve communication of your apps and MongoDB. Speed up data processing and save on storage costs with clustered collections . Clustered collections don\u2019t require secondary indexes and thus, result in faster queries. A single read/write for the index and the document improves performance for inserts, updates, deletes and queries. With less storage space required by clustered connections, bulk updates and inserts are performed faster. And by turning clustered indexes to TTL indexes with a single field, you benefit from simplified delete operations and reduced storage costs. Percona Server for MongoDB also includes the following bug fixes and enhancements provided upstream: SERVER-68511 - Fixed the issue that caused inconsistency in sharding metadata when running the movePrimary command on the database that has the Feature Compatibility Version (FCV) set to 4.4 or earlier. Affects MongoDB versions 5.0.0 through 5.0.10 and MongoDB 6.0.0. Upgrade to the the fixed version of MongoDB 6.0.2 / Percona Server for MongoDB 6.0.2-1 as soon as possible. SERVER-66072 - Fixed dependency analysis for $match aggregation stage with aggregation expressions with the $rand operator SERVER-68130 - Fixed the AutoSplitVector\u2019s behavior to predict the BSON object size when generating the response WT-9870 - Fixed the global time window state before performing the rollback to stable operation by updating the pinned timestamp as part of the transaction setup. SERVER-68628 - Fixed the issue when retrying a failed resharding operation after a primary failover could lead to server crash or lost writes. SERVER-68925 - Detect and resolve table logging inconsistencies for WiredTiger tables at startup Find the full list of new features and improvements in MongoDB 6.0 Community Edition release notes . Percona Server for MongoDB 6.0.2-1 extends this feature set by providing enterprise-level enhancements for free . To upgrade to PSMDB, see our upgrade instructions.","title":"Percona Server for MongoDB 6.0.2-1 (2022-10-31)"},{"location":"release_notes/6.0.2-1.html#percona-server-for-mongodb-602-1-2022-10-31","text":"Release date October 31, 2022 Installation Installing Percona Backup for MongoDB We are pleased to announce the availability of Percona Server for MongoDB (PSMDB) 6.0.2-1 \u2013 the new major version of the source available, drop-in replacement of MongoDB 6.0 Community edition . It is available for download from Percona website and for installation from Percona Software Repositories . Percona Server for MongoDB 6.0.2-1 fully supports MongoDB 6.0 protocols and drivers and does not require any code modifications.","title":"Percona Server for MongoDB 6.0.2-1 (2022-10-31)"},{"location":"release_notes/6.0.2-1.html#release-highlights","text":"Data-at-rest encryption using the Key Management Interoperability Protocol (KMIP) is generally available enabling you to use it in your production environment $backupCursor and $backupCursorExtend aggregation stages functionality is generally available, enabling your application developers to use it for building custom backup solutions. Note Percona provides Percona Backup for MongoDB - the open source tool for consistent backups and restores in MongoDB sharded clusters. Percona Server for MongoDB packages now include mongosh of the previous mongo shell. The previous legacy mongo shell was deprecated in MongoDB 5.0 and has been removed in version 6.0. Some older methods are unavailable or have been replaced with newer ones for the new mongosh . Please review any methods for compatibility. If you install Percona Server for MongoDB from tarballs , you must install mongosh from a separate tarball. Percona Server for MongoDB 6.0.2-1 includes all the features of MongoDB 6.0.2 Community Edition, among which are the following: Enhanced time series collections enable you to: Get deeper data analysis insights by building compound and secondary indexes on time, metadata and measurement fields. Distribute the load among nodes in the cluster by sharding new and existing time series collections . Benefit from faster reads and improved performance by applying the sorting on the most recent entry instead of the whole collection. The following change streams optimizations help you enhance your event-driven solutions: Improve in-app notifications, reference deleted documents or feed the updated version of the entire doc to the downstream system using the before and after states of a document that was changed . React not only to data changes but also to database change events like creating or dropping of collections with the Data Definition Language (DDL) support. New aggregation stages like $densify , $documents , $fill and operators like $bottom , $firstN , $lastN , $maxN / $minN and others enable you to off load work from your developers to the database. These operators allow automating key commands, getting required data insights by combining individual operators into aggregation pipelines. As a result, your developers spend less time on writing complex code or manipulating data manually and can focus on other activities. Cluster-wide configuration parameters and commands save your DBAs\u2019 time on cluster administration. The Stable API (formerly known as versioned API) features the extended set of new database commands and aggregation operators which enables you to improve communication of your apps and MongoDB. Speed up data processing and save on storage costs with clustered collections . Clustered collections don\u2019t require secondary indexes and thus, result in faster queries. A single read/write for the index and the document improves performance for inserts, updates, deletes and queries. With less storage space required by clustered connections, bulk updates and inserts are performed faster. And by turning clustered indexes to TTL indexes with a single field, you benefit from simplified delete operations and reduced storage costs. Percona Server for MongoDB also includes the following bug fixes and enhancements provided upstream: SERVER-68511 - Fixed the issue that caused inconsistency in sharding metadata when running the movePrimary command on the database that has the Feature Compatibility Version (FCV) set to 4.4 or earlier. Affects MongoDB versions 5.0.0 through 5.0.10 and MongoDB 6.0.0. Upgrade to the the fixed version of MongoDB 6.0.2 / Percona Server for MongoDB 6.0.2-1 as soon as possible. SERVER-66072 - Fixed dependency analysis for $match aggregation stage with aggregation expressions with the $rand operator SERVER-68130 - Fixed the AutoSplitVector\u2019s behavior to predict the BSON object size when generating the response WT-9870 - Fixed the global time window state before performing the rollback to stable operation by updating the pinned timestamp as part of the transaction setup. SERVER-68628 - Fixed the issue when retrying a failed resharding operation after a primary failover could lead to server crash or lost writes. SERVER-68925 - Detect and resolve table logging inconsistencies for WiredTiger tables at startup Find the full list of new features and improvements in MongoDB 6.0 Community Edition release notes . Percona Server for MongoDB 6.0.2-1 extends this feature set by providing enterprise-level enhancements for free . To upgrade to PSMDB, see our upgrade instructions.","title":"Release Highlights"},{"location":"release_notes/6.0.3-2.html","text":"Percona Server for MongoDB 6.0.3-2 (2022-12-07) \u00b6 Release date December 7, 2022 Installation Installing Percona Backup for MongoDB Percona Server for MongoDB 6.0.3-2 is an enhanced, source-available, and highly-scalable database that is a fully-compatible, drop-in replacement for MongoDB 6.0.3 Community edition . Percona Server for MongoDB 6.0.3-2 fully supports MongoDB 6.0 protocols and drivers and does not require any code modifications. Release Highlights \u00b6 Improvements and bug fixes, provided by MongoDB and included in Percona Server for MongoDB are the following: SERVER-66289 - Fixed the issue with how the server handles batches of writes when running $out with secondary read preference by updating write size estimation logic in DocumentSourceWriter SERVER-68371 - Allowed search queries to pass through query analysis when Client-Side Field Level Encryption is enabled for the MongoClient SERVER-68115 - Prevented dropping empty path component from elemMatch path during index selection SERVER-68394 - Prevented yielding strong locks upon startup recovery when _id index is missing Find the full list of new features and improvements in MongoDB 6.0.3 Community edition release notes . Improvements \u00b6 PSMDB-1181 : Add backup cursor parameters to cursor\u2019s metadata Bugs Fixed \u00b6 PSMDB-1175 : Fixed Percona Server for MongoDB behavior when calling $backupCursor with disableIncrementalBackup option","title":"Percona Server for MongoDB 6.0.3-2 (2022-12-07)"},{"location":"release_notes/6.0.3-2.html#percona-server-for-mongodb-603-2-2022-12-07","text":"Release date December 7, 2022 Installation Installing Percona Backup for MongoDB Percona Server for MongoDB 6.0.3-2 is an enhanced, source-available, and highly-scalable database that is a fully-compatible, drop-in replacement for MongoDB 6.0.3 Community edition . Percona Server for MongoDB 6.0.3-2 fully supports MongoDB 6.0 protocols and drivers and does not require any code modifications.","title":"Percona Server for MongoDB 6.0.3-2 (2022-12-07)"},{"location":"release_notes/6.0.3-2.html#release-highlights","text":"Improvements and bug fixes, provided by MongoDB and included in Percona Server for MongoDB are the following: SERVER-66289 - Fixed the issue with how the server handles batches of writes when running $out with secondary read preference by updating write size estimation logic in DocumentSourceWriter SERVER-68371 - Allowed search queries to pass through query analysis when Client-Side Field Level Encryption is enabled for the MongoClient SERVER-68115 - Prevented dropping empty path component from elemMatch path during index selection SERVER-68394 - Prevented yielding strong locks upon startup recovery when _id index is missing Find the full list of new features and improvements in MongoDB 6.0.3 Community edition release notes .","title":"Release Highlights"},{"location":"release_notes/6.0.3-2.html#improvements","text":"PSMDB-1181 : Add backup cursor parameters to cursor\u2019s metadata","title":"Improvements"},{"location":"release_notes/6.0.3-2.html#bugs-fixed","text":"PSMDB-1175 : Fixed Percona Server for MongoDB behavior when calling $backupCursor with disableIncrementalBackup option","title":"Bugs Fixed"},{"location":"release_notes/6.0.4-3.html","text":"Percona Server for MongoDB 6.0.4-3 (2023-01-30) \u00b6 Release date January 30, 2023 Installation Installing Percona Backup for MongoDB Percona Server for MongoDB 6.0.4-3 is an enhanced, source-available, and highly-scalable database that is a fully-compatible, drop-in replacement for MongoDB 6.0.4 Community Edition. It is rebased on MongoDB 6.0.4 Community edition and supports the upstream protocols and drivers. Release Highlights \u00b6 Percona Server for MongoDB is now available on Red Hat Enterprise Linux 9 and compatible derivatives A Docker image for Percona Server for MongoDB (Release candidate) is now available for ARM64 architectures. The support of ARM64 will be extended in subsequent releases. Improvements and bug fixes, provided by MongoDB and included in Percona Server for MongoDB are the following: SERVER-72416 - Fixed the issue with incorrect projection parsing when a collection level collation is specified SERVER-71759 - Changed the yielding policy of dataSize command to YIELD_AUTO for both when the command is called with estimate:true or false SERVER-70237 - Fixed the issue with a BSON object exceeding the max allowed size during chunks merge in a shard SERVER-72222 - Fixed the incorrect behavior of the mapReduce command with single reduce optimization in sharded clusters Find the full list of new features and improvements in MongoDB 6.0.4 Community edition release notes .","title":"Percona Server for MongoDB 6.0.4-3 (2023-01-30)"},{"location":"release_notes/6.0.4-3.html#percona-server-for-mongodb-604-3-2023-01-30","text":"Release date January 30, 2023 Installation Installing Percona Backup for MongoDB Percona Server for MongoDB 6.0.4-3 is an enhanced, source-available, and highly-scalable database that is a fully-compatible, drop-in replacement for MongoDB 6.0.4 Community Edition. It is rebased on MongoDB 6.0.4 Community edition and supports the upstream protocols and drivers.","title":"Percona Server for MongoDB 6.0.4-3 (2023-01-30)"},{"location":"release_notes/6.0.4-3.html#release-highlights","text":"Percona Server for MongoDB is now available on Red Hat Enterprise Linux 9 and compatible derivatives A Docker image for Percona Server for MongoDB (Release candidate) is now available for ARM64 architectures. The support of ARM64 will be extended in subsequent releases. Improvements and bug fixes, provided by MongoDB and included in Percona Server for MongoDB are the following: SERVER-72416 - Fixed the issue with incorrect projection parsing when a collection level collation is specified SERVER-71759 - Changed the yielding policy of dataSize command to YIELD_AUTO for both when the command is called with estimate:true or false SERVER-70237 - Fixed the issue with a BSON object exceeding the max allowed size during chunks merge in a shard SERVER-72222 - Fixed the incorrect behavior of the mapReduce command with single reduce optimization in sharded clusters Find the full list of new features and improvements in MongoDB 6.0.4 Community edition release notes .","title":"Release Highlights"}]}